---
title: "Analysis paper"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)
options(knitr.kable.NA = '')
library(covid.german.forecasts)
library(here)
library(magrittr)
library(scoringutils)
library(knitr)
library(kableExtra)
library(data.table)
library(ggplot2)
library(ggridges)
library(RColorBrewer)
library(patchwork)
library(stringr)

```

## Todo

-   [ ] final decision on the Christmas period. Do we want to also exclude target end dates, or just forceast dates? Do we want to exclude the 2nd of January?
-   [ ] look more closely into the stratification: do we want the current thing or do we want something else that has the outcome in it as well? One thing I thought was have another category: inflection or no inflection and also score that?
-   [ ] Talk to Johannes about whether we want to score log forecasts and log truth values instead. I for now removed that part for the following reasons: I currently don't have a good feeling for what it does. I'm somewhat hesitant that establishing a completely new way of scoring forecasts could be beyond the scope of this paper. Very happy to switch to it entirely if we agree it is the better metric, but not sure we are at that point yet.

## Visualsiation of daily data

```{r}
dailytruth_data %>%
  dplyr::filter(target_end_date >= min(forecast_dates$full_hub_period), 
                target_end_date <= max(forecast_dates$full_hub_period)) %>%
  ggplot(aes(y = true_value, x = target_end_date)) + 
  geom_point(size = 0.3) + 
  geom_line(size = 0.5) + 
  facet_grid(target_type ~ location_name, scales = "free") + 
  labs(y = "Observed values", x = "Date") + 
  theme_light()

ggsave(here("analysis", "plots", "daily_truth.png"))
```

## Visualisation for 1, 2, 3, 4 week ahead forecasts and scores

### Plots that visualise truth vs. predictions

```{r truth-vs-forecasts, fig.height=12, fig.width=15}
# create helper function for the plot ------------------------------------------
truth_and_pred_plot <- function(df) {
  p <- df %>%
  ggplot(aes(y = true_value, x = target_end_date)) + 
  geom_linerange(aes(ymin = `0.25`, ymax = `0.75`, color = model), 
                 size = 1.5,
                 alpha = 1,
                 position = position_dodge(width = 6)) + 
  geom_point(aes(shape = classification)) + 
  geom_line() + 
  theme_light() + 
  facet_wrap(~ location_target, scales = "free", ncol = 2) + 
  theme(legend.position = "bottom") + 
  theme(panel.background = element_rect(fill = "#e1f0fe")) + 
  scale_x_date(limits = c(min(forecast_dates$full_hub_period) + 14, 
                          max(forecast_dates$full_hub_period)))
  return(p)
}





# prepare data for plotting ----------------------------------------------------
# - load ufiltered data and pivot wider
# - add trend classification by target_end_date 
#   (and remove classification by forecast_date that is already present)

df <- unfiltered_data[model %in% regular_models &
                        quantile %in% c(0.025, 0.25, 0.75, 0.975)] %>%
  dcast(... ~ quantile, value.var = "prediction")
df <- merge(
  df[, c("classification", "speed") := NULL], 
  copy(epitrend)[, forecast_date := NULL], 
  by = c("target_end_date", "location_name", "target_type")
)


# create plots for deaths and cases --------------------------------------------

for (horizon in 1:4) {
  # plot for cases
  truth_vs_forecast_cases <- df[grepl(horizon, target)] %>%
    dplyr::filter(target_type == "case") %>%
    truth_and_pred_plot() + 
    scale_color_manual(values = brewer.pal(name = "Accent", n = 5)[-2]) + 
    labs(y = "Cases", x = "")
    
  filename <- here("analysis", "plots", 
                   paste0("truth-and-", horizon, "-wk-ahead_cases"))
  ggsave(paste0(filename, ".png"), plot = truth_vs_forecast_cases)
  
  saveRDS(truth_vs_forecast_cases, 
          paste0(filename, ".RDS"))
  
  # plot for deaths
  truth_vs_forecast_deaths <- df[grepl(horizon, target)] %>%
  dplyr::filter(target_type == "death") %>%
  truth_and_pred_plot()  + 
  scale_color_manual(values = brewer.pal(name = "Accent", n = 5)[1:5]) + 
  annotate('rect', xmin = min(forecast_dates$full_hub_period) + 14,
                xmax = max(forecast_dates$death_not_scored) + 14,
                ymin = 0,
                ymax = Inf, fill = "grey10", alpha = 0.1) + 
    labs(y = "Deaths", x = "")
  
  filename <- here("analysis", "plots", 
                   paste0("truth-and-", horizon, "-wk-ahead_deaths"))
  ggsave(paste0(filename, ".png"), plot = truth_vs_forecast_deaths)
  
  saveRDS(truth_vs_forecast_deaths, 
          paste0(filename, ".RDS"))
}
```


### Plots that visualise the achieved scores over time

```{r scores-over-time, fig.height=10, fig.width=15}
# score forecasts --------------------------------------------------------------
# obtain scores and then do pairwise comparisons between models
summarise_by <- c("model", "horizon", "location_name", "target_type", 
                   "forecast_date", "target_end_date", "location_target", 
                   "classification")
scores_target_forecastdate <- eval_forecasts(
  data = unfiltered_data[model %in% regular_models],
  summarise_by = summarise_by
)

pairwise <- pairwise_comparison(scores_target_forecastdate, 
                                summarise_by = summarise_by, 
                                baseline = "Baseline")
pairwise <- pairwise[compare_against == "Baseline"]


# create helper function to plot forecasts -------------------------------------
scores_over_time_plot <- function(scores, y = "mean_scores_ratio") {
  p <- scores %>%
  ggplot(aes(x = as.Date(target_end_date), y = get(y))) + 
  geom_line(aes(colour = model)) + 
  geom_point(aes(shape = classification, colour = model)) + 
  theme_light() + 
  facet_wrap( ~ location_target, ncol = 2, scales = "free_y") +
  theme(legend.position = "bottom") +
  # geom_rect(aes(xmin = min(forecast_dates$christmas) + 14,
  #               xmax = max(forecast_dates$christmas) + 14,
  #               ymin = 0,
  #               ymax = Inf), fill = "lightgrey", alpha = 0.002) +
  theme(panel.background = element_rect(fill = "#e1f0fe")) +
  scale_y_log10() + 
  scale_x_date(limits = c(min(forecast_dates$full_hub_period) + 14, 
                          max(forecast_dates$full_hub_period)))
  return(p)
}

# create plots for all horizons ------------------------------------------------
for (i in 1:4) {
  scores_over_time_case <- pairwise[horizon == i & target_type == "case"] %>%
    scores_over_time_plot() + 
    scale_color_manual(values = brewer.pal(name = "Accent", n = 5)[-2]) + 
    labs(y = "WIS rel. to baseline", x = "")
  
  ggsave(here("analysis", "plots", paste0("score-over-time-cases-", i, ".png")), 
         plot = scores_over_time_case)
  
  saveRDS(scores_over_time_case, 
          here("analysis", "plots", paste0("score-over-time-cases-", i, ".RDS")))
  
  scores_over_time_deaths <- pairwise[horizon == i & target_type == "death"] %>%
    scores_over_time_plot() + 
    scale_color_brewer(palette = "Accent") + 
    annotate('rect', xmin = min(forecast_dates$full_hub_period) + 14,
             xmax = max(forecast_dates$death_not_scored) + 14,
             ymin = 0,
             ymax = Inf, fill = "grey10", alpha = 0.1) + 
    labs(y = "WIS rel. to baseline", x = "Date")
  
  ggsave(here("analysis", "plots", paste0("score-over-time-deaths-", i, ".png")), 
         plot = scores_over_time_deaths)
  
  saveRDS(scores_over_time_deaths, 
          here("analysis", "plots", paste0("score-over-time-deaths-", i, ".RDS")))
  
}
```

### Combine the two plots

```{r fig.height=15, fig.width=10}
horizons <- 1:4

for (horizon in horizons) {
  truth_vs_pred_cases <- readRDS(file = here("analysis", "plots", 
                                             paste0("truth-and-", horizon, 
                                                    "-wk-ahead_cases.RDS")))
  
  truth_vs_pred_deaths <- readRDS(file = here("analysis", "plots", 
                                              paste0("truth-and-", horizon, 
                                                     "-wk-ahead_deaths.RDS")))
  
  scores_over_time_cases <- readRDS(file = here("analysis", "plots", 
                                                paste0("score-over-time-cases-", 
                                                       horizon,".RDS")))
  
  scores_over_time_deaths <- readRDS(file = here("analysis", "plots", 
                                                 paste0("score-over-time-deaths-", 
                                                        horizon,".RDS")))
  
  truth_vs_pred_cases / scores_over_time_cases / truth_vs_pred_deaths / scores_over_time_deaths + 
    plot_layout(guides = "collect") & 
    plot_annotation(tag_levels = 'A') &
    theme(legend.position = 'bottom') 
  
  ggsave(here("analysis", "plots", paste0("figure-forecasts-", horizon, ".png")), width = 10, height = 12)
}


```

**Todo** - [ ] maybe remove baseline from relative skill plot - [ ] maybe rearrange plots - [ ] make plots nicer (legend, maybe point size on the left / remove either points or lines)

------------------------------------------------------------------------

## Summary table with scores

```{r}
# create helper function to make table
make_score_table <- function(scores, 
                             group = TRUE, 
                             full_width = TRUE) {
  # copy data, change names, round column values and reduce to sign. digits
  scores <- as.data.table(scores)
  setnames(scores, 
           old = c("horizon", "model", "target_type", "interval_score", "aem", 
                   "relative_skill", "scaled_rel_skill", "sharpness", 
                   "underprediction", "overprediction", "bias", 
                   "50", "90", "location_target", "target_phase"), 
           new = c("Horizon", "Model", "Target", "WIS", "Abs. error", 
                   "rel. skill", "Skill", "Sharpness", 
                   "Underpred.", "Overpred.", "Bias", 
                   "50%-Cov.", "90%-Cov.", "Target", "Target"), 
           skip_absent = TRUE)
  
  scores <- scores[, lapply(.SD, FUN = function(x) {
    if (is.numeric(x)) {
      return(round(signif(x, 3), 2))
    } else {
      return(x)
    }
  })]
  
  # remove some cols, change column order, sort table and rename horizon
  if (all(c("coverage_deviation", "rel. skill") %in% names(scores))) {
    scores <- scores[, .SD,  .SDcols = !c("coverage_deviation", "rel. skill")]
  }

  if ("WIS" %in% names(scores)) {
    setcolorder(scores, 
                neworder = c("Target", "Horizon", "Model", "WIS"))  
  }
  
  scores <- scores[order(Target, Horizon)]
  scores[, Horizon := paste(Horizon, "wk ahead")]
  
  # calculate where to group rows
  case_rows <- nrow(scores[Target == "case"])

  table <- scores[,!c("Target")] %>%
    kable(format = "html", col.names = c(" ", names(scores)[-(1:2)])) %>% #format = "markdown"
    collapse_rows(columns = 1) %>%
    kable_styling(bootstrap_options = "striped", 
                  full_width = full_width) %>%
    column_spec(1, background = "white")
  
  if (group) {
    table <- table %>%
      pack_rows("Cases", 1, case_rows, indent = FALSE) %>% 
      pack_rows("Deaths", case_rows + 1, nrow(scores), indent = FALSE)
  }
    
  return(table)
}


```

### Create tables
 
```{r }
# create scores ----------------------------------------------------------------
# calculate coverage independently and merge with other scores
coverage <- eval_forecasts(
  filtered_data[model %in% regular_models], 
  summarise_by = c("horizon", "model", "target_type", "range"), 
)[range %in% c(50, 90), 
                   .(model, target_type, coverage, range, horizon)] %>%
  dcast(formula = ... ~ range, value.var = "coverage")

df <- eval_forecasts(
  filtered_data[model %in% regular_models], 
  summarise_by = c("model", "horizon", "target_type"), 
  compute_relative_skill = TRUE, 
  baseline = "Baseline"
) %>%
  merge(coverage, all.x = TRUE, by = c("model", "horizon", "target_type")) 

# tables for 1-2 weeks ahead and 3-4 weeks ahdead
table <- make_score_table(df[horizon <= 2]) 
save_kable(table, file = here("analysis", "plots", "table_scores_2_ahead.png"))

table <- make_score_table(df[horizon > 2]) 
save_kable(table, file = here("analysis", "plots", "table_scores_4_ahead.png"))


```

### Create table for all median ensembles

```{r }
# create scores ----------------------------------------------------------------
# calculate coverage independently and merge with other scores
coverage <- eval_forecasts(
  filtered_data[model %in% ensemble_models[!grepl("mean", ensemble_models)]], 
  summarise_by = c("horizon", "model", "target_type", "range"), 
)[range %in% c(50, 90), 
                   .(model, target_type, coverage, range, horizon)] %>%
  dcast(formula = ... ~ range, value.var = "coverage")

df <- eval_forecasts(
  filtered_data[model %in% ensemble_models[!grepl("mean", ensemble_models)]], 
  summarise_by = c("model", "horizon", "target_type"), 
  compute_relative_skill = TRUE, 
  baseline = "Baseline"
) %>%
  merge(coverage, all.x = TRUE, by = c("model", "horizon", "target_type")) 

# tables for 1-2 weeks ahead and 3-4 weeks ahdead
table <- make_score_table(df[horizon <= 2]) 
save_kable(table, file = here("analysis", "plots", "table_median-ensemble_scores_2_ahead.png"))

table <- make_score_table(df[horizon > 2]) 
save_kable(table, file = here("analysis", "plots", "table_median-ensemble_scores_4_ahead.png"))


```


### Create table for all mean ensembles

```{r }
# create scores ----------------------------------------------------------------
# calculate coverage independently and merge with other scores
coverage <- eval_forecasts(
  filtered_data[model %in% ensemble_models[grepl("mean", ensemble_models)]], 
  summarise_by = c("horizon", "model", "target_type", "range"), 
)[range %in% c(50, 90), 
                   .(model, target_type, coverage, range, horizon)] %>%
  dcast(formula = ... ~ range, value.var = "coverage")

df <- eval_forecasts(
  filtered_data[model %in% ensemble_models[grepl("mean", ensemble_models)]], 
  summarise_by = c("model", "horizon", "target_type"), 
  compute_relative_skill = TRUE, 
  baseline = "Baseline"
) %>%
  merge(coverage, all.x = TRUE, by = c("model", "horizon", "target_type")) 

# tables for 1-2 weeks ahead and 3-4 weeks ahdead
table <- make_score_table(df[horizon <= 2]) 
save_kable(table, file = here("analysis", "plots", "table_mean-ensemble_scores_2_ahead.png"))

table <- make_score_table(df[horizon > 2]) 
save_kable(table, file = here("analysis", "plots", "table_mean-ensemble_scores_4_ahead.png"))


```


```{r}
# calculate median and sd of the WIS -------------------------------------------

df <- eval_forecasts(
  filtered_data[model %in% regular_models], 
  metric = "interval_score",
  summarise_by = c("model", "horizon", "target_type"), 
  sd = TRUE, 
  quantile = 0.5
) 


df <- df[, .(model, horizon, target_type, 
             `WIS - mean` = interval_score, 
             `WIS - median` = interval_score_0.5, 
             `WIS - sd` = interval_score_sd)] %>%
    dcast(... ~ ., value.var = c("WIS - mean", "WIS - median", "WIS - sd"))

setcolorder(df, c("target_type", "horizon", "model"))


table <- df[order(target_type, horizon, model)] %>%
  make_score_table()

save_kable(table, 
           file = here("analysis", "plots", "table-wis-sd-median.png"))

```


```{r}
# calculate percentage differences in performance ------------------------------

df <- eval_forecasts(
  filtered_data[model %in% regular_models], 
  summarise_by = c("model", "horizon", "target_type"), 
  compute_relative_skill = TRUE, 
  baseline = "Hub-ensemble"
)



df <- df %>%
  merge(df[model == "Hub-ensemble", 
           .(horizon, target_type, base_score = interval_score)])
df[, rel_score := (interval_score / base_score) * 100 - 100]
df[, diff_score := interval_score - base_score]
df[, .(horizon, target_type, model, rel_score, scaled_rel_skill, diff_score)][order(target_type, horizon)]


```


### Tables for different phases of the epidemic

```{r fig.height=10, fig.width=5}

coverage <- eval_forecasts(
  filtered_data[model %in% regular_models], 
  summarise_by = c("horizon", "model", "target_type", "target_phase", "range"), 
)[range %in% c(50, 90), 
                   .(model, target_type, coverage, range, target_phase, horizon)] %>%
  dcast(formula = ... ~ range, value.var = "coverage")

df <- eval_forecasts(
  filtered_data[model %in% regular_models], 
  summarise_by = c("model", "horizon", "target_type", "target_phase"), 
  metrics = c("interval_score", "coverage_deviation"),
  sd = TRUE, 
  quantiles = 0.5
) %>%
  merge(coverage, all.x = TRUE, by = c("model", "horizon", "target_phase", "target_type")) 

tables <- list()
table_dfs <- list()
targets <- unique(df$target_phase)

horizons = 2
for (tar in targets) {
  for (i in horizons) {
    name <- paste0(tar, "-", i)
    
    tmp_df <- df[target_phase == tar & horizon == i, 
                 .(model, interval_score, sharpness,
                   target_phase, horizon, 
                   underprediction, overprediction, 
                   `WIS - median` = interval_score_0.5, 
                   `WIS - sd` = interval_score_sd)]
    
    tables[[name]] <- make_score_table(tmp_df, 
                                       group = FALSE, 
                                       full_width = FALSE) %>%
      pack_rows(tar, 1, nrow(tmp_df), indent = FALSE)
    
    save_kable(tables[[name]],
               file = here("analysis", "plots",
                           paste0("table-", gsub(" ", "", name), ".png")))
  }
}

```


### Look at ensemble forecasts

```{r}

models_plot <- c("Crowd forecast", "Hub-ensemble-with-crowd", "Hub-ensemble")

comparison_ensembles <- function(models_to_plot) {
  df <- unfiltered_data[model %in% models_to_plot &
                          quantile %in% c(0.025, 0.25, 0.5, 0.75, 0.975)] %>%
    dcast(... ~ quantile, value.var = "prediction")
  df <- merge(
    df[, c("classification", "speed") := NULL], 
    copy(epitrend)[, forecast_date := NULL], 
    by = c("target_end_date", "location_name", "target_type")
  )
  
  p <- df[grepl(2, target)] %>%
    ggplot(aes(y = `0.5`, x = target_end_date, color = model)) +
    geom_line() + 
    theme_light() + 
    facet_wrap(~ location_target, scales = "free", ncol = 2) + 
    theme(legend.position = "bottom") + 
    theme(panel.background = element_rect(fill = "#e1f0fe")) + 
    scale_x_date(limits = c(min(forecast_dates$full_hub_period) + 14, 
                            max(forecast_dates$full_hub_period)))
  
  return(p)
}

comparison_ensembles(models_plot)


```



------------------------------------------------------------------------

## Analyse distribution of scores

```{r}
scores <- eval_forecasts(
  filtered_data[(model %in% regular_models) & grepl("2", target)], 
  summarise_by = c("model", "target_type", "location_name", "forecast_date", 
                   "target_phase",
                   "location_target", "classification"),
  compute_relative_skill = TRUE, 
  baseline = "Baseline"
) 

scores[, .(sd = sd(interval_score)), by = c("model", "target_type")]

scores[, target_type := paste0(str_to_title(target_type), "s overall")]

# look at variance to check
scores[, .(sd = sd(scaled_rel_skill)), by = c("model")]

distribution_plot <- function(df, x = "scaled_rel_skill") {
  df %>%
    ggplot(aes_string(y = "model", x = x, 
                      group = "model")) + 
    geom_density_ridges(aes(fill = model), 
                                  quantile_lines = TRUE, quantiles = 0.5, 
                                  rel_min_height = 0.01) + 
    geom_vline(aes(xintercept = 1), alpha = 0.4) + 
    scale_fill_manual(values = brewer.pal(name = "Accent", n = 5)[2:5]) + 
    theme(panel.background = element_rect(fill = "#e1f0fe")) +
    theme(legend.position = "bottom") + 
    labs(y = "Scaled relative skill") + 
    scale_x_log10(labels = scales::number_format(accuracy = 0.1))
}

distribution_plot_wis <- function(df, x = "interval_score") {
  df %>%
    ggplot(aes_string(y = "model", x = x, 
                      group = "model", fill = "model")) + 
    geom_density_ridges(aes(fill = model), 
                        quantile_lines = TRUE, quantiles = 0.5, 
                        rel_min_height = 0.005, 
                        scale = 0.95, 
                        jittered_points = TRUE, 
                        position = position_points_jitter(width = 0.05, height = 0),
                        point_size = 1.5, 
                        point_shape = 21,
                        #point_shape = '|',
                        point_alpha = 1, 
                        alpha = 0.7) + 
    geom_density_ridges(quantile_lines=TRUE,
                        quantile_fun=function(x,...) mean(x), 
                        linetype = "dotted", 
                        alpha = 0, 
                        scale = 0.95, 
                        rel_min_height = 0.01) +
    scale_fill_manual(values = brewer.pal(name = "Accent", n = 5)[1:5]) + 
    # scale_color_manual(aesthetics = "point_color", 
    #                    values = brewer.pal(name = "Accent", n = 5)[1:5]) + 
    theme(panel.background = element_rect(fill = "#e1f0fe")) +
    theme(legend.position = "bottom") + 
    labs(y = "Model", x = "Weighted interval score") + 
  scale_x_continuous(labels = scales::label_number(suffix = "k", 
                                                   scale = 1e-3, 
                                                   accuracy = NULL))
}

p_combined <- distribution_plot(df = scores[model != "Baseline"]) + 
  facet_wrap(~ target_type, ncol = 1)

p_combined_wis <- distribution_plot_wis(df = scores, 
                                        x = "interval_score") +
  facet_wrap(~ target_type, ncol = 1, scales = "free") + 
  theme(plot.margin=unit(c(0,0.4,0,0),"cm")) 

p_combined_ae <- distribution_plot_wis(df = scores, 
                                        x = "aem") +
  facet_wrap(~ target_type, ncol = 1, scales = "free_x") 


p <- distribution_plot(df = scores[model != "Baseline"]) + 
  theme(axis.title.y=element_blank(),
        axis.text.y=element_blank(), 
        axis.ticks.y = element_blank()) + 
  facet_wrap(~ location_target, ncol = 2)

p_wis <- distribution_plot_wis(df = scores) + 
  theme(axis.title.y=element_blank(),
        axis.text.y=element_blank(), 
        axis.ticks.y = element_blank()) + 
  facet_wrap(~ location_target, ncol = 2, scale = "free")

p_ae <- distribution_plot_wis(df = scores, x = "aem") + 
  theme(axis.title.y=element_blank(),
        axis.text.y=element_blank(), 
        axis.ticks.y = element_blank()) + 
  facet_wrap(~ location_target, ncol = 2, scale = "free")



```

```{r}
# scores for different phases of the epidemic
scores[, target_phase := factor(target_phase, 
                                levels = str_to_title(c("Cases - decreasing phase", 
                                                        "Cases - unclear phase", 
                                                        "Cases - increasing phase", 
                                                        "Deaths - decreasing phase", 
                                                        "Deaths - unclear phase", 
                                                        "Deaths - increasing phase")))]

scores[, .(target_count = .N), by = c("target_phase")]

p_phases <- distribution_plot(df = scores[model != "Baseline"]) + 
  facet_wrap( ~ target_phase)

p_phases_wis <- distribution_plot_wis(df = scores) + 
  facet_wrap( ~ target_phase, scales = "free_x") 

p_phases_ae <- distribution_plot_wis(df = scores, x = "aem") + 
  facet_wrap( ~ target_phase, scales = "free_x")
  

```

```{r fig.height=10, fig.width=15}

pl <- wrap_plots(p_combined, p, widths = c(1, 2)) / p_phases + 
  plot_layout(guides = "collect") & 
  plot_annotation(tag_levels = 'A') &
  theme(legend.position = 'bottom') 

ggsave("plots/distribution_scores.png", plot = pl, height = 9)



pl_wis <- wrap_plots(p_combined_wis, p_wis, widths = c(1, 2)) / p_phases_wis + 
  plot_layout(guides = "collect") & 
  plot_annotation(tag_levels = 'A') &
  theme(legend.position = 'bottom') 

ggsave("plots/distribution_scores_wis.png", pl_wis, height = 9)

pl_ae <- wrap_plots(p_combined_ae, p_ae, widths = c(1, 2)) / p_phases_wis + 
  plot_layout(guides = "collect") & 
  plot_annotation(tag_levels = 'A') &
  theme(legend.position = 'bottom') 

ggsave("plots/distribution_scores_ae.png", pl_ae, height = 9)

```

*Figure 2. Top: Distribution of the scaled relative skill scores for the different model and forecast targets. The vertical black line represents the baseline model. Models beat the baseline more easily for death forecasts. The renewal model had by far the most variance in terms of its performance, while the crowd forecasting model seems most consistent. Bottom: Distribution of scaled relative skill in different phases of the epidemic. The epidemic was classified as 'increasing', if the forecast point and the two data points before form a monotonically rising line, 'decreasing' if numbers were falling and 'unclear' otherwise. This plot seems like a lot of noise to me, but unsure.*

```{r fig.height=10, fig.width=15}

coverage_tables <- eval_forecasts(
  filtered_data[grepl("2", target)], 
  summarise_by = c("model", "target_phase", "classification", "range"), 
  compute_relative_skill = TRUE, 
  baseline = "Baseline"
)[range %in% c(50, 90), 
                   .(model, target_phase, coverage, classification, range)] %>%
  dcast(formula = ... ~ range, value.var = "coverage")

scores_tables <- eval_forecasts(
  filtered_data[grepl("2", target)], 
  summarise_by = c("model", "target_phase", "classification"), 
  compute_relative_skill = TRUE, 
  baseline = "Baseline"
)

tbl <- scores_tables %>%
  merge(coverage_tables, all.x = TRUE, by = c("model", "target_phase", "classification")) 

 tbl <- tbl[, lapply(.SD, FUN = function(x) {
    if (is.numeric(x)) {
      return(round(signif(x, 3), 2))
    } else {
      return(x)
    }
  })]

tables <- list()
table_dfs <- list()
targets <- unique(tbl$target_phase)

for (tar in targets) {
  tables[[tar]] <- make_score_table(tbl[target_phase == tar])
}

for (tar in targets) {
  table_dfs[[tar]] <- tbl[target_phase == tar, 
                          .("Model" = model, 
                            # "Target" = target_phase,
                            "WIS" = interval_score,
                            # "Rel. skill" = scaled_rel_skill, 
                            "Sharpn." = sharpness, 
                            "Underp.." = underprediction, 
                            "Overp." = overprediction)#, 
                            # "Bias" = bias,
                            # "50%-Cov." = `50`, 
                            # "90%-Cov." = `90`)
                          ]
}


# make plots with tables
library(gridExtra)

tbl_plt <- grid.arrange(tableGrob(table_dfs[[1]]), 
             tableGrob(table_dfs[[2]]), 
             tableGrob(table_dfs[[3]]), 
             tableGrob(table_dfs[[4]]), 
             tableGrob(table_dfs[[5]]), 
             tableGrob(table_dfs[[6]]), 
             nrow = 2) 

tbl_plt <- ggplotify::as.ggplot(tbl_plt)

tbl_plt

ggsave("plots/distribution_scores_table.png")

library(gt)

tbl[, 
    .("Model" = model, 
      "Target" = target_phase,
      "WIS" = interval_score,
      # "Rel. skill" = scaled_rel_skill, 
      "Sharpn." = sharpness, 
      "Underp.." = underprediction, 
      "Overp." = overprediction)#, 
    # "Bias" = bias,
    # "50%-Cov." = `50`, 
    # "90%-Cov." = `90`)
] %>%
  gt(rowname_col = "Model", 
     groupname_col = "Target") 



```

------------------------------------------------------------------------

## WIS contributions

```{r}
# df <- data[grepl("2", target)] %>%
#   merge(epitrend, 
#         by = c("target_end_date", "location_name", "target_type"))

scores_target <- eval_forecasts(
  filtered_data, 
  summarise_by = c("model", "target_type", "classification"), 
  compute_relative_skill = TRUE
) 

scores_target[, target_phase := paste0(target_type, "s - ", 
                                       classification, " phase")]

wis_components(scores_target, 
               facet_formula = ~ target_phase, 
               scales = "free_x", 
               relative_contributions = TRUE,
               x_text_angle = 0) + 
  theme(legend.position = "bottom") + 
  coord_flip() + 
  labs(x = NULL)

ggsave(here("analysis", "plots", "wis-components.png"))
  
```

*Figure 3. Relative contributions of sharpness, overprediction and underprediction to the weighted interval scores. Models overpredict in a decreasing phase and underpredict in a decreasing phase. So far so obvious. Somehow adding inflection points would be really cool - maybe stratify according to "decreasing, but inflection afterwards etc.?". Apparently the baseline model is really good in an unclear phase, just much too uncertain?.*

------------------------------------------------------------------------

```{r, eval = TRUE}
scores <- eval_forecasts(
  filtered_data, 
  summarise_by = c("model", "target_type", "location_name", "horizon"), 
  compute_relative_skill = TRUE, 
  baseline = "Baseline"
)

scores %>%
  ggplot(aes(y = interval_score, x = horizon, color = model, 
             group = model)) + 
  geom_point() + 
  geom_line() + 
  theme(panel.background = element_rect(fill = "#e1f0fe")) +
  scale_color_brewer(palette = "Accent") + 
  scale_y_log10() + 
  facet_grid(target_type ~ location_name, scales = "free") + 
  theme(legend.position = "bottom")

```

```{r, eval = TRUE}
scores_full <- eval_forecasts(
  filtered_data, 
  summarise_by = c("model", "location_target", "horizon", "forecast_date"), 
  compute_relative_skill = FALSE, 
  baseline = "Baseline"
)

means <- scores_full[, .(meanval = mean(interval_score), 
                         medianval = median(interval_score)), 
                     by =c("model", "location_target", "horizon")]

scores_full %>%
  ggplot(aes(y = interval_score, x = horizon, 
             fill = model, color = model)) +
  geom_boxplot(outlier.shape = 21, coef = 1.5, 
               width=0.5, alpha = 1, 
               position = position_dodge2(width = 0.5)) + 
  # geom_line(data = means, 
  #           aes(group = model, y = meanval, color = model), 
  #           position = position_dodge2(width = 0.5), 
  #           size = 2) +
  theme(panel.background = element_rect(fill = "#e1f0fe")) +
  scale_color_brewer(palette = "Accent") + 
  geom_point(data = means, 
             mapping = aes(y = meanval, fill = model),
             color = "black",
             # fill = "red",
             shape = 21,
             size = 2,
             position = position_dodge2(width = 0.5)) + 
    geom_point(data = means, 
             mapping = aes(y = medianval, fill = model),
             color = "black",
             # fill = "red",
             shape = 22,
             size = 2,
             position = position_dodge2(width = 0.5)) + 
  scale_fill_brewer(palette = "Accent") + 
  scale_y_log10() + 
  facet_wrap( ~ location_target, scales = "free") + 
  theme(legend.position = "bottom")

ggsave("plots/scores_horizons.png")

```

------------------------------------------------------------------------

## Calibration

```{r, eval = TRUE}
# df <- data[grepl("2", target)] %>%
#   merge(epitrend, 
#         by = c("target_end_date", "location_name", "target_type"))

scores_target <- eval_forecasts(
  filtered_data, 
  summarise_by = c("model", "target_type", "classification", "range", "quantile"), 
  compute_relative_skill = FALSE, 
  pit_plots = TRUE
) 

interval_coverage(scores_target, 
                  facet_formula = ~ target_type + classification)

```

*Figure 4: Comparison of nominal and empirical coverage (percentage of true observed values covered by a given prediction interval). The one thing I find interesting about this plot is that models are apparently much too confident when there is an increasing trend. I feel this is probably actionable advice (even though it could probably be made better using a separate analysis about optimal uncertainty that is beyond the scope of this paper).*

**Todo**

-   maybe make this a PIT plot

------------------------------------------------------------------------

## Supplementary Material

### Look at the effect of data exclusions

-   look at first period, second period etc

```{r, eval = FALSE}
scores <- list()
# scores for restricted data set
scores_full <- eval_forecasts(filtered_data, 
                              summarise_by = c("model", "target_type", "target"), 
                              compute_relative_skill = TRUE, 
                              baseline = "Baseline")

scores[["full"]] <- 
  scores_full[, .(model, target_type, scaled_rel_skill, interval_score, target,
                  scenario = "full")]

res <- rbindlist(scores)
res %>%
  ggplot(aes(x = scenario, y = scaled_rel_skill, color = model, group = model)) + 
  geom_point() + 
  facet_wrap( ~ target, scales = "free", ncol = 2) + 
  theme(legend.position = "bottom")
```

<!-- **Further things we could look at** -->

<!-- - maybe look at correlation between the number of weekly cases and the score? -->

<!-- - maybe it would be interesting to look at other baseline models, e.g. "how hard is it to beat a model that just always continues the trend?" -->

<!-- - look at crowd performance as a function of the number of forecasts -->

maybe leave that to a second paper --\>

## Number of expert forecasters

```{r num-forecasters, results = 'asis'}
dt <- crowdforecast_data[!(model %in% c("Crowd-Rt-Forecast",
                                        "EpiNow2_secondary", 
                                        "EpiExpert-ensemble", 
                                        "EpiNow2")), 
                         .(`number of forecasters` = length(unique(model))), , 
                         by = c("forecast_date", "location_name", "target_type")
][order(forecast_date)][
  !is.na(forecast_date)]


dt[, .(sd = sd(`number of forecasters`), 
                             mean = mean(`number of forecasters`), 
                             min  = min(`number of forecasters`), 
                             max = max(`number of forecasters`), 
                             median = median(`number of forecasters`)), 
   by = c("location_name", "target_type")] 



```

```{r num-forecasters2, results = 'asis'}
dt <- crowdforecast_data[!(model %in% c("Crowd-Rt-Forecast",
                                        "EpiNow2_secondary", 
                                        "EpiExpert-ensemble", 
                                        "EpiNow2")), 
                         .(`number of forecasters` = length(unique(model))), , 
                         by = c("forecast_date", "location_name", "target_type")
][order(forecast_date)][
  !is.na(forecast_date)]

dt %>%
  ggplot(aes(y = `number of forecasters`, x = forecast_date)) + 
  geom_line() + 
  facet_wrap(location_name ~ target_type)

```

```{r, results = 'asis'}
dt <- crowdforecast_data[!(model %in% c("Crowd-Rt-Forecast",
                                        "EpiNow2_secondary", 
                                        "EpiExpert-ensemble", 
                                        "EpiNow2")) & forecast_date %in% forecast_dates$unfiltered]

num_fc <- dt[, .(n_forecasts = length(unique(forecast_date))),
             by = c("model")][order(n_forecasts)]

median(num_fc$n_forecasts)
mean(num_fc$n_forecasts)

num_fc %>%
  ggplot(aes(x = n_forecasts)) + 
  geom_bar() + 
  theme_light() + 
  labs(x = "Number of available submissions", 
       y = "Number of forecasters") 

ggsave("plots/crowdforecast_regularity.png")

```

## Number of expert forecasters

```{r, results = 'asis'}

dt <- crowdforecast_data[!(model %in% c("Crowd-Rt-Forecast",
                                        "EpiNow2_secondary", 
                                        "EpiNow2")) & forecast_date %in% forecast_dates$unfiltered]

crowddata <- merge_pred_and_obs(dt, truth_data)

scores <- eval_forecasts(
  data = crowddata[grepl("2", target)],
  summarise_by = c("model", "target_type"), 
  compute_relative_skill = TRUE, 
  baseline = "EpiExpert-ensemble"
)

plot_df <- merge(num_fc, scores, by = "model")

plot_df %>%
  ggplot(aes(y = scaled_rel_skill, x = n_forecasts)) + 
  geom_point() + 
  theme_light() + 
  facet_wrap(~ target_type) + 
  labs(y = "Scaled relative skill", x = "Number of available submissions") + 
  geom_smooth(method='lm', formula= y~x)

ggsave("plots/skill-vs-forecast-freq.png")


```
