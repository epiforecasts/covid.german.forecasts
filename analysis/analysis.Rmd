---
title: "Analysis paper"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)
options(knitr.kable.NA = '')
library(here)
library(magrittr)
library(scoringutils)
library(knitr)
library(kableExtra)
library(data.table)
library(ggplot2)
library(ggridges)
library(RColorBrewer)
library(patchwork)
library(stringr)
library(covid.german.forecasts)
library(grates)
library(ggdist)
library(ggthemes)
library(scales)
library(dplyr)

# define colors for deaths and cases
colcases <- brewer.pal(name = "Accent", n = 8)[-c(1, 4)]
coldeaths <- brewer.pal(name = "Accent", n = 8)[-4]

# colcases <- few_pal()(4)[-1]
# coldeaths <- few_pal()(4)


```

--------------------------------------------------------------------------------
## Plot with Visualsiation of daily data

```{r}
dailytruth_data %>%
  dplyr::filter(target_end_date >= min(forecast_dates$full_hub_period), 
                target_end_date <= max(forecast_dates$full_hub_period)) %>%
  ggplot(aes(y = true_value, x = target_end_date)) + 
  geom_point(size = 0.3, alpha = 0.4) + 
  geom_line(size = 0.5, alpha = 0.4) + 
  geom_line(data = truth_data, aes(y = true_value / 7)) + 
  facet_grid(target_type ~ location_name, scales = "free") + 
  labs(y = "Observed values", x = "Date") + 
  scale_x_date(limits = c(min(forecast_dates$full_hub_period) - 28, 
                            max(forecast_dates$full_hub_period))) + 
  theme_minimal()

ggsave(here("analysis", "plots", "daily_truth.png"))
```

--------------------------------------------------------------------------------
## Plot with Visualsiation of x week ahead forecasts and scores

```{r truth-vs-forecasts, fig.height=12, fig.width=15}

# create helper functions for the plot 
# ------------------------------------------------------------------------------
# truth_and_pred_plot = helper function for the visualisation truth and forecast
# scores_over_time_plot = helper function for plotting scores over time
# forecasts_and_scores = function that organises creation of the plots

truth_and_pred_plot <- function(df, ttype = "case") {
  
  setnames(df, old = c("model"), new = c("Model"))
  
  trend <- 
    copy(epitrend)[, location_target := paste0(str_to_sentence(target_type), 
                                               "s", " in ", location_name)]
  setnames(trend, old = c("classification"), new = c("Classification"))
  p <- df %>%
    dplyr::filter(target_type == ttype) %>%
    ggplot(aes(y = true_value, x = target_end_date)) + 
    geom_linerange(aes(ymin = `0.25`, ymax = `0.75`, color = Model), 
                   size = 1.4,
                   alpha = 1,
                   position = position_dodge(width = 4.6)) + 
    geom_point(data = trend[target_type == ttype],
               aes(shape = Classification)) +
    geom_line(data = unfiltered_data[target_type == ttype & horizon == 2]) + 
    theme_minimal() + 
    facet_wrap(~ location_target, scales = "free", ncol = 2) + 
    theme(legend.position = "bottom") + 
    scale_x_date(limits = c(min(forecast_dates$full_hub_period) + 5, 
                            max(forecast_dates$full_hub_period)))
  return(p)
}

scores_over_time_plot <- function(scores, y = "mean_scores_ratio") {
  p <- scores %>%
    ggplot(aes(x = as.Date(target_end_date), y = get(y))) + 
    geom_line(aes(colour = model)) + 
    geom_point(aes(colour = model, shape = classification)) + 
    theme_minimal() + 
    facet_wrap( ~ location_target, ncol = 2, scales = "free_y") +
    theme(legend.position = "bottom") +
    scale_y_continuous(labels = comma) + # , 
                       # trans = log_trans()) +
    scale_x_date(limits = c(min(forecast_dates$full_hub_period) + 5, 
                            max(forecast_dates$full_hub_period)))
  return(p)
}

forecasts_and_scores <- function(data, 
                                 output_dir = here("analysis", "plots"), 
                                 plotname = "figure-forecasts", 
                                 ensembles = FALSE) {
  
  if (ensembles) {
    colcases <- c(colcases[1:2], colcases[4], colcases[3])
    coldeaths <- colcases
  }
  
  # create data.frame for plotting predictions ---------------------------------
  df <- data[quantile %in% c(0.025, 0.25, 0.5, 0.75, 0.975)] %>%
    dcast(... ~ quantile, value.var = "prediction")
  df <- merge(
    df[, c("classification", "speed") := NULL], 
    copy(epitrend)[, c("forecast_date", "true_value") := NULL], 
    by = c("target_end_date", "location_name", "target_type")
  )
  
  # create data.frame for plotting scores --------------------------------------
  summarise_by <- c("model", "horizon", "location_name", "target_type", 
                    "forecast_date", "target_end_date", "location_target")
  
  scores_target_forecastdate <- eval_forecasts(
    data = data,
    summarise_by = summarise_by
  )[, forecast_date := as.Date(forecast_date)]
  
  # copy epitrend data.frame and only keep necessary columns
  epi_tmp <- copy(epitrend)
  epi_tmp[, forecast_date := (as.Date(forecast_date))]
  epi_tmp <- 
    epi_tmp[, .(location_name, forecast_date, classification, target_type)] %>% 
    unique()
  
  # create plots for all horizons ----------------------------------------------
  for (i in 1:4) {
    
    # truth plot for cases 
    truth_vs_forecast_cases <- df[grepl(i, target)] %>%
      truth_and_pred_plot(ttype = "case") + 
      scale_color_manual(values = colcases) + 
      labs(y = "Cases", x = "") 
    
    # truth plot for deaths
    truth_vs_forecast_deaths <- df[grepl(i, target)] %>%
      truth_and_pred_plot(ttype = "death")  + 
      scale_color_manual(values = coldeaths) + 
      annotate('rect', xmin = min(forecast_dates$full_hub_period) + 14,
               xmax = max(forecast_dates$death_not_scored) + 14,
               ymin = 0,
               ymax = Inf, fill = "grey10", alpha = 0.1) + 
      labs(y = "Deaths", x = "") +
      theme(legend.position = "none") + 
      guides(color = "none", shape = "none")
    
    # scores plot for cases
    scores_over_time_cases <- 
      scores_target_forecastdate[horizon == i & target_type == "case"] %>%
      merge(epi_tmp) %>%
      scores_over_time_plot(y = "interval_score") + 
      scale_color_manual(values = colcases) + 
      labs(y = "WIS", x = "") + 
      theme(legend.position = "none") + 
      guides(color = "none", shape = "none")

  
    # scores plot for deaths
    scores_over_time_deaths <- 
      scores_target_forecastdate[horizon == i & target_type == "death"] %>%
      merge(epi_tmp) %>%
      scores_over_time_plot(y = "interval_score") + 
      scale_color_manual(values = coldeaths) + 
      annotate('rect', xmin = min(forecast_dates$full_hub_period) + 14,
               xmax = max(forecast_dates$death_not_scored) + 14,
               ymin = 0,
               ymax = Inf, fill = "grey10", alpha = 0.1) + 
      labs(y = "WIS", x = "Date") + 
      theme(legend.position = "none") + 
      guides(color = "none", shape = "none")

    
    # putting them all together
    truth_vs_forecast_cases / scores_over_time_cases / 
      truth_vs_forecast_deaths / scores_over_time_deaths + 
      plot_layout(guides = "collect") & 
      # guides(fill = "guidetitle") &
      plot_annotation(tag_levels = 'A') &
      theme(legend.position = 'bottom') 
    
    ggsave(here(output_dir, 
                paste0(plotname, "-", i, ".png")), width = 10, height = 12)
    
  }
}


# create plots -----------------------------------------------------------------
# regular forecasts
unfiltered_data[model %in% regular_models] %>%
  forecasts_and_scores()
  

# ensemble variants
models <- c("Hub-ensemble-all", "Crowd forecast", "Hub-ensemble", "Renewal")
unfiltered_data[model %in% models] %>%
  forecasts_and_scores(plotname = "figure-forecasts-ensembles", 
                       ensembles = TRUE)

```


--------------------------------------------------------------------------------
### alternative visualisation of forecasts

not yet done

```{r}
scores_over_time_plot_components <- function(scores) {
  
size = 1.8
width = 4

scores %>%
  ggplot(aes(x = forecast_date, 
             group = model, 
             color = model)) + 
  
  geom_linerange(aes(ymin = -0.5*sharpness, ymax = 0.5 * sharpness, alpha = "Sharpness"), 
                 size = size,
                 alpha = 1,
                 position = position_dodge(width = width)) + 
  
  geom_linerange(aes(ymax = -0.5 * sharpness, ymin = -0.5* sharpness - underprediction),
                 size = size,
                 position = position_dodge(width = width)) + 
  geom_linerange(aes(ymax = -0.5 * sharpness, ymin = -0.5* sharpness - underprediction),
                 size = size,
                 colour = "white",
                 size = size - 0.6,
                 alpha = 0.6,
                 position = position_dodge(width = width)) + 
  geom_linerange(aes(ymin = 0.5 * sharpness, ymax = 0.5* sharpness + overprediction),
                 size = size,
                 position = position_dodge(width = width)) + 
  geom_linerange(aes(ymin = 0.5 * sharpness, ymax = 0.5* sharpness + overprediction),
                 size = size,
                 colour = "white",
                 size = size - 0.6,
                 alpha = 0.6,
                 position = position_dodge(width = width)) + 
  theme_minimal() + 
  scale_x_date(limits = c(min(forecast_dates$full_hub_period) + 5, 
                          max(forecast_dates$full_hub_period)))


}

# scores_target_forecastdate[horizon == i & target_type == "case"] %>%
#   scores_over_time_plot_components() + 
#   scale_color_manual(values = colcases) + 
#   labs(y = "WIS rel. to baseline", x = "")


```


--------------------------------------------------------------------------------
## Summary tables



```{r}

# create helper function to make table
# ------------------------------------------------------------------------------
score_table <- function(scores, 
                             group = TRUE, 
                             full_width = TRUE) {
  # copy data, change names, round column values and reduce to sign. digits
  scores <- as.data.table(scores)
  setnames(scores, 
           old = c("horizon", "model", "target_type", "interval_score", "aem", 
                   "relative_skill", "scaled_rel_skill", "sharpness", 
                   "underprediction", "overprediction", "bias", 
                   "50", "90", "location_target", "target_phase"), 
           new = c("Horizon", "Model", "Target", "WIS", "Abs. error", 
                   "rel. skill", "WIS - rel.", "Sharpness", 
                   "Underpred.", "Overpred.", "Bias", 
                   "50%-Cov.", "90%-Cov.", "Target", "Target"), 
           skip_absent = TRUE)
  
  # remove some cols, change column order, sort table and rename horizon
  if (all(c("coverage_deviation", "rel. skill") %in% names(scores))) {
    scores <- scores[, .SD,  .SDcols = !c("coverage_deviation", "rel. skill")]
  }

  if (all(c("WIS", "Horizon") %in% names(scores))) {
    wis <- names(scores)[grepl("WIS", names(scores))]
    setcolorder(scores, 
                neworder = c("Target", "Horizon", "Model", wis))  
  }
  
  if ("Horizon" %in% names(scores)) {
    scores <- scores[order(Target, Horizon)]
    scores[, Horizon := paste(Horizon, "wk ahead")]
  }

  
  # calculate where to group rows
  case_rows <- nrow(scores[Target == "case"])

  table <- scores[,!c("Target")] %>%
    kable(format = "html", col.names = c(" ", names(scores)[-(1:2)])) %>% #format = "markdown"
    collapse_rows(columns = 1) %>%
    kable_styling(bootstrap_options = "striped", 
                  full_width = full_width) %>%
    column_spec(1, background = "white")
  
  if (group) {
    table <- table %>%
      pack_rows("Cases", 1, case_rows, indent = FALSE) %>% 
      pack_rows("Deaths", case_rows + 1, nrow(scores), indent = FALSE)
  }
    
  return(table)
}


make_table <- function(data, 
                       plotname = "table_scores",
                       output_dir = here("analysis", "plots")) {
  
  coverage <- eval_forecasts(
    data = data, 
    summarise_by = c("horizon", "model", "target_type", "range"), 
  )[range %in% c(50, 90), 
    .(model, target_type, coverage, range, horizon)] %>%
    dcast(formula = ... ~ range, value.var = "coverage")
  
  df <- eval_forecasts(
    data, 
    summarise_by = c("model", "horizon", "target_type"), 
    compute_relative_skill = FALSE,
    sd = TRUE, 
    quantiles = 0.5) %>%
    merge(coverage, all.x = TRUE, by = c("model", "horizon", "target_type")) 
  
  # round digits
  df <- df[, lapply(.SD, FUN = function(x) {
    if (is.numeric(x)) {
      return(round(signif(x, 3), 2))
    } else {
      return(x)
    }
  })]
  
  percentage_cols <- c("interval_score", "interval_score_0.5", 
                       "interval_score_sd", "sharpness", "underprediction", 
                       "overprediction", "aem")
  
  # no idea how to do that in data.table: 
  df <- df %>%
    dplyr::group_by(horizon, target_type) %>%
    dplyr::mutate_at(percentage_cols, ~ paste0(., " (", 
                                               round(100 * ./.[model == "Hub-ensemble"]), 
                                               "%)"))
  
  setDT(df)
  
  del_cols <- names(df)[(grepl("_sd", names(df)) | grepl("0.5", names(df))) &
                          !(grepl("interval", names(df)))]
  del_cols <- c(del_cols, "coverage_deviation")
  df[, (del_cols) := NULL] 
  
  setnames(df, old = c("interval_score_0.5", "interval_score_sd"), 
           new = c("WIS - median", 
                   "WIS - sd"))

  # tables for 1-2 weeks ahead and 3-4 weeks ahdead
  table <- score_table(df[horizon <= 2]) 
  save_kable(table, file = here(output_dir, 
                                paste0(plotname, "_", 2, "_ahead.png")))
  
  table <- score_table(df[horizon > 2]) 
  save_kable(table, file = here(output_dir, 
                                paste0(plotname, "_", 4, "_ahead.png")))
}



# create tables
# ------------------------------------------------------------------------------

filtered_data[model %in% regular_models] %>%
  make_table()

filtered_data[model %in% ensemble_models[grepl("mean", ensemble_models)]] %>%
  make_table(plotname = "table_mean-ensemble_scores")

filtered_data[model %in% ensemble_models[!grepl("mean", ensemble_models)]] %>%
  make_table(plotname = "table_median-ensemble_scores")









```



```{r}
# # calculate median and sd of the WIS -------------------------------------------
# 
# df <- eval_forecasts(
#   filtered_data[model %in% regular_models], 
#   metric = "interval_score",
#   summarise_by = c("model", "horizon", "target_type"), 
#   sd = TRUE, 
#   quantile = 0.5
# ) 
# 
# 
# df <- df[, .(model, horizon, target_type, 
#              `WIS - mean` = interval_score, 
#              `WIS - median` = interval_score_0.5, 
#              `WIS - sd` = interval_score_sd)] %>%
#     dcast(... ~ ., value.var = c("WIS - mean", "WIS - median", "WIS - sd"))
# 
# setcolorder(df, c("target_type", "horizon", "model"))
# 
# 
# table <- df[order(target_type, horizon, model)] %>%
#   score_table()
# 
# save_kable(table, 
#            file = here("analysis", "plots", "table-wis-sd-median.png"))

```


```{r}
# calculate percentage differences in performance ------------------------------

df <- eval_forecasts(
  filtered_data, 
  summarise_by = c("model", "horizon", "target_type")
)



df <- df %>%
  merge(df[model == "Hub-ensemble", 
           .(horizon, target_type, base_score = interval_score)])
df[, rel_score := (interval_score / base_score) * 100 - 100]
df[, diff_score := interval_score - base_score]
df[, .(horizon, target_type, model, rel_score, diff_score)][order(target_type, horizon)]


```

### Tables for different phases of the epidemic

```{r fig.height=10, fig.width=5}

coverage <- eval_forecasts(
  filtered_data[model %in% regular_models], 
  summarise_by = c("horizon", "model", "target_type", "target_phase", "range"), 
)[range %in% c(50, 90), 
                   .(model, target_type, coverage, range, target_phase, horizon)] %>%
  dcast(formula = ... ~ range, value.var = "coverage")

df <- eval_forecasts(
  filtered_data[model %in% regular_models], 
  summarise_by = c("model", "horizon", "target_type", "target_phase"), 
  metrics = c("interval_score", "coverage_deviation"),
  sd = TRUE, 
  quantiles = 0.5
) %>%
  merge(coverage, all.x = TRUE, by = c("model", "horizon", "target_phase", "target_type")) 

del_cols <- names(df)[(grepl("_sd", names(df)) | grepl("0.5", names(df))) &
                        !(grepl("interval", names(df)))]
del_cols <- c(del_cols, "coverage_deviation")
df[, (del_cols) := NULL]

setnames(df, old = c("interval_score_0.5", "interval_score_sd"), 
         new = c("WIS - median", 
                 "WIS - sd"))

tables <- list()
table_dfs <- list()
targets <- unique(df$target_phase)

# for horizon <= 2
labels <- df[horizon <= 2][order(target_phase, horizon)]$target_phase
table <- score_table(df[horizon <= 2, !"target_type"], group = FALSE) %>%
  pack_rows(index = table(labels), indent = FALSE)
save_kable(table, 
           file = here("analysis", "plots", "table-phases-2.png"))

# for horizon > 2
labels <- df[horizon > 2][order(target_phase, horizon)]$target_phase
table <- score_table(df[horizon > 2, !"target_type"], group = FALSE) %>%
  pack_rows(index = table(labels), indent = FALSE)
save_kable(table, 
           file = here("analysis", "plots", "table-phases-4.png"))


# 
# horizons = 2
# for (tar in targets) {
#   for (i in horizons) {
#     name <- paste0(tar, "-", i)
#     
#     tmp_df <- df[target_phase == tar & horizon == i, 
#                  .(model, interval_score, sharpness,
#                    target_phase, horizon, 
#                    underprediction, overprediction, 
#                    `WIS - median` = interval_score_0.5, 
#                    `WIS - sd` = interval_score_sd)]
#     
#     tables[[name]] <- score_table(tmp_df, 
#                                        group = FALSE, 
#                                        full_width = FALSE) %>%
#       pack_rows(tar, 1, nrow(tmp_df), indent = FALSE)
#     
#     save_kable(tables[[name]],
#                file = here("analysis", "plots",
#                            paste0("table-", gsub(" ", "", name), ".png")))
#   }
# }

```


### Look at ensemble forecasts

#### Number of members in the ensemble
```{r}
ens <- ensemble_members %>%
  melt(id.vars = c("Date", "model"))

epinow2_included <- ens[model == "epiforecasts-EpiNow2", "epinow" := value]
crowd_included <- ens[model == "epiforecasts-EpiExpert", "crowd" := value]



p <- ens[, .(value = sum(value), 
             epinow = sum(epinow, na.rm = TRUE), 
             crowd = sum(crowd, na.rm = TRUE)), by = c("variable", "Date")] %>%
  ggplot(aes(y = value, x = Date, color = variable)) + 
  geom_point()

ggsave(here("analysis", "plots", "ensemble-members.png"), 
       plot = p)
  

```


### Comparing ensembles with and without a model

```{r}

comparison_ensembles <- function(models_to_plot) {
  df <- unfiltered_data[model %in% models_to_plot &
                          quantile %in% c(0.025, 0.25, 0.5, 0.75, 0.975)] %>%
    dcast(... ~ quantile, value.var = "prediction")
  df <- merge(
    df[, c("classification", "speed") := NULL], 
    copy(epitrend)[, c("forecast_date", "true_value") := NULL], 
    by = c("target_end_date", "location_name", "target_type")
  )
  
  p <- df[grepl(2, target)] %>%
    ggplot(aes(y = `0.5`, x = target_end_date, color = model)) +
    geom_line() +
    geom_line(aes(y = true_value), color = "black") + 
    theme_minimal() + 
    facet_wrap(~ location_target, scales = "free", ncol = 2) + 
    theme(legend.position = "bottom") + 
    # theme(panel.background = element_rect(fill = "#e1f0fe")) + 
    scale_x_date(limits = c(min(forecast_dates$full_hub_period) + 14, 
                            max(forecast_dates$full_hub_period))) + 
    labs(y = "Median forecast", x = "Date")
  return(p)
}

models_plot <- c("Crowd forecast", "Hub-ensemble-with-crowd", "Hub-ensemble")
p <- comparison_ensembles(models_plot)
ggsave(here("analysis", "plots", "ensemble-with-and-without-crowd.png"), 
       plot = p)

models_plot <- c("Renewal", "Hub-ensemble-with-renewal", "Hub-ensemble")
p <- comparison_ensembles(models_plot)
ggsave(here("analysis", "plots", "ensemble-with-and-without-renewal.png"), 
       plot = p)

models_plot <- c("Renewal", "Crowd forecast", "Hub-ensemble-all", "Hub-ensemble")
p <- comparison_ensembles(models_plot)
ggsave(here("analysis", "plots", "ensemble-with-and-without-both.png"), 
       plot = p)

```


------------------------------------------------------------------------

## Analyse distribution of scores

```{r}
scores <- eval_forecasts(
  filtered_data[(model %in% regular_models)], 
  summarise_by = c("model", "target_type", "location_name", "horizon", 
                   "forecast_date", "target_phase",
                   "location_target", "classification"),
  compute_relative_skill = FALSE
) 

scores[, .(sd = sd(interval_score)), by = c("model", "target_type")]

scores[, target_type := paste0(str_to_title(target_type), "s overall")]

# scores for different phases of the epidemic
scores[, target_phase := factor(target_phase, 
                                levels = str_to_title(c("Cases - decreasing phase", 
                                                        "Cases - unclear phase", 
                                                        "Cases - increasing phase", 
                                                        "Deaths - decreasing phase", 
                                                        "Deaths - unclear phase", 
                                                        "Deaths - increasing phase")))]


distribution_plot_wis <- function(df, x = "interval_score") {
  df %>%
    ggplot(aes_string(y = "model", x = x, 
                      group = "model", fill = "model")) + 
    # geom_density_ridges(aes(fill = model, color = NA),
    #                     rel_min_height = 0.005,
    #                     scale = 0.9,
    #                     # jittered_points = TRUE,
    #                     # position = position_points_jitter(width = 0.05, height = 0),
    #                     point_size = 1.5,
    #                     point_shape = 21,
    #                     #point_shape = '|',
    #                     point_alpha = 1,
    #                     alpha = 0.3) +
    ggdist::stat_slab(alpha = 0.3, scale = 0.8, normalize = "panels") +
  # ggridges::geom_density_ridges(aes(color = NA), scale = 1.3) + 
    ggdist::stat_dots(aes(color = model)) + 
    ggdist::stat_pointinterval(point_interval = mean_qi, size = 3, shape = 16, fill = "black", .width = NA) + 
    ggdist::stat_pointinterval(point_interval = median_qi, size = 3, shape = 15, fill = "black", .width = NA) + 
        facet_wrap(~ target_type, ncol = 1, scales = "free") + 
    theme(plot.margin=unit(c(0,0.4,0,0),"cm")) +
    # geom_density_ridges(quantile_lines=TRUE,
    #                     quantile_fun=function(x,...) mean(x), 
    #                     linetype = "dotted", 
    #                     alpha = 0, 
    #                     scale = 0.9, 
    #                     rel_min_height = 0.01) +
    scale_fill_manual(values = coldeaths) + 
    scale_color_manual(values = coldeaths) + 
    # scale_color_manual(aesthetics = "point_color", 
    #                    values = brewer.pal(name = "Accent", n = 5)[1:5]) + 
    # theme(panel.background = element_rect(fill = "#e1f0fe")) +
    theme(legend.position = "bottom") + 
    labs(y = "Model", x = "Weighted interval score") + 
  scale_x_continuous(labels = scales::label_number(suffix = "k", 
                                                   scale = 1e-3, 
                                                   accuracy = NULL)) + 
    theme_minimal()
}


for (i in 1:4) {
  p_combined_wis <- distribution_plot_wis(df = scores[horizon == i], 
                                          x = "interval_score") +
    facet_wrap(~ target_type, ncol = 1, scales = "free") + 
    theme(plot.margin=unit(c(0,0.4,0,0),"cm")) 
  
  p_wis <- distribution_plot_wis(df = scores[horizon == i]) + 
  theme(axis.title.y=element_blank(),
        axis.text.y=element_blank(), 
        axis.ticks.y = element_blank()) + 
  facet_wrap(~ location_target, ncol = 2, scale = "free")
  
  p_phases_wis <- distribution_plot_wis(df = scores[horizon == i]) + 
    facet_wrap( ~ target_phase, scales = "free_x") 

  
  pl_wis <- wrap_plots(p_combined_wis, p_wis, widths = c(1, 2)) / p_phases_wis + 
    plot_layout(guides = "collect") & 
    plot_annotation(tag_levels = 'A') &
    theme(legend.position = 'bottom') 
  
  ggsave(here("analysis", "plots", 
              paste0("distribution_scores_wis-", i, ".png")), 
         pl_wis, height = 11, width = 9)
    
}




p_combined_ae <- distribution_plot_wis(df = scores, 
                                        x = "aem") +
  facet_wrap(~ target_type, ncol = 1, scales = "free_x") 


# p <- distribution_plot(df = scores[model != "Baseline"]) + 
#   theme(axis.title.y=element_blank(),
#         axis.text.y=element_blank(), 
#         axis.ticks.y = element_blank()) + 
#   facet_wrap(~ location_target, ncol = 2)



p_ae <- distribution_plot_wis(df = scores, x = "aem") + 
  theme(axis.title.y=element_blank(),
        axis.text.y=element_blank(), 
        axis.ticks.y = element_blank()) + 
  facet_wrap(~ location_target, ncol = 2, scale = "free")



    

```

```{r}
scores[, .(target_count = .N), by = c("target_phase", "model")]

# p_phases <- distribution_plot(df = scores[model != "Baseline"]) + 
#   facet_wrap( ~ target_phase)


p_phases_ae <- distribution_plot_wis(df = scores, x = "aem") + 
  facet_wrap( ~ target_phase, scales = "free_x")

scores[, .(n = .N), by = "target_phase"]
  

```

```{r fig.height=10, fig.width=15}

# pl <- wrap_plots(p_combined, p, widths = c(1, 2)) / p_phases + 
#   plot_layout(guides = "collect") & 
#   plot_annotation(tag_levels = 'A') &
#   theme(legend.position = 'bottom') 
# 
# ggsave("plots/distribution_scores.png", plot = pl, height = 9)




pl_ae <- wrap_plots(p_combined_ae, p_ae, widths = c(1, 2)) / p_phases_wis + 
  plot_layout(guides = "collect") & 
  plot_annotation(tag_levels = 'A') &
  theme(legend.position = 'bottom') 

ggsave("plots/distribution_scores_ae.png", pl_ae, height = 9)

```

*Figure 2. Top: Distribution of the scaled relative skill scores for the different model and forecast targets. The vertical black line represents the baseline model. Models beat the baseline more easily for death forecasts. The renewal model had by far the most variance in terms of its performance, while the crowd forecasting model seems most consistent. Bottom: Distribution of scaled relative skill in different phases of the epidemic. The epidemic was classified as 'increasing', if the forecast point and the two data points before form a monotonically rising line, 'decreasing' if numbers were falling and 'unclear' otherwise. This plot seems like a lot of noise to me, but unsure.*


```{r fig.height=10, fig.width=15}
# 
# coverage_tables <- eval_forecasts(
#   filtered_data[grepl("2", target)], 
#   summarise_by = c("model", "target_phase", "classification", "range", "horizon"), 
#   compute_relative_skill = TRUE, 
#   baseline = "Baseline"
# )[range %in% c(50, 90), 
#                    .(model, target_phase, coverage, classification, range)] %>%
#   dcast(formula = ... ~ range, value.var = "coverage")
# 
# scores_tables <- eval_forecasts(
#   filtered_data[grepl("2", target)], 
#   summarise_by = c("model", "target_phase", "classification", "horizon"), 
#   compute_relative_skill = TRUE, 
#   baseline = "Baseline"
# )
# 
# tbl <- scores_tables %>%
#   merge(coverage_tables, all.x = TRUE, by = c("model", "target_phase", "classification")) 
# 
#  tbl <- tbl[, lapply(.SD, FUN = function(x) {
#     if (is.numeric(x)) {
#       return(round(signif(x, 3), 2))
#     } else {
#       return(x)
#     }
#   })]
# 
# tables <- list()
# table_dfs <- list()
# targets <- unique(tbl$target_phase)
# 
# for (tar in targets) {
#   tables[[tar]] <- score_table(tbl[target_phase == tar])
# }
# 
# for (tar in targets) {
#   table_dfs[[tar]] <- tbl[target_phase == tar, 
#                           .("Model" = model, 
#                             # "Target" = target_phase,
#                             "WIS" = interval_score,
#                             # "Rel. skill" = scaled_rel_skill, 
#                             "Sharpn." = sharpness, 
#                             "Underp.." = underprediction, 
#                             "Overp." = overprediction)#, 
#                             # "Bias" = bias,
#                             # "50%-Cov." = `50`, 
#                             # "90%-Cov." = `90`)
#                           ]
# }
# 
# 
# # make plots with tables
# library(gridExtra)
# 
# tbl_plt <- grid.arrange(tableGrob(table_dfs[[1]]), 
#              tableGrob(table_dfs[[2]]), 
#              tableGrob(table_dfs[[3]]), 
#              tableGrob(table_dfs[[4]]), 
#              tableGrob(table_dfs[[5]]), 
#              tableGrob(table_dfs[[6]]), 
#              nrow = 2) 
# 
# tbl_plt <- ggplotify::as.ggplot(tbl_plt)
# 
# tbl_plt
# 
# ggsave("plots/distribution_scores_table.png")
# 
# library(gt)
# 
# tbl[, 
#     .("Model" = model, 
#       "Target" = target_phase,
#       "WIS" = interval_score,
#       # "Rel. skill" = scaled_rel_skill, 
#       "Sharpn." = sharpness, 
#       "Underp.." = underprediction, 
#       "Overp." = overprediction)#, 
#     # "Bias" = bias,
#     # "50%-Cov." = `50`, 
#     # "90%-Cov." = `90`)
# ] %>%
#   gt(rowname_col = "Model", 
#      groupname_col = "Target") 
# 


```

------------------------------------------------------------------------

## WIS contributions

```{r}
# df <- data[grepl("2", target)] %>%
#   merge(epitrend, 
#         by = c("target_end_date", "location_name", "target_type"))

scores_target <- eval_forecasts(
  filtered_data[model %in% regular_models], 
  summarise_by = c("model", "target_type", "classification"), 
  compute_relative_skill = TRUE
) 

scores_target[, target_phase := paste0(target_type, "s - ", 
                                       classification, " phase")]

wis_components(scores_target, 
               facet_formula = ~ target_phase, 
               scales = "free_x", 
               relative_contributions = TRUE,
               x_text_angle = 0) + 
  theme(legend.position = "bottom") + 
  coord_flip() + 
  labs(x = NULL)

ggsave(here("analysis", "plots", "wis-components.png"))
  
```

*Figure 3. Relative contributions of sharpness, overprediction and underprediction to the weighted interval scores. Models overpredict in a decreasing phase and underpredict in a decreasing phase. So far so obvious. Somehow adding inflection points would be really cool - maybe stratify according to "decreasing, but inflection afterwards etc.?". Apparently the baseline model is really good in an unclear phase, just much too uncertain?.*


### Distribution of Bias over time

```{r}
# df <- data[grepl("2", target)] %>%
#   merge(epitrend, 
#         by = c("target_end_date", "location_name", "target_type"))

scores_target <- eval_forecasts(
  filtered_data[model %in% regular_models], 
  summarise_by = c("model", "target_type", "classification", "forecast_date")
) 

scores_target[, target_phase := paste0(target_type, "s - ", 
                                       classification, " phase")]


p <- scores_target[model %in% regular_models] %>%
  distribution_plot_wis(x = "bias") + 
  scale_x_continuous() + 
  facet_wrap(~ target_phase, ncol = 3) + 
  geom_vline(xintercept = 0, color = "black", size = 1.4) + 
  labs(y = "Bias")

ggsave(here("analysis", "plots", "distribution_bias_phases.png"), plot = p)
```



```{r, eval = TRUE}
scores_full <- eval_forecasts(
  filtered_data[model %in% regular_models], 
  summarise_by = c("model", "location_target", "horizon", "forecast_date"), 
  compute_relative_skill = FALSE
)

means <- scores_full[, .(meanval = mean(interval_score), 
                         medianval = median(interval_score)), 
                     by =c("model", "location_target", "horizon")]

scores_full %>%
  ggplot(aes(y = interval_score, x = horizon, 
             fill = model, color = model)) +
  geom_boxplot(outlier.shape = 21, coef = 1.5, 
               width=0.5, alpha = 1, 
               position = position_dodge2(width = 0.5)) + 
  # geom_line(data = means, 
  #           aes(group = model, y = meanval, color = model), 
  #           position = position_dodge2(width = 0.5), 
  #           size = 2) +
  # theme(panel.background = element_rect(fill = "#e1f0fe")) +
  scale_color_manual(values = coldeaths) + 
  scale_fill_manual(values = coldeaths) + 
  geom_point(data = means, 
             mapping = aes(y = meanval, fill = model),
             color = "black",
             # fill = "red",
             shape = 21,
             size = 2,
             position = position_dodge2(width = 0.5)) + 
    geom_point(data = means, 
             mapping = aes(y = medianval, fill = model),
             color = "black",
             # fill = "red",
             shape = 22,
             size = 2,
             position = position_dodge2(width = 0.5)) + 
  scale_y_log10() + 
  facet_wrap( ~ location_target, scales = "free") + 
  theme(legend.position = "bottom")

ggsave("plots/scores_horizons.png")

```

------------------------------------------------------------------------

## Calibration

```{r, eval = TRUE}
# df <- data[grepl("2", target)] %>%
#   merge(epitrend, 
#         by = c("target_end_date", "location_name", "target_type"))

scores_target <- eval_forecasts(
  filtered_data[model %in% regular_models], 
  summarise_by = c("model", "target_type", "classification", "range", "quantile"), 
  compute_relative_skill = FALSE, 
  pit_plots = TRUE
) 

interval_coverage(scores_target, 
                  facet_formula = ~ target_type + classification)

```

*Figure 4: Comparison of nominal and empirical coverage (percentage of true observed values covered by a given prediction interval). The one thing I find interesting about this plot is that models are apparently much too confident when there is an increasing trend. I feel this is probably actionable advice (even though it could probably be made better using a separate analysis about optimal uncertainty that is beyond the scope of this paper).*

**Todo**

-   maybe make this a PIT plot

------------------------------------------------------------------------

## Supplementary Material

### Look at the effect of data exclusions

-   look at first period, second period etc

```{r, eval = FALSE}
scores <- list()
# scores for restricted data set
scores_full <- eval_forecasts(filtered_data, 
                              summarise_by = c("model", "target_type", "target"), 
                              compute_relative_skill = TRUE)

scores[["full"]] <- 
  scores_full[, .(model, target_type, scaled_rel_skill, interval_score, target,
                  scenario = "full")]

res <- rbindlist(scores)
res %>%
  ggplot(aes(x = scenario, y = scaled_rel_skill, color = model, group = model)) + 
  geom_point() + 
  facet_wrap( ~ target, scales = "free", ncol = 2) + 
  theme(legend.position = "bottom")
```

<!-- **Further things we could look at** -->

<!-- - maybe look at correlation between the number of weekly cases and the score? -->

<!-- - maybe it would be interesting to look at other baseline models, e.g. "how hard is it to beat a model that just always continues the trend?" -->

<!-- - look at crowd performance as a function of the number of forecasts -->

maybe leave that to a second paper --\>

## Number of expert forecasters

```{r num-forecasters, results = 'asis'}
dt <- crowdforecast_data[!(model %in% c("Crowd-Rt-Forecast",
                                        "EpiNow2_secondary", 
                                        "EpiExpert-ensemble", 
                                        "EpiNow2")), 
                         .(`number of forecasters` = length(unique(model))), , 
                         by = c("forecast_date", "location_name", "target_type")
][order(forecast_date)][
  !is.na(forecast_date)]


dt[, .(sd = sd(`number of forecasters`), 
                             mean = mean(`number of forecasters`), 
                             min  = min(`number of forecasters`), 
                             max = max(`number of forecasters`), 
                             median = median(`number of forecasters`)), 
   by = c("location_name", "target_type")] 



```

```{r num-forecasters2, results = 'asis'}
dt <- crowdforecast_data[!(model %in% c("Crowd-Rt-Forecast",
                                        "EpiNow2_secondary", 
                                        "EpiExpert-ensemble", 
                                        "EpiNow2")), 
                         .(`number of forecasters` = length(unique(model))), , 
                         by = c("forecast_date", "location_name", "target_type")
][order(forecast_date)][
  !is.na(forecast_date)]

dt %>%
  ggplot(aes(y = `number of forecasters`, x = forecast_date)) + 
  geom_line() + 
  facet_wrap(location_name ~ target_type)

```

```{r, results = 'asis'}
dt <- crowdforecast_data[!(model %in% c("Crowd-Rt-Forecast",
                                        "EpiNow2_secondary", 
                                        "EpiExpert-ensemble", 
                                        "EpiNow2")) & forecast_date %in% forecast_dates$unfiltered]

num_fc <- dt[, .(n_forecasts = length(unique(forecast_date))),
             by = c("model")][order(n_forecasts)]

median(num_fc$n_forecasts)
mean(num_fc$n_forecasts)

num_fc %>%
  ggplot(aes(x = n_forecasts)) + 
  geom_bar() + 
  theme_minimal() + 
  labs(x = "Number of available submissions", 
       y = "Number of forecasters") 

ggsave("plots/crowdforecast_regularity.png")

```

## Number of expert forecasters

```{r, results = 'asis'}

dt <- crowdforecast_data[!(model %in% c("Crowd-Rt-Forecast",
                                        "EpiNow2_secondary", 
                                        "EpiNow2")) & forecast_date %in% forecast_dates$unfiltered]

crowddata <- merge_pred_and_obs(dt, truth_data)

scores <- eval_forecasts(
  data = crowddata[grepl("2", target)],
  summarise_by = c("model", "target_type"), 
  compute_relative_skill = TRUE, 
  baseline = "EpiExpert-ensemble"
)

plot_df <- merge(num_fc, scores, by = "model")

plot_df %>%
  ggplot(aes(y = scaled_rel_skill, x = n_forecasts)) + 
  geom_point() + 
  geom_line() + 
  theme_minimal() + 
  facet_wrap(~ target_type) + 
  labs(y = "Scaled relative skill", x = "Number of available submissions") + 
  geom_smooth(method='lm', formula= y~x)

ggsave("plots/skill-vs-forecast-freq.png")


```

### Aggregate performance across different horizons

``` {r}

aggregate_performance <- function(data, 
                                  x = "horizon",
                                  xlabel = "Forecast horizon",
                                  output_dir = here("analysis", "plots"), 
                                  plotname,
                                  relative = FALSE,
                                  facet_formula = ~ target_type) {
  
  scores <- eval_forecasts(data, 
                           summarise_by = c("model", "target_type", x), 
                           quantiles = 0.5, 
                           sd = TRUE)
  
  setnames(scores, old = "model", new = "Model")
  
  plot_helper <- function(tmp = scores, xvar = x, y, rel = relative) {
    if (rel) {
      tmp <- tmp %>%
        arrange(target_type, get(x)) %>%
        group_by(target_type, get(x)) %>%
        mutate_at(y, ~ . - .[Model == "Hub-ensemble"])
    }
    
    tmp %>%
      ggplot(aes_string(x = xvar, y = y, group = "Model", color = "Model")) +
      geom_point() +
      geom_line() +
      facet_wrap(facet_formula, scales = "free_y") +
      theme_minimal() +
      theme(legend.position = "bottom") +
      scale_color_manual(values = coldeaths)
  }
  
  # mean performance
  p_mean <- 
    plot_helper(scores, y = "interval_score") + 
    labs(y = "mean WIS", x = NULL)
  
  # median performance
  p_median <- 
    plot_helper(scores, y = "interval_score_0.5") + 
    labs(y = "median WIS", x = NULL)
  
  # sd of performance
  p_wis_sd <- 
    plot_helper(scores, y = "interval_score_sd") + 
    labs(y = "WIS - sd", x = NULL)
  
  # sharpness of performance
  p_sharpness <- 
    plot_helper(scores, y = "sharpness") + 
    labs(y = "Sharpness", x = NULL)
    
  # absolute error of performance
  p_aem <-
    plot_helper(scores, y = "aem") + 
    labs(y = "Absolute error", x = NULL) 
   
  # bias
  p_bias <- 
    plot_helper(scores, y = "bias") + 
    labs(y = "Bias", x = NULL) +
    geom_hline(yintercept = 0, linetype = "dashed") +
    expand_limits(y=c(-0.2, 0.2)) 
   
  # coverage
  scores <- eval_forecasts(data, 
                           summarise_by = c("model", "target_type", x, "range"), 
                           quantiles = 0.5, 
                           sd = TRUE)
  
  setnames(scores, old = "model", new = "Model")
  
  p_cov50 <- scores[range %in% c(50)] %>%
    plot_helper(y = "coverage") + 
    geom_hline(yintercept = 0.5, linetype = "dashed") +
    labs(y = "Coverage - 50% PI", x = xlabel) + 
    expand_limits(y=c(0, 1)) + 
    scale_y_continuous(labels = scales::percent)
  
  p_cov90 <- scores[range %in% c(90)] %>%
    plot_helper(y = "coverage") + 
    geom_hline(yintercept = 0.5, linetype = "dashed") +
    labs(y = "Coverage - 50% PI", x = xlabel) + 
    expand_limits(y=c(0, 1)) + 
    scale_y_continuous(labels = scales::percent)
  
  p_combined <- (p_mean + p_median) / 
    (p_aem + p_wis_sd) / 
    (p_sharpness + p_bias) / 
    (p_cov50 + p_cov90) +  
    plot_layout(guides = "collect") & 
    plot_annotation(tag_levels = 'A') &
    theme(legend.position = 'bottom') 
  
  ggsave(here(output_dir, paste0(plotname, ".png")), 
         height = 9.1, width = 10)
  
}


filtered_data[model %in% regular_models] %>%
  aggregate_performance(plotname = "aggregate-performance-all")

filtered_data[model %in% regular_models & horizon == 2] %>%
  aggregate_performance(plotname = "aggregate-performance-2-weeks-locations-all", 
                        x = "location_name", 
                        xlabel = NULL)

filtered_data[model %in% ensemble_models[!grepl("mean", ensemble_models)]] %>%
  aggregate_performance(plotname = "aggregate-performance-rel-ensemble", 
                        relative = TRUE)


```




## Plots with all forecasts

```{r}
# only select every second forecast date to stratify
df <- unfiltered_data[model %in% regular_models &
                        quantile %in% c(0.025, 0.25, 0.5, 0.75, 0.975)] %>%
  dcast(... ~ quantile, value.var = "prediction")
df <- merge(
  df[, c("classification", "speed") := NULL], 
  copy(epitrend)[, c("forecast_date", "true_value") := NULL], 
  by = c("target_end_date", "location_name", "target_type")
)

df[, forecast_date := as.Date(forecast_date)]
df[, i := as.numeric(forecast_date - as.Date(min(forecast_date))) %% 2 + 1]

plot_forecast <- function(df, m = "Renewal") {
  min_date <- min(forecast_dates$unfiltered)
  plot_dates <- c((min_date - c(28, 21, 14, 7)), forecast_dates$unfiltered)
  plot_dates <- plot_dates - 2
  d <- copy(truth_data)[, location_target := paste0(str_to_sentence(target_type), 
                                                    "s", " in ", location_name)]
  daily <- copy(dailytruth_data)[, location_target := paste0(str_to_sentence(target_type), 
                                                             "s", " in ", location_name)]
  daily[, week := as_yearweek(target_end_date, firstday = 7L)]
  daily[, sum_val := sum(true_value), by = c("week", "location_target")]
  daily[, scaled_val := true_value - sum_val / 7]
  
  df <- copy(df)[, forecast_date := as.factor(forecast_date)]
  
  df[model == m] %>%
    ggplot(aes(y = true_value, x = target_end_date)) + 
    geom_line() + 
    geom_line(data = d[target_end_date %in% plot_dates],
              aes(y = true_value, x = target_end_date)) +
    geom_line(data = daily[target_end_date >= min(plot_dates) & target_end_date <= max(plot_dates)],
              aes(y = scaled_val, x = target_end_date), alpha = 0.4) +
    geom_vline(aes(xintercept = as.Date(forecast_date), 
                   color = forecast_date), alpha = 0.3, size = 0.4) + 
    ggplot2::geom_ribbon(ggplot2::aes(ymin = `0.025`, ymax = `0.975`, 
                                      group = forecast_date, 
                                      fill = forecast_date), alpha = 0.3) +
    ggplot2::geom_ribbon(ggplot2::aes(ymin = `0.25`, ymax = `0.75`, 
                                      group = forecast_date, 
                                      fill = forecast_date), alpha = 0.5) +
    ggplot2::geom_line(aes(y = `0.5`,group = forecast_date, 
                           colour = forecast_date), alpha = 1) +
    geom_point() + 
    theme_minimal() + 
    facet_grid(location_target ~ i, scale = "free_y") + 
    theme(legend.position = "bottom") 
    # theme(panel.background = element_rect(fill = "#e1f0fe")) + 
    # scale_y_log10() 
}



for (m in c("Renewal", "Convolution", "Crowd forecast")) {
  p <- plot_forecast(df[horizon <= 2], m = m) 
  
  saveRDS(p, file = here("analysis", "plots", 
                         paste0("all-forecasts-", m,".RDS")))
  
  ggsave(here("analysis", "plots", 
                         paste0("all-forecasts-", m,".png")), 
         height = 15, width = 10)
  
}



```

### Plots with overprediction, sharpness etc over time

``` {r}


```

