\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\contentsline {section}{Introduction}{2}{section*.3}\protected@file@percent }
\newlabel{introduction}{{}{2}{Introduction}{section*.3}{}}
\@writefile{toc}{\contentsline {section}{Methods}{3}{section*.4}\protected@file@percent }
\newlabel{methods}{{}{3}{Methods}{section*.4}{}}
\@writefile{toc}{\contentsline {subsection}{Forecast targets and interaction with the German and Polish Forecast Hub}{3}{section*.5}\protected@file@percent }
\newlabel{forecast-targets-and-interaction-with-the-german-and-polish-forecast-hub}{{}{3}{Forecast targets and interaction with the German and Polish Forecast Hub}{section*.5}{}}
\@writefile{toc}{\contentsline {subsection}{Crowd forecasts}{4}{section*.6}\protected@file@percent }
\newlabel{crowd-forecasts}{{}{4}{Crowd forecasts}{section*.6}{}}
\@writefile{toc}{\contentsline {subsection}{Model-based forecasts}{5}{section*.7}\protected@file@percent }
\newlabel{model-based-forecasts}{{}{5}{Model-based forecasts}{section*.7}{}}
\@writefile{toc}{\contentsline {subsection}{Analysis}{5}{section*.8}\protected@file@percent }
\newlabel{analysis}{{}{5}{Analysis}{section*.8}{}}
\@writefile{toc}{\contentsline {section}{Results}{6}{section*.9}\protected@file@percent }
\newlabel{results}{{}{6}{Results}{section*.9}{}}
\@writefile{toc}{\contentsline {subsection}{Crowd forecast participation}{6}{section*.10}\protected@file@percent }
\newlabel{crowd-forecast-participation}{{}{6}{Crowd forecast participation}{section*.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Visualisation of aggregate performance metrics for forecasts one to four weeks into the future. A, B: mean weighted interval score (WIS, lower indicates better performance) across horizons. WIS is decomposed into its components dispersion, over-prediction and under-prediction. C: Empirical coverage of the 50\% prediction intervals (50\% coverage is perfect). D: Empirical coverage of the 90\% prediction intervals. E: Dispersion (same as in panel A, B). Higher values mean greater dispersion of the forecast and imply ceteris paribus a worse score. F: Bias, i.e. general (relative) tendency to over- or underpredict. Values are between -1 (complete under-prediction) and 1 (complete over-prediction) and 0 ideally. G: Absolute error of the median forecast (lower is better). H. Standard deviation of all WIS values for different horizons\relax }}{7}{figure.caption.11}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:agg-performance-all}{{1}{7}{Visualisation of aggregate performance metrics for forecasts one to four weeks into the future. A, B: mean weighted interval score (WIS, lower indicates better performance) across horizons. WIS is decomposed into its components dispersion, over-prediction and under-prediction. C: Empirical coverage of the 50\% prediction intervals (50\% coverage is perfect). D: Empirical coverage of the 90\% prediction intervals. E: Dispersion (same as in panel A, B). Higher values mean greater dispersion of the forecast and imply ceteris paribus a worse score. F: Bias, i.e. general (relative) tendency to over- or underpredict. Values are between -1 (complete under-prediction) and 1 (complete over-prediction) and 0 ideally. G: Absolute error of the median forecast (lower is better). H. Standard deviation of all WIS values for different horizons\relax }{figure.caption.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Two week ahead forecasts and corresponding scores. A, C: Visualisation of 50\% prediction intervals of two week ahead forecasts against the reported values. Forecasts that were not scored (because there was no complete set of death forecasts available) are greyed out. B, D: Visualisation of corresponding WIS.\relax }}{8}{figure.caption.12}\protected@file@percent }
\newlabel{fig:forecasts-and-truth}{{2}{8}{Two week ahead forecasts and corresponding scores. A, C: Visualisation of 50\% prediction intervals of two week ahead forecasts against the reported values. Forecasts that were not scored (because there was no complete set of death forecasts available) are greyed out. B, D: Visualisation of corresponding WIS.\relax }{figure.caption.12}{}}
\@writefile{toc}{\contentsline {subsection}{Case Forecasts}{8}{section*.13}\protected@file@percent }
\newlabel{case-forecasts}{{}{8}{Case Forecasts}{section*.13}{}}
\@writefile{toc}{\contentsline {subsection}{Death Forecasts}{10}{section*.14}\protected@file@percent }
\newlabel{death-forecasts}{{}{10}{Death Forecasts}{section*.14}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Distribution of scores. A: Distribution of weighted interval scores for two week ahead forecasts of the different models and forecast targets. Points denote single forecasts scores, while the shaded area shows an estimated probability density. B: Distribution of WIS separate by country. Black squares indicate median and black circles mean scores.\relax }}{11}{figure.caption.15}\protected@file@percent }
\newlabel{fig:distribution-scores}{{3}{11}{Distribution of scores. A: Distribution of weighted interval scores for two week ahead forecasts of the different models and forecast targets. Points denote single forecasts scores, while the shaded area shows an estimated probability density. B: Distribution of WIS separate by country. Black squares indicate median and black circles mean scores.\relax }{figure.caption.15}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Relative aggregate performance metrics across forecast horizons for different versions of the Hub median ensemble. \begingroup \let \relax \relax \endgroup [Pleaseinsert\PrerenderUnicode{“}intopreamble]Hub-ensemble\begingroup \let \relax \relax \endgroup [Pleaseinsert\PrerenderUnicode{”}intopreamble] extit{excludes} all our models, Hub-ensemble-all extit{includes} all of our models, \begingroup \let \relax \relax \endgroup [Pleaseinsert\PrerenderUnicode{“}intopreamble]Hub-ensemble-realised\begingroup \let \relax \relax \endgroup [Pleaseinsert\PrerenderUnicode{”}intopreamble] is the actual hub-ensemble observed in reality, which includes the renewal model and the crowd forecasts, but not the convolution model. A, B: mean weighted interval score (WIS) across horizons relative to the Hub ensemble (lower values indicate better performance). C, D: Empirical coverage of the 50\% and 90\% prediction intervals minus empirical coverage observed for the Hub ensemble. E: Dispersion relative to the dispersion of the Hub ensemble. Higher values mean greater dispersion of the forecast and imply ceteris paribus a worse score. F: Bias, i.e. general (relative) tendency to over- orunderpredict. Values are between -1 (complete under-prediction) and 1 (complete over-prediction) and 0 ideally. G: Absolute error of the median forecast relative to the Hub ensemble. H. Standard deviation of all WIS values for different horizons relative to the Hub ensemble.\relax }}{12}{figure.caption.16}\protected@file@percent }
\newlabel{fig:agg-performance-ensemble-rel}{{4}{12}{Relative aggregate performance metrics across forecast horizons for different versions of the Hub median ensemble. “Hub-ensemble” extit{excludes} all our models, Hub-ensemble-all extit{includes} all of our models, “Hub-ensemble-realised” is the actual hub-ensemble observed in reality, which includes the renewal model and the crowd forecasts, but not the convolution model. A, B: mean weighted interval score (WIS) across horizons relative to the Hub ensemble (lower values indicate better performance). C, D: Empirical coverage of the 50\% and 90\% prediction intervals minus empirical coverage observed for the Hub ensemble. E: Dispersion relative to the dispersion of the Hub ensemble. Higher values mean greater dispersion of the forecast and imply ceteris paribus a worse score. F: Bias, i.e. general (relative) tendency to over- orunderpredict. Values are between -1 (complete under-prediction) and 1 (complete over-prediction) and 0 ideally. G: Absolute error of the median forecast relative to the Hub ensemble. H. Standard deviation of all WIS values for different horizons relative to the Hub ensemble.\relax }{figure.caption.16}{}}
\@writefile{toc}{\contentsline {subsection}{Contribution to the Forecast Hub}{12}{section*.17}\protected@file@percent }
\newlabel{contributions-hub}{{}{12}{Contribution to the Forecast Hub}{section*.17}{}}
\@writefile{toc}{\contentsline {section}{Discussion}{13}{section*.18}\protected@file@percent }
\newlabel{discussion}{{}{13}{Discussion}{section*.18}{}}
\gdef \LT@i {\LT@entry 
    {1}{83.13188pt}\LT@entry 
    {1}{276.6107pt}}
\newlabel{appendix-supplementary-information}{{}{17}{(APPENDIX) Supplementary information}{section*.19}{}}
\@writefile{toc}{\contentsline {section}{(APPENDIX) Supplementary information}{17}{section*.19}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{Supplementary information}{17}{section*.20}\protected@file@percent }
\newlabel{supplementary-information}{{}{17}{Supplementary information}{section*.20}{}}
\@writefile{toc}{\contentsline {subsection}{Scoring metrics used}{17}{section*.21}\protected@file@percent }
\newlabel{scoring-metrics-used}{{}{17}{Scoring metrics used}{section*.21}{}}
\newlabel{tab:scoring-metrics}{{S1}{17}{Scoring metrics used}{table.1}{}}
\@writefile{lot}{\contentsline {table}{\numberline {S1}{\ignorespaces Overview of the scoring metrics used.\relax }}{17}{table.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{The crowdforecasting app}{19}{section*.22}\protected@file@percent }
\newlabel{the-crowdforecasting-app}{{}{19}{The crowdforecasting app}{section*.22}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {S1}{\ignorespaces Screenshot of the crowdforecasting app used to elicit predictions (made in June 2021). \relax }}{19}{figure.caption.23}\protected@file@percent }
\newlabel{fig:screenshot}{{S1}{19}{Screenshot of the crowdforecasting app used to elicit predictions (made in June 2021). \relax }{figure.caption.23}{}}
\@writefile{toc}{\contentsline {subsection}{Text S1. Further details on the semi-mechanistic forecasting models}{20}{section*.24}\protected@file@percent }
\newlabel{text-s1.-further-details-on-the-semi-mechanistic-forecasting-models}{{}{20}{Text S1. Further details on the semi-mechanistic forecasting models}{section*.24}{}}
\@writefile{toc}{\contentsline {subsubsection}{Renewal equation model}{20}{section*.25}\protected@file@percent }
\newlabel{renewal-equation-model}{{}{20}{Renewal equation model}{section*.25}{}}
\newlabel{convolution-model}{{}{21}{Convolution model}{section*.26}{}}
\@writefile{toc}{\contentsline {paragraph}{Convolution model}{21}{section*.26}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Model fitting}{22}{section*.27}\protected@file@percent }
\newlabel{model-fitting}{{}{22}{Model fitting}{section*.27}{}}
\@writefile{toc}{\contentsline {subsection}{Tables with results of the forecast evaluation}{23}{section*.28}\protected@file@percent }
\newlabel{tables-with-results-of-the-forecast-evaluation}{{}{23}{Tables with results of the forecast evaluation}{section*.28}{}}
\@writefile{lot}{\contentsline {table}{\numberline {S2}{\ignorespaces Scores for one and two week ahead forecasts (cut to three significant digits and rounded). Note that scores for cases (which include the whole period from October 12th 2020 until March 1st 2021) and deaths (which include only forecasts from the 21st of December 2020 on) are computed on different subsets. Numbers in brackets show the metrics relative to the Hub ensemble (i.e. the median ensemble of all other models submitted to the German and Polish Forecast Hub, excluding our contributions). WIS is the mean weighted interval score (lower values are better), WIS - sd is the standard deviation of all scores achieved by a model. Dispersion, over-prediction and under-prediction together sum up to the weighted interval score. Bias (between -1 and 1, 0 is ideal) represents the general average tendency of a model to over- or underpredict. 50\% and 90\%-coverage are the percentage of observed values that fell within the 50\% and 90\% prediction intervals of a model. \hspace  {\textwidth }\relax }}{23}{table.caption.29}\protected@file@percent }
\newlabel{tab:score-table-2}{{S2}{23}{Scores for one and two week ahead forecasts (cut to three significant digits and rounded). Note that scores for cases (which include the whole period from October 12th 2020 until March 1st 2021) and deaths (which include only forecasts from the 21st of December 2020 on) are computed on different subsets. Numbers in brackets show the metrics relative to the Hub ensemble (i.e. the median ensemble of all other models submitted to the German and Polish Forecast Hub, excluding our contributions). WIS is the mean weighted interval score (lower values are better), WIS - sd is the standard deviation of all scores achieved by a model. Dispersion, over-prediction and under-prediction together sum up to the weighted interval score. Bias (between -1 and 1, 0 is ideal) represents the general average tendency of a model to over- or underpredict. 50\% and 90\%-coverage are the percentage of observed values that fell within the 50\% and 90\% prediction intervals of a model.\\\hspace {\textwidth }\relax }{table.caption.29}{}}
\@writefile{lot}{\contentsline {table}{\numberline {S3}{\ignorespaces Scores for three and four week ahead forecasts (cut to three significant digits and rounded). Note that scores for cases (which include the whole period from October 12th 2020 until March 1st 2021) and deaths (which include only forecasts from the 21st of December 2020 on) are computed on different subsets. Numbers in brackets show the metrics relative to the Hub ensemble (i.e. the median ensemble of all other models submitted to the German and Polish Forecast Hub, excluding our contributions). WIS is the mean weighted interval score (lower values are better), WIS - sd is the standard deviation of all scores achieved by a model. Dispersion, over-prediction and under-prediction together sum up to the weighted interval score. Bias (between -1 and 1, 0 is ideal) represents the general average tendency of a model to over- or underpredict. 50\% and 90\%-coverage are the percentage of observed values that fell within the 50\% and 90\% prediction intervals of a model. \hspace  {\textwidth }\relax }}{24}{table.caption.30}\protected@file@percent }
\newlabel{tab:score-table-4}{{S3}{24}{Scores for three and four week ahead forecasts (cut to three significant digits and rounded). Note that scores for cases (which include the whole period from October 12th 2020 until March 1st 2021) and deaths (which include only forecasts from the 21st of December 2020 on) are computed on different subsets. Numbers in brackets show the metrics relative to the Hub ensemble (i.e. the median ensemble of all other models submitted to the German and Polish Forecast Hub, excluding our contributions). WIS is the mean weighted interval score (lower values are better), WIS - sd is the standard deviation of all scores achieved by a model. Dispersion, over-prediction and under-prediction together sum up to the weighted interval score. Bias (between -1 and 1, 0 is ideal) represents the general average tendency of a model to over- or underpredict. 50\% and 90\%-coverage are the percentage of observed values that fell within the 50\% and 90\% prediction intervals of a model.\\\hspace {\textwidth }\relax }{table.caption.30}{}}
\@writefile{toc}{\contentsline {subsection}{Aggregate performance by location}{25}{section*.31}\protected@file@percent }
\newlabel{aggregate-performance-by-location}{{}{25}{Aggregate performance by location}{section*.31}{}}
\@writefile{toc}{\contentsline {subsubsection}{Performance in Germany}{25}{section*.32}\protected@file@percent }
\newlabel{performance-in-germany}{{}{25}{Performance in Germany}{section*.32}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {S2}{\ignorespaces Visualisation of aggregate performance metrics for forecasts one to four weeks into the future in Germany. A, B: mean weighted interval score (WIS, lower indicates better performance) across horizons. WIS is decomposed into its components dispersion, over-prediction and under-prediction. C: Empirical coverage of the 50\% prediction intervals (50\% coverage is perfect). D: Empirical coverage of the 90\% prediction intervals. E: Dispersion (same as in panel A, B). Higher values mean greater dispersion of the forecast and imply ceteris paribus a worse score. F: Bias, i.e. general (relative) tendency to over- or underpredict. Values are between -1 (complete under-prediction) and 1 (complete over-prediction) and 0 ideally. G: Absolute error of the median forecast (lower is better). H. Standard deviation of all WIS values for different horizons\relax }}{25}{figure.caption.33}\protected@file@percent }
\newlabel{fig:agg-performance-all-Germany}{{S2}{25}{Visualisation of aggregate performance metrics for forecasts one to four weeks into the future in Germany. A, B: mean weighted interval score (WIS, lower indicates better performance) across horizons. WIS is decomposed into its components dispersion, over-prediction and under-prediction. C: Empirical coverage of the 50\% prediction intervals (50\% coverage is perfect). D: Empirical coverage of the 90\% prediction intervals. E: Dispersion (same as in panel A, B). Higher values mean greater dispersion of the forecast and imply ceteris paribus a worse score. F: Bias, i.e. general (relative) tendency to over- or underpredict. Values are between -1 (complete under-prediction) and 1 (complete over-prediction) and 0 ideally. G: Absolute error of the median forecast (lower is better). H. Standard deviation of all WIS values for different horizons\relax }{figure.caption.33}{}}
\@writefile{toc}{\contentsline {subsubsection}{Performance in Poland}{26}{section*.34}\protected@file@percent }
\newlabel{performance-in-poland}{{}{26}{Performance in Poland}{section*.34}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {S3}{\ignorespaces Visualisation of aggregate performance metrics for forecasts one to four weeks into the future in Poland. A, B: mean weighted interval score (WIS, lower indicates better performance) across horizons. WIS is decomposed into its components dispersion, over-prediction and under-prediction. C: Empirical coverage of the 50\% prediction intervals (50\% coverage is perfect). D: Empirical coverage of the 90\% prediction intervals. E: Dispersion (same as in panel A, B). Higher values mean greater dispersion of the forecast and imply ceteris paribus a worse score. F: Bias, i.e. general (relative) tendency to over- or underpredict. Values are between -1 (complete under-prediction) and 1 (complete over-prediction) and 0 ideally. G: Absolute error of the median forecast (lower is better). H. Standard deviation of all WIS values for different horizons\relax }}{26}{figure.caption.35}\protected@file@percent }
\newlabel{fig:agg-performance-all-Poland}{{S3}{26}{Visualisation of aggregate performance metrics for forecasts one to four weeks into the future in Poland. A, B: mean weighted interval score (WIS, lower indicates better performance) across horizons. WIS is decomposed into its components dispersion, over-prediction and under-prediction. C: Empirical coverage of the 50\% prediction intervals (50\% coverage is perfect). D: Empirical coverage of the 90\% prediction intervals. E: Dispersion (same as in panel A, B). Higher values mean greater dispersion of the forecast and imply ceteris paribus a worse score. F: Bias, i.e. general (relative) tendency to over- or underpredict. Values are between -1 (complete under-prediction) and 1 (complete over-prediction) and 0 ideally. G: Absolute error of the median forecast (lower is better). H. Standard deviation of all WIS values for different horizons\relax }{figure.caption.35}{}}
\@writefile{toc}{\contentsline {subsubsection}{Performance across locations in absolute terms}{27}{section*.36}\protected@file@percent }
\newlabel{performance-across-locations-in-absolute-terms}{{}{27}{Performance across locations in absolute terms}{section*.36}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {S4}{\ignorespaces Visualisation of aggregate performance metrics across locations. A, B: mean weighted interval score (WIS, lower indicates better performance) across horizons. WIS is decomposed into its components dispersion, over-prediction and under-prediction. C: Empirical coverage of the 50\% prediction intervals (50\% coverage is perfect). D: Empirical coverage of the 90\% prediction intervals. E: Dispersion (same as in panel A, B). Higher values mean greater dispersion of the forecast and imply ceteris paribus a worse score. F: Bias, i.e. general (relative) tendency to over- or underpredict. Values are between -1 (complete under-prediction) and 1 (complete over-prediction) and 0 ideally. G: Absolute error of the median forecast (lower is better). H. Standard deviation of WIS values.\relax }}{27}{figure.caption.37}\protected@file@percent }
\newlabel{fig:performance-locations}{{S4}{27}{Visualisation of aggregate performance metrics across locations. A, B: mean weighted interval score (WIS, lower indicates better performance) across horizons. WIS is decomposed into its components dispersion, over-prediction and under-prediction. C: Empirical coverage of the 50\% prediction intervals (50\% coverage is perfect). D: Empirical coverage of the 90\% prediction intervals. E: Dispersion (same as in panel A, B). Higher values mean greater dispersion of the forecast and imply ceteris paribus a worse score. F: Bias, i.e. general (relative) tendency to over- or underpredict. Values are between -1 (complete under-prediction) and 1 (complete over-prediction) and 0 ideally. G: Absolute error of the median forecast (lower is better). H. Standard deviation of WIS values.\relax }{figure.caption.37}{}}
\@writefile{toc}{\contentsline {subsection}{Performance across locations in relative terms}{28}{section*.38}\protected@file@percent }
\newlabel{performance-across-locations-in-relative-terms}{{}{28}{Performance across locations in relative terms}{section*.38}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {S5}{\ignorespaces Visualisation of relative aggregate performance metrics across locations. A, B: mean weighted interval score (WIS) across locations (lower values indicate better performance). C, D: Empirical coverage of the 50\% and 90\% prediction intervals. E: Dispersion. Higher values mean greater dispersion of the forecast and imply ceteris paribus a worse score. F: Bias, i.e. general (relative) tendency to over- orunderpredict. Values are between -1 (complete under-prediction) and 1 (complete over-prediction) and 0 ideally. G: Absolute error of the median forecast. H. Standard deviation of WIS values.\relax }}{28}{figure.caption.39}\protected@file@percent }
\newlabel{fig:performance-locations-rel}{{S5}{28}{Visualisation of relative aggregate performance metrics across locations. A, B: mean weighted interval score (WIS) across locations (lower values indicate better performance). C, D: Empirical coverage of the 50\% and 90\% prediction intervals. E: Dispersion. Higher values mean greater dispersion of the forecast and imply ceteris paribus a worse score. F: Bias, i.e. general (relative) tendency to over- orunderpredict. Values are between -1 (complete under-prediction) and 1 (complete over-prediction) and 0 ideally. G: Absolute error of the median forecast. H. Standard deviation of WIS values.\relax }{figure.caption.39}{}}
\@writefile{toc}{\contentsline {subsection}{Visualisation of daily reported cases and deaths}{29}{section*.40}\protected@file@percent }
\newlabel{visualisation-of-daily-reported-cases-and-deaths}{{}{29}{Visualisation of daily reported cases and deaths}{section*.40}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {S6}{\ignorespaces Visualisation of daily report data. The black line represents weekly data divided by seven. Data were last accessed through the German and Polish Forecast Hub on August 21 2021.\relax }}{29}{figure.caption.41}\protected@file@percent }
\newlabel{fig:daily-truth}{{S6}{29}{Visualisation of daily report data. The black line represents weekly data divided by seven. Data were last accessed through the German and Polish Forecast Hub on August 21 2021.\relax }{figure.caption.41}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {S7}{\ignorespaces Visualisation of the absolute difference between the daily report data at the time and the data now. In Germany, there were zero cases and deaths reported on 2020-10-12, and only later 2467 cases and 6 deaths were added. Data were last accessed through the German and Polish Forecast Hub on May 10 2022.\relax }}{30}{figure.caption.42}\protected@file@percent }
\newlabel{fig:daily-truth-update}{{S7}{30}{Visualisation of the absolute difference between the daily report data at the time and the data now. In Germany, there were zero cases and deaths reported on 2020-10-12, and only later 2467 cases and 6 deaths were added. Data were last accessed through the German and Polish Forecast Hub on May 10 2022.\relax }{figure.caption.42}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {S8}{\ignorespaces Visualisation of the relative difference between the weekly report data at the time and the data now. Apart from the data that was retrospectively added on 2020-10-12, data updates did not have a noticeable effect on weekly data (as shown in the forecasting application). Data were last accessed through the German and Polish Forecast Hub on May 10 2022.\relax }}{31}{figure.caption.43}\protected@file@percent }
\newlabel{fig:weekly-truth-update}{{S8}{31}{Visualisation of the relative difference between the weekly report data at the time and the data now. Apart from the data that was retrospectively added on 2020-10-12, data updates did not have a noticeable effect on weekly data (as shown in the forecasting application). Data were last accessed through the German and Polish Forecast Hub on May 10 2022.\relax }{figure.caption.43}{}}
\@writefile{toc}{\contentsline {subsection}{Visualisation of scores and forecasts 1, 3, 4 weeks ahead}{32}{section*.44}\protected@file@percent }
\newlabel{visualisation-of-scores-and-forecasts-1-3-4-weeks-ahead}{{}{32}{Visualisation of scores and forecasts 1, 3, 4 weeks ahead}{section*.44}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {S9}{\ignorespaces A, C: Visualisation of 50\% prediction intervals of one week ahead forecasts against the reported values. Forecasts that were not scored (because there was no complete set of death forecasts available) are greyed out. B, D: Visualisation of corresponding WIS.\relax }}{32}{figure.caption.45}\protected@file@percent }
\newlabel{fig:forecasts-and-truth-1}{{S9}{32}{A, C: Visualisation of 50\% prediction intervals of one week ahead forecasts against the reported values. Forecasts that were not scored (because there was no complete set of death forecasts available) are greyed out. B, D: Visualisation of corresponding WIS.\relax }{figure.caption.45}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {S10}{\ignorespaces A, C: Visualisation of 50\% prediction intervals of three week ahead forecasts against the reported values. Forecasts that were not scored (because there was no complete set of death forecasts available) are greyed out. B, D: Visualisation of corresponding WIS.\relax }}{33}{figure.caption.46}\protected@file@percent }
\newlabel{fig:forecasts-and-truth-3}{{S10}{33}{A, C: Visualisation of 50\% prediction intervals of three week ahead forecasts against the reported values. Forecasts that were not scored (because there was no complete set of death forecasts available) are greyed out. B, D: Visualisation of corresponding WIS.\relax }{figure.caption.46}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {S11}{\ignorespaces A, C: Visualisation of 50\% prediction intervals of four week ahead forecasts against the reported values. Forecasts that were not scored (because there was no complete set of death forecasts available) are greyed out. B, D: Visualisation of corresponding WIS.\relax }}{34}{figure.caption.47}\protected@file@percent }
\newlabel{fig:forecasts-and-truth-4}{{S11}{34}{A, C: Visualisation of 50\% prediction intervals of four week ahead forecasts against the reported values. Forecasts that were not scored (because there was no complete set of death forecasts available) are greyed out. B, D: Visualisation of corresponding WIS.\relax }{figure.caption.47}{}}
\@writefile{toc}{\contentsline {subsection}{Distribution of scores}{35}{section*.48}\protected@file@percent }
\newlabel{distribution-of-scores}{{}{35}{Distribution of scores}{section*.48}{}}
\@writefile{toc}{\contentsline {subsubsection}{Absolute scores}{35}{section*.49}\protected@file@percent }
\newlabel{absolute-scores}{{}{35}{Absolute scores}{section*.49}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {S12}{\ignorespaces A: Distribution of weighted interval scores for one week ahead forecasts of the different models and forecast targets. B: Distribution of WIS separate by country.\relax }}{35}{figure.caption.50}\protected@file@percent }
\newlabel{fig:distribution-scores-1}{{S12}{35}{A: Distribution of weighted interval scores for one week ahead forecasts of the different models and forecast targets. B: Distribution of WIS separate by country.\relax }{figure.caption.50}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {S13}{\ignorespaces A: Distribution of weighted interval scores for three week ahead forecasts of the different models and forecast targets. B: Distribution of WIS separate by country.\relax }}{35}{figure.caption.51}\protected@file@percent }
\newlabel{fig:distribution-scores-3}{{S13}{35}{A: Distribution of weighted interval scores for three week ahead forecasts of the different models and forecast targets. B: Distribution of WIS separate by country.\relax }{figure.caption.51}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {S14}{\ignorespaces A: Distribution of weighted interval scores for four week ahead forecasts of the different models and forecast targets. B: Distribution of WIS separate by country.\relax }}{36}{figure.caption.52}\protected@file@percent }
\newlabel{fig:distribution-scores-4}{{S14}{36}{A: Distribution of weighted interval scores for four week ahead forecasts of the different models and forecast targets. B: Distribution of WIS separate by country.\relax }{figure.caption.52}{}}
\@writefile{toc}{\contentsline {subsubsection}{Ranks achieved by forecasts}{36}{section*.53}\protected@file@percent }
\newlabel{ranks-achieved-by-forecasts}{{}{36}{Ranks achieved by forecasts}{section*.53}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {S15}{\ignorespaces A: Distribution of the ranks (determined by the weighted interval score) for one week ahead forecasts of the different models and forecast targets. B: Distribution of ranks separate by country.\relax }}{36}{figure.caption.54}\protected@file@percent }
\newlabel{fig:distribution-scores-ranks-1}{{S15}{36}{A: Distribution of the ranks (determined by the weighted interval score) for one week ahead forecasts of the different models and forecast targets. B: Distribution of ranks separate by country.\relax }{figure.caption.54}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {S16}{\ignorespaces A: Distribution of the ranks (determined by the weighted interval score) for two week ahead forecasts of the different models and forecast targets. B: Distribution of ranks separate by country.\relax }}{37}{figure.caption.55}\protected@file@percent }
\newlabel{fig:distribution-scores-ranks-2}{{S16}{37}{A: Distribution of the ranks (determined by the weighted interval score) for two week ahead forecasts of the different models and forecast targets. B: Distribution of ranks separate by country.\relax }{figure.caption.55}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {S17}{\ignorespaces A: Distribution of the ranks (determined by the weighted interval score) for three week ahead forecasts of the different models and forecast targets. B: Distribution of ranks separate by country.\relax }}{37}{figure.caption.56}\protected@file@percent }
\newlabel{fig:distribution-scores-ranks-3}{{S17}{37}{A: Distribution of the ranks (determined by the weighted interval score) for three week ahead forecasts of the different models and forecast targets. B: Distribution of ranks separate by country.\relax }{figure.caption.56}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {S18}{\ignorespaces A: Distribution of the ranks (determined by the weighted interval score) for four week ahead forecasts of the different models and forecast targets. B: Distribution of ranks separate by country.\relax }}{38}{figure.caption.57}\protected@file@percent }
\newlabel{fig:distribution-scores-ranks-4}{{S18}{38}{A: Distribution of the ranks (determined by the weighted interval score) for four week ahead forecasts of the different models and forecast targets. B: Distribution of ranks separate by country.\relax }{figure.caption.57}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {S19}{\ignorespaces Density plot with the difference in WIS between the Crowd forecast and the Hub ensemble (values below zero mean better performance of the Crowd forecasts) for a 2 week ahead forecast horizon.\relax }}{38}{figure.caption.58}\protected@file@percent }
\newlabel{fig:distribution-scores-differences}{{S19}{38}{Density plot with the difference in WIS between the Crowd forecast and the Hub ensemble (values below zero mean better performance of the Crowd forecasts) for a 2 week ahead forecast horizon.\relax }{figure.caption.58}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {S20}{\ignorespaces Density plot with the difference in WIS between the Crowd forecast and the Renewal model (values below zero mean better performance of the Crowd forecasts) for a 2 week ahead forecast horizon.\relax }}{39}{figure.caption.59}\protected@file@percent }
\newlabel{fig:distribution-scores-differences-renewal}{{S20}{39}{Density plot with the difference in WIS between the Crowd forecast and the Renewal model (values below zero mean better performance of the Crowd forecasts) for a 2 week ahead forecast horizon.\relax }{figure.caption.59}{}}
\@writefile{toc}{\contentsline {subsection}{Comparison of ensembles}{40}{section*.60}\protected@file@percent }
\newlabel{comparison-of-ensembles}{{}{40}{Comparison of ensembles}{section*.60}{}}
\@writefile{toc}{\contentsline {subsubsection}{Performance visualisation mean ensemble}{40}{section*.61}\protected@file@percent }
\newlabel{performance-visualisation-mean-ensemble}{{}{40}{Performance visualisation mean ensemble}{section*.61}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {S21}{\ignorespaces Visualisation of aggregate performance metrics across forecast horizons for the different versions of the Hub mean ensemble. \IeC {\textquotedblleft }Hub-ensemble\IeC {\textquotedblright } extit{excludes} all our models, Hub-ensemble-all extit{includes} all of our models, \IeC {\textquotedblleft }Hub-ensemble-realised\IeC {\textquotedblright } is the actual hub-ensemble observed in reality, which includes the renewal model and the crowd forecasts, but ont the convolution model. Values (except for Bias) are computed as differences to the Hub ensemble which excludes our contributions. For Coverage, this is an absolute difference, for other metrics this is a percentage difference. A, B: mean weighted interval score (WIS) across horizons relative to the Hub ensemble (lower values indicate better performance). C, D: Empirical coverage of the 50\% and 90\% prediction intervals minus empirical coverage observed for the Hub ensemble. E: Dispersion relative to the dispersion of the Hub ensemble. Higher values mean greater dispersion of the forecast and imply ceteris paribus a worse score. F: Bias, i.e. general (relative) tendency to over- orunderpredict. Values are between -1 (complete under-prediction) and 1 (complete over-prediction) and 0 ideally. G: Absolute error of the median forecast relative to the Hub ensemble. H. Standard deviation of all WIS values for different horizons relative to the Hub ensemble.\relax }}{40}{figure.caption.62}\protected@file@percent }
\newlabel{fig:agg-performance-ensemble-mean}{{S21}{40}{Visualisation of aggregate performance metrics across forecast horizons for the different versions of the Hub mean ensemble. “Hub-ensemble” extit{excludes} all our models, Hub-ensemble-all extit{includes} all of our models, “Hub-ensemble-realised” is the actual hub-ensemble observed in reality, which includes the renewal model and the crowd forecasts, but ont the convolution model. Values (except for Bias) are computed as differences to the Hub ensemble which excludes our contributions. For Coverage, this is an absolute difference, for other metrics this is a percentage difference. A, B: mean weighted interval score (WIS) across horizons relative to the Hub ensemble (lower values indicate better performance). C, D: Empirical coverage of the 50\% and 90\% prediction intervals minus empirical coverage observed for the Hub ensemble. E: Dispersion relative to the dispersion of the Hub ensemble. Higher values mean greater dispersion of the forecast and imply ceteris paribus a worse score. F: Bias, i.e. general (relative) tendency to over- orunderpredict. Values are between -1 (complete under-prediction) and 1 (complete over-prediction) and 0 ideally. G: Absolute error of the median forecast relative to the Hub ensemble. H. Standard deviation of all WIS values for different horizons relative to the Hub ensemble.\relax }{figure.caption.62}{}}
\@writefile{toc}{\contentsline {subsubsection}{Tables median ensemble}{40}{section*.63}\protected@file@percent }
\newlabel{tables-median-ensemble}{{}{40}{Tables median ensemble}{section*.63}{}}
\@writefile{toc}{\contentsline {subsubsection}{Tables mean ensemble}{40}{section*.66}\protected@file@percent }
\newlabel{tables-mean-ensemble}{{}{40}{Tables mean ensemble}{section*.66}{}}
\@writefile{lot}{\contentsline {table}{\numberline {S4}{\ignorespaces Scores for one and two week ahead forecasts (cut to three significant digits and rounded) for the different versions of the median ensemble. Note that scores for cases (which include the whole period from October 12th 2020 until March 1st 2021) and deaths (which include only forecasts from the 21st of December 2020 on) are computed on different subsets. Numbers in brackets show the metrics relative to the Hub ensemble (i.e. the median ensemble of all other models submitted to the German and Polish Forecast Hub, excluding our contributions). WIS is the mean weighted interval score (lower values are better), WIS - sd is the standard deviation of all scores achieved by a model. Dispersion, over-prediction and under-prediction together sum up to the weighted interval score. Bias (between -1 and 1, 0 is ideal) represents the general average tendency of a model to over- or underpredict. 50\% and 90\%-coverage are the percentage of observed values that fell within the 50\% and 90\% prediction intervals of a model. \hspace  {\textwidth }\relax }}{41}{table.caption.64}\protected@file@percent }
\newlabel{tab:score-table-ensemble-2}{{S4}{41}{Scores for one and two week ahead forecasts (cut to three significant digits and rounded) for the different versions of the median ensemble. Note that scores for cases (which include the whole period from October 12th 2020 until March 1st 2021) and deaths (which include only forecasts from the 21st of December 2020 on) are computed on different subsets. Numbers in brackets show the metrics relative to the Hub ensemble (i.e. the median ensemble of all other models submitted to the German and Polish Forecast Hub, excluding our contributions). WIS is the mean weighted interval score (lower values are better), WIS - sd is the standard deviation of all scores achieved by a model. Dispersion, over-prediction and under-prediction together sum up to the weighted interval score. Bias (between -1 and 1, 0 is ideal) represents the general average tendency of a model to over- or underpredict. 50\% and 90\%-coverage are the percentage of observed values that fell within the 50\% and 90\% prediction intervals of a model.\\\hspace {\textwidth }\relax }{table.caption.64}{}}
\@writefile{lot}{\contentsline {table}{\numberline {S5}{\ignorespaces Scores for three and four week ahead forecasts (cut to three significant digits and rounded) for the different versions of the median ensemble. Note that scores for cases (which include the whole period from October 12th 2020 until March 1st 2021) and deaths (which include only forecasts from the 21st of December 2020 on) are computed on different subsets. Numbers in brackets show the metrics relative to the Hub ensemble (i.e. the median ensemble of all other models submitted to the German and Polish Forecast Hub, excluding our contributions). WIS is the mean weighted interval score (lower values are better), WIS - sd is the standard deviation of all scores achieved by a model. Dispersion, over-prediction and under-prediction together sum up to the weighted interval score. Bias (between -1 and 1, 0 is ideal) represents the general average tendency of a model to over- or underpredict. 50\% and 90\%-coverage are the percentage of observed values that fell within the 50\% and 90\% prediction intervals of a model. \hspace  {\textwidth }\relax }}{42}{table.caption.65}\protected@file@percent }
\newlabel{tab:score-table-ensemble-4}{{S5}{42}{Scores for three and four week ahead forecasts (cut to three significant digits and rounded) for the different versions of the median ensemble. Note that scores for cases (which include the whole period from October 12th 2020 until March 1st 2021) and deaths (which include only forecasts from the 21st of December 2020 on) are computed on different subsets. Numbers in brackets show the metrics relative to the Hub ensemble (i.e. the median ensemble of all other models submitted to the German and Polish Forecast Hub, excluding our contributions). WIS is the mean weighted interval score (lower values are better), WIS - sd is the standard deviation of all scores achieved by a model. Dispersion, over-prediction and under-prediction together sum up to the weighted interval score. Bias (between -1 and 1, 0 is ideal) represents the general average tendency of a model to over- or underpredict. 50\% and 90\%-coverage are the percentage of observed values that fell within the 50\% and 90\% prediction intervals of a model.\\\hspace {\textwidth }\relax }{table.caption.65}{}}
\@writefile{lot}{\contentsline {table}{\numberline {S6}{\ignorespaces Scores for one and two week ahead forecasts (cut to three significant digits and rounded) for the different versions of the mean ensemble. Note that scores for cases (which include the whole period from October 12th 2020 until March 1st 2021) and deaths (which include only forecasts from the 21st of December 2020 on) are computed on different subsets. Numbers in brackets show the metrics relative to the Hub mean ensemble (i.e. the mean ensemble of all other models submitted to the German and Polish Forecast Hub, excluding our contributions). WIS is the mean weighted interval score (lower values are better), WIS - sd is the standard deviation of all scores achieved by a model. Dispersion, over-prediction and under-prediction together sum up to the weighted interval score. Bias (between -1 and 1, 0 is ideal) represents the general average tendency of a model to over- or underpredict. 50\% and 90\%-coverage are the percentage of observed values that fell within the 50\% and 90\% prediction intervals of a model. \hspace  {\textwidth }\relax }}{43}{table.caption.67}\protected@file@percent }
\newlabel{tab:score-table-ensemble-mean-2}{{S6}{43}{Scores for one and two week ahead forecasts (cut to three significant digits and rounded) for the different versions of the mean ensemble. Note that scores for cases (which include the whole period from October 12th 2020 until March 1st 2021) and deaths (which include only forecasts from the 21st of December 2020 on) are computed on different subsets. Numbers in brackets show the metrics relative to the Hub mean ensemble (i.e. the mean ensemble of all other models submitted to the German and Polish Forecast Hub, excluding our contributions). WIS is the mean weighted interval score (lower values are better), WIS - sd is the standard deviation of all scores achieved by a model. Dispersion, over-prediction and under-prediction together sum up to the weighted interval score. Bias (between -1 and 1, 0 is ideal) represents the general average tendency of a model to over- or underpredict. 50\% and 90\%-coverage are the percentage of observed values that fell within the 50\% and 90\% prediction intervals of a model.\\\hspace {\textwidth }\relax }{table.caption.67}{}}
\@writefile{lot}{\contentsline {table}{\numberline {S7}{\ignorespaces Scores for three and four week ahead forecasts (cut to three significant digits and rounded) for the different versions of the mean ensemble. Note that scores for cases (which include the whole period from October 12th 2020 until March 1st 2021) and deaths (which include only forecasts from the 21st of December 2020 on) are computed on different subsets. Numbers in brackets show the metrics relative to the Hub mean ensemble (i.e. the mean ensemble of all other models submitted to the German and Polish Forecast Hub, excluding our contributions). WIS is the mean weighted interval score (lower values are better), WIS - sd is the standard deviation of all scores achieved by a model. Dispersion, over-prediction and under-prediction together sum up to the weighted interval score. Bias (between -1 and 1, 0 is ideal) represents the general average tendency of a model to over- or underpredict. 50\% and 90\%-coverage are the percentage of observed values that fell within the 50\% and 90\% prediction intervals of a model. \hspace  {\textwidth }\relax }}{44}{table.caption.68}\protected@file@percent }
\newlabel{tab:score-table-ensemble-mean-4}{{S7}{44}{Scores for three and four week ahead forecasts (cut to three significant digits and rounded) for the different versions of the mean ensemble. Note that scores for cases (which include the whole period from October 12th 2020 until March 1st 2021) and deaths (which include only forecasts from the 21st of December 2020 on) are computed on different subsets. Numbers in brackets show the metrics relative to the Hub mean ensemble (i.e. the mean ensemble of all other models submitted to the German and Polish Forecast Hub, excluding our contributions). WIS is the mean weighted interval score (lower values are better), WIS - sd is the standard deviation of all scores achieved by a model. Dispersion, over-prediction and under-prediction together sum up to the weighted interval score. Bias (between -1 and 1, 0 is ideal) represents the general average tendency of a model to over- or underpredict. 50\% and 90\%-coverage are the percentage of observed values that fell within the 50\% and 90\% prediction intervals of a model.\\\hspace {\textwidth }\relax }{table.caption.68}{}}
\@writefile{toc}{\contentsline {subsection}{Sensitivity analysis}{45}{section*.69}\protected@file@percent }
\newlabel{sensitivity-analysis}{{}{45}{Sensitivity analysis}{section*.69}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {S22}{\ignorespaces Visualisation of aggregate performance metrics across forecast horizons only for the period from December 14th 2020 on where all models were available. A, B: mean weighted interval score (WIS, lower indicates better performance) across horizons. WIS is decomposed into its components dispersion, over-prediction and under-prediction. C: Empirical coverage of the 50\% prediction intervals (50\% coverage is perfect). D: Empirical coverage of the 90\% prediction intervals. E: Dispersion (same as in panel A, B). Higher values mean greater dispersion of the forecast and imply ceteris paribus a worse score. F: Bias, i.e. general (relative) tendency to over- or underpredict. Values are between -1 (complete under-prediction) and 1 (complete over-prediction) and 0 ideally. G: Absolute error of the median forecast (lower is better). H. Standard deviation of all WIS values for different horizons\relax }}{45}{figure.caption.70}\protected@file@percent }
\newlabel{fig:agg-performance-all-late}{{S22}{45}{Visualisation of aggregate performance metrics across forecast horizons only for the period from December 14th 2020 on where all models were available. A, B: mean weighted interval score (WIS, lower indicates better performance) across horizons. WIS is decomposed into its components dispersion, over-prediction and under-prediction. C: Empirical coverage of the 50\% prediction intervals (50\% coverage is perfect). D: Empirical coverage of the 90\% prediction intervals. E: Dispersion (same as in panel A, B). Higher values mean greater dispersion of the forecast and imply ceteris paribus a worse score. F: Bias, i.e. general (relative) tendency to over- or underpredict. Values are between -1 (complete under-prediction) and 1 (complete over-prediction) and 0 ideally. G: Absolute error of the median forecast (lower is better). H. Standard deviation of all WIS values for different horizons\relax }{figure.caption.70}{}}
\@writefile{lot}{\contentsline {table}{\numberline {S8}{\ignorespaces Scores for one and two week ahead forecasts (cut to three significant digits and rounded) calculated on forecasts made between December 14th 2020 and March 1st 2021. Numbers in brackets show the metrics relative to the Hub ensemble (i.e. the median ensemble of all other models submitted to the German and Polish Forecast Hub, excluding our contributions). WIS is the mean weighted interval score (lower values are better), WIS - sd is the standard deviation of all scores achieved by a model. Dispersion, over-prediction and under-prediction together sum up to the weighted interval score. Bias (between -1 and 1, 0 is ideal) represents the general average tendency of a model to over- or underpredict. 50\% and 90\%-coverage are the percentage of observed values that fell within the 50\% and 90\% prediction intervals of a model. \hspace  {\textwidth }\relax }}{46}{table.caption.71}\protected@file@percent }
\newlabel{tab:score-table-late-2}{{S8}{46}{Scores for one and two week ahead forecasts (cut to three significant digits and rounded) calculated on forecasts made between December 14th 2020 and March 1st 2021. Numbers in brackets show the metrics relative to the Hub ensemble (i.e. the median ensemble of all other models submitted to the German and Polish Forecast Hub, excluding our contributions). WIS is the mean weighted interval score (lower values are better), WIS - sd is the standard deviation of all scores achieved by a model. Dispersion, over-prediction and under-prediction together sum up to the weighted interval score. Bias (between -1 and 1, 0 is ideal) represents the general average tendency of a model to over- or underpredict. 50\% and 90\%-coverage are the percentage of observed values that fell within the 50\% and 90\% prediction intervals of a model.\\\hspace {\textwidth }\relax }{table.caption.71}{}}
\@writefile{lot}{\contentsline {table}{\numberline {S9}{\ignorespaces Scores for three and four week ahead forecasts (cut to three significant digits and rounded) calculated on forecasts made between December 14th 2020 and March 1st 2021. Numbers in brackets show the metrics relative to the Hub ensemble (i.e. the median ensemble of all other models submitted to the German and Polish Forecast Hub, excluding our contributions). WIS is the mean weighted interval score (lower values are better), WIS - sd is the standard deviation of all scores achieved by a model. Dispersion, over-prediction and under-prediction together sum up to the weighted interval score. Bias (between -1 and 1, 0 is ideal) represents the general average tendency of a model to over- or underpredict. 50\% and 90\%-coverage are the percentage of observed values that fell within the 50\% and 90\% prediction intervals of a model. \hspace  {\textwidth }\relax }}{46}{table.caption.72}\protected@file@percent }
\newlabel{tab:score-table-late-4}{{S9}{46}{Scores for three and four week ahead forecasts (cut to three significant digits and rounded) calculated on forecasts made between December 14th 2020 and March 1st 2021. Numbers in brackets show the metrics relative to the Hub ensemble (i.e. the median ensemble of all other models submitted to the German and Polish Forecast Hub, excluding our contributions). WIS is the mean weighted interval score (lower values are better), WIS - sd is the standard deviation of all scores achieved by a model. Dispersion, over-prediction and under-prediction together sum up to the weighted interval score. Bias (between -1 and 1, 0 is ideal) represents the general average tendency of a model to over- or underpredict. 50\% and 90\%-coverage are the percentage of observed values that fell within the 50\% and 90\% prediction intervals of a model.\\\hspace {\textwidth }\relax }{table.caption.72}{}}
\gdef \LT@ii {\LT@entry 
    {1}{140.0374pt}\LT@entry 
    {1}{219.7052pt}}
\@writefile{toc}{\contentsline {subsection}{Overview of models and forecasters}{47}{section*.73}\protected@file@percent }
\newlabel{overview-of-models-and-forecasters}{{}{47}{Overview of models and forecasters}{section*.73}{}}
\newlabel{tab:table-ensemble-versions}{{S10}{47}{Overview of models and forecasters}{table.10}{}}
\@writefile{lot}{\contentsline {table}{\numberline {S10}{\ignorespaces Overview of the models and ensembles used.\relax }}{47}{table.10}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {S23}{\ignorespaces Number of participants who submitted a forecast over time.\relax }}{48}{figure.caption.74}\protected@file@percent }
\newlabel{fig:num-forecasters}{{S23}{48}{Number of participants who submitted a forecast over time.\relax }{figure.caption.74}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {S24}{\ignorespaces Number of member models (including our crowd forecasts and the renewal model) in the official Hub ensemble. Note that the renewal model was not included in the ensemble on December 28th 2020.\relax }}{49}{figure.caption.75}\protected@file@percent }
\newlabel{fig:num-ensemble-members}{{S24}{49}{Number of member models (including our crowd forecasts and the renewal model) in the official Hub ensemble. Note that the renewal model was not included in the ensemble on December 28th 2020.\relax }{figure.caption.75}{}}
\@writefile{toc}{\contentsline {subsection}{Comparison of crowd forecasts and application baseline}{50}{section*.76}\protected@file@percent }
\newlabel{comparison-of-crowd-forecasts-and-application-baseline}{{}{50}{Comparison of crowd forecasts and application baseline}{section*.76}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {S25}{\ignorespaces Crowd forecasts and baseline shown in the application for a two week horizon. Shown are the median, as well as the 50\% and 90\% prediction intervals (in order of decreasing opacity). For any given point in time, the baseline shown in red is what forecasters saw when they opened the app (the baseline shown was constant across all forecast horizons).\relax }}{50}{figure.caption.77}\protected@file@percent }
\newlabel{fig:compare-forecasters}{{S25}{50}{Crowd forecasts and baseline shown in the application for a two week horizon. Shown are the median, as well as the 50\% and 90\% prediction intervals (in order of decreasing opacity). For any given point in time, the baseline shown in red is what forecasters saw when they opened the app (the baseline shown was constant across all forecast horizons).\relax }{figure.caption.77}{}}
\newlabel{LastPage}{{}{55}{}{page.55}{}}
\xdef\lastpage@lastpage{55}
\xdef\lastpage@lastpageHy{55}
\gdef \@abspage@last{55}
