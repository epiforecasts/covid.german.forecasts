\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\providecommand\BKM@entry[2]{}
\BKM@entry{id=1,dest={73656374696F6E2E31},srcline={211}}{5C3337365C3337375C303030415C303030625C303030735C303030745C303030725C303030615C303030635C30303074}
\BKM@entry{id=2,dest={73656374696F6E2E32},srcline={216}}{5C3337365C3337375C303030415C303030755C303030745C303030685C3030306F5C303030725C3030305C3034305C303030735C303030755C3030306D5C3030306D5C303030615C303030725C30303079}
\@writefile{toc}{\contentsline {section}{\numberline {1}Abstract}{1}{section.1}\protected@file@percent }
\newlabel{abstract}{{1}{1}{Abstract}{section.1}{}}
\BKM@entry{id=3,dest={73656374696F6E2E33},srcline={222}}{5C3337365C3337375C303030495C3030306E5C303030745C303030725C3030306F5C303030645C303030755C303030635C303030745C303030695C3030306F5C3030306E}
\@writefile{toc}{\contentsline {section}{\numberline {2}Author summary}{2}{section.2}\protected@file@percent }
\newlabel{author-summary}{{2}{2}{Author summary}{section.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Introduction}{2}{section.3}\protected@file@percent }
\newlabel{introduction}{{3}{2}{Introduction}{section.3}{}}
\BKM@entry{id=4,dest={73656374696F6E2E34},srcline={237}}{5C3337365C3337375C3030304D5C303030655C303030745C303030685C3030306F5C303030645C30303073}
\@writefile{toc}{\contentsline {section}{\numberline {4}Methods}{4}{section.4}\protected@file@percent }
\newlabel{methods}{{4}{4}{Methods}{section.4}{}}
\BKM@entry{id=5,dest={73756273656374696F6E2E342E31},srcline={242}}{5C3337365C3337375C303030465C3030306F5C303030725C303030655C303030635C303030615C303030735C303030745C3030305C3034305C303030745C303030615C303030725C303030675C303030655C303030745C303030735C3030305C3034305C303030615C3030306E5C303030645C3030305C3034305C303030695C3030306E5C303030745C303030655C303030725C303030615C303030635C303030745C303030695C3030306F5C3030306E5C3030305C3034305C303030775C303030695C303030745C303030685C3030305C3034305C303030745C303030685C303030655C3030305C3034305C303030475C303030655C303030725C3030306D5C303030615C3030306E5C3030305C3034305C303030615C3030306E5C303030645C3030305C3034305C303030505C3030306F5C3030306C5C303030695C303030735C303030685C3030305C3034305C303030465C3030306F5C303030725C303030655C303030635C303030615C303030735C303030745C3030305C3034305C303030485C303030755C30303062}
\BKM@entry{id=6,dest={73756273656374696F6E2E342E32},srcline={250}}{5C3337365C3337375C303030435C303030725C3030306F5C303030775C303030645C3030305C3034305C303030665C3030306F5C303030725C303030655C303030635C303030615C303030735C303030745C30303073}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Forecast targets and interaction with the German and Polish Forecast Hub}{5}{subsection.4.1}\protected@file@percent }
\newlabel{forecast-targets-and-interaction-with-the-german-and-polish-forecast-hub}{{4.1}{5}{Forecast targets and interaction with the German and Polish Forecast Hub}{subsection.4.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Crowd forecasts}{5}{subsection.4.2}\protected@file@percent }
\newlabel{crowd-forecasts}{{4.2}{5}{Crowd forecasts}{subsection.4.2}{}}
\BKM@entry{id=7,dest={73756273656374696F6E2E342E33},srcline={266}}{5C3337365C3337375C3030304D5C3030306F5C303030645C303030655C3030306C5C3030302D5C303030625C303030615C303030735C303030655C303030645C3030305C3034305C303030665C3030306F5C303030725C303030655C303030635C303030615C303030735C303030745C30303073}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Model-based forecasts}{7}{subsection.4.3}\protected@file@percent }
\newlabel{model-based-forecasts}{{4.3}{7}{Model-based forecasts}{subsection.4.3}{}}
\BKM@entry{id=8,dest={73756273656374696F6E2E342E34},srcline={275}}{5C3337365C3337375C303030415C3030306E5C303030615C3030306C5C303030795C303030735C303030695C30303073}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Analysis}{8}{subsection.4.4}\protected@file@percent }
\newlabel{analysis}{{4.4}{8}{Analysis}{subsection.4.4}{}}
\BKM@entry{id=9,dest={73656374696F6E2E35},srcline={285}}{5C3337365C3337375C303030525C303030655C303030735C303030755C3030306C5C303030745C30303073}
\BKM@entry{id=10,dest={73756273656374696F6E2E352E31},srcline={288}}{5C3337365C3337375C303030435C303030725C3030306F5C303030775C303030645C3030305C3034305C303030665C3030306F5C303030725C303030655C303030635C303030615C303030735C303030745C3030305C3034305C303030705C303030615C303030725C303030745C303030695C303030635C303030695C303030705C303030615C303030745C303030695C3030306F5C3030306E}
\@writefile{toc}{\contentsline {section}{\numberline {5}Results}{9}{section.5}\protected@file@percent }
\newlabel{results}{{5}{9}{Results}{section.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Crowd forecast participation}{9}{subsection.5.1}\protected@file@percent }
\newlabel{crowd-forecast-participation}{{5.1}{9}{Crowd forecast participation}{subsection.5.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Visualisation of aggregate performance metrics \DIFdelbeginFL  {\color {red}\sout {across }}\DIFdelendFL  for forecasts one to four weeks into the future\DIFdelbeginFL  {\color {red}\sout {(marked as 1 - 4 on the x axis)}}\DIFdelendFL  . A, B: mean weighted interval score (WIS, lower indicates better performance) across horizons. WIS is decomposed into its components dispersion, over-prediction and under-prediction. C: Empirical coverage of the 50\% prediction intervals (50\% coverage is perfect). D: Empirical coverage of the 90\% prediction intervals. E: Dispersion (same as in panel A, B). Higher values mean greater dispersion of the forecast and imply ceteris paribus a worse score. F: Bias, i.e. general (relative) tendency to over- or underpredict. Values are between -1 (complete under-prediction) and 1 (complete over-prediction) and 0 ideally. G: Absolute error of the median forecast (lower is better). H. Standard deviation of all WIS values for different horizons}}{10}{figure.1}\protected@file@percent }
\newlabel{fig:agg-performance-all}{{1}{10}{Visualisation of aggregate performance metrics \DIFdelbeginFL \DIFdelFL {across }\DIFdelendFL for forecasts one to four weeks into the future\DIFdelbeginFL \DIFdelFL {(marked as 1 - 4 on the x axis)}\DIFdelendFL . A, B: mean weighted interval score (WIS, lower indicates better performance) across horizons. WIS is decomposed into its components dispersion, over-prediction and under-prediction. C: Empirical coverage of the 50\% prediction intervals (50\% coverage is perfect). D: Empirical coverage of the 90\% prediction intervals. E: Dispersion (same as in panel A, B). Higher values mean greater dispersion of the forecast and imply ceteris paribus a worse score. F: Bias, i.e. general (relative) tendency to over- or underpredict. Values are between -1 (complete under-prediction) and 1 (complete over-prediction) and 0 ideally. G: Absolute error of the median forecast (lower is better). H. Standard deviation of all WIS values for different horizons}{figure.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces A, C: Visualisation of 50\% prediction intervals of two week ahead forecasts against the reported values. Forecasts that were not scored (because there was no complete set of death forecasts available) are greyed out. B, D: Visualisation of corresponding WIS.}}{11}{figure.2}\protected@file@percent }
\newlabel{fig:forecasts-and-truth}{{2}{11}{A, C: Visualisation of 50\% prediction intervals of two week ahead forecasts against the reported values. Forecasts that were not scored (because there was no complete set of death forecasts available) are greyed out. B, D: Visualisation of corresponding WIS}{figure.2}{}}
\BKM@entry{id=11,dest={73756273656374696F6E2E352E32},srcline={301}}{5C3337365C3337375C303030435C303030615C303030735C303030655C3030305C3034305C303030465C3030306F5C303030725C303030655C303030635C303030615C303030735C303030745C30303073}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Case Forecasts}{12}{subsection.5.2}\protected@file@percent }
\newlabel{case-forecasts}{{5.2}{12}{Case Forecasts}{subsection.5.2}{}}
\BKM@entry{id=12,dest={73756273656374696F6E2E352E33},srcline={319}}{5C3337365C3337375C303030445C303030655C303030615C303030745C303030685C3030305C3034305C303030465C3030306F5C303030725C303030655C303030635C303030615C303030735C303030745C30303073}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Death Forecasts}{14}{subsection.5.3}\protected@file@percent }
\newlabel{death-forecasts}{{5.3}{14}{Death Forecasts}{subsection.5.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces A: Distribution of weighted interval scores for two week ahead forecasts of the different models and forecast targets. Points denote single forecasts scores, while the shaded area shows an estimated probability density. B: Distribution of WIS separate by country. \DIFaddbeginFL  {\color {blue}\uwave {Black squares indicate median and black circles mean scores.}}\DIFaddendFL  }}{16}{figure.3}\protected@file@percent }
\newlabel{fig:distribution-scores}{{3}{16}{A: Distribution of weighted interval scores for two week ahead forecasts of the different models and forecast targets. Points denote single forecasts scores, while the shaded area shows an estimated probability density. B: Distribution of WIS separate by country. \DIFaddbeginFL \DIFaddFL {Black squares indicate median and black circles mean scores.}\DIFaddendFL }{figure.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Visualisation of \DIFaddbeginFL  {\color {blue}\uwave {relative }}\DIFaddendFL  aggregate performance metrics across forecast horizons for the different versions of the Hub median ensemble. “Hub-ensemble” \DIFaddbeginFL  {\color {blue}\uwave {extit}}{\DIFaddendFL  excludes\DIFaddbeginFL  } \DIFaddendFL  all our models, Hub-ensemble-all \DIFaddbeginFL  {\color {blue}\uwave {extit}}{\DIFaddendFL  includes\DIFaddbeginFL  } \DIFaddendFL  all of our models, “\DIFdelbeginFL  {\color {red}\sout {Hub-ensemble-real}}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {Hub-ensemble-realised}}\DIFaddendFL  ” is the \DIFdelbeginFL  {\color {red}\sout {real }}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {actual }}\DIFaddendFL  hub-ensemble \DIFdelbeginFL  {\color {red}\sout {with }}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {observed in reality, which includes }}\DIFaddendFL  the renewal model and the crowd forecasts\DIFdelbeginFL  {\color {red}\sout {included. Values (except for Bias) are computed as differences to }}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {, but not }}\DIFaddendFL  the \DIFdelbeginFL  {\color {red}\sout {Hub ensemble excluding our contributions}}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {convolution model}}\DIFaddendFL  . \DIFdelbeginFL  {\color {red}\sout {For Coverage, this is an absolute difference, for other metrics this is a percentage difference. }}\DIFdelendFL  A\DIFaddbeginFL  {\color {blue}\uwave {, B}}\DIFaddendFL  : mean weighted interval score (WIS) across horizons \DIFdelbeginFL  {\color {red}\sout {. B: median WIS. C: Absolute error of }}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {relative to }}\DIFaddendFL  the \DIFdelbeginFL  {\color {red}\sout {median forecast}}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {Hub ensemble (lower values indicate better performance)}}\DIFaddendFL  . \DIFaddbeginFL  {\color {blue}\uwave {C, }}\DIFaddendFL  D: \DIFdelbeginFL  {\color {red}\sout {Standard deviation }}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {Empirical coverage }}\DIFaddendFL  of the \DIFdelbeginFL  {\color {red}\sout {WIS}}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {50\% and 90\% prediction intervals minus empirical coverage observed for the Hub ensemble}}\DIFaddendFL  . E: Dispersion \DIFdelbeginFL  {\color {red}\sout {(higher }}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {relative to the dispersion of the Hub ensemble. Higher }}\DIFaddendFL  values mean greater \DIFdelbeginFL  {\color {red}\sout {spread }}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {dispersion }}\DIFaddendFL  of the forecast \DIFdelbeginFL  {\color {red}\sout {)}}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {and imply ceteris paribus a worse score}}\DIFaddendFL  . F: Bias, i.e. general \DIFaddbeginFL  {\color {blue}\uwave {(relative) }}\DIFaddendFL  tendency to over- \DIFdelbeginFL  {\color {red}\sout {or underpredict}}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {orunderpredict}}\DIFaddendFL  . Values are between -1 (complete under-prediction) and 1 (complete over-prediction) and 0 ideally. G: \DIFdelbeginFL  {\color {red}\sout {Empirical coverage }}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {Absolute error }}\DIFaddendFL  of the \DIFdelbeginFL  {\color {red}\sout {50\% prediction intervals}}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {median forecast relative to the Hub ensemble}}\DIFaddendFL  . \DIFdelbeginFL  {\color {red}\sout {F: Empirical coverage }}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {H. Standard deviation }}\DIFaddendFL  of \DIFaddbeginFL  {\color {blue}\uwave {all WIS values for different horizons relative to }}\DIFaddendFL  the \DIFdelbeginFL  {\color {red}\sout {90\% prediction intervals}}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {Hub ensemble.}}\DIFaddendFL  }}{17}{figure.4}\protected@file@percent }
\newlabel{fig:agg-performance-ensemble-rel}{{4}{17}{Visualisation of \DIFaddbeginFL \DIFaddFL {relative }\DIFaddendFL aggregate performance metrics across forecast horizons for the different versions of the Hub median ensemble. “Hub-ensemble” \DIFaddbeginFL \DIFaddFL {extit}{\DIFaddendFL excludes\DIFaddbeginFL } \DIFaddendFL all our models, Hub-ensemble-all \DIFaddbeginFL \DIFaddFL {extit}{\DIFaddendFL includes\DIFaddbeginFL } \DIFaddendFL all of our models, “\DIFdelbeginFL \DIFdelFL {Hub-ensemble-real}\DIFdelendFL \DIFaddbeginFL \DIFaddFL {Hub-ensemble-realised}\DIFaddendFL ” is the \DIFdelbeginFL \DIFdelFL {real }\DIFdelendFL \DIFaddbeginFL \DIFaddFL {actual }\DIFaddendFL hub-ensemble \DIFdelbeginFL \DIFdelFL {with }\DIFdelendFL \DIFaddbeginFL \DIFaddFL {observed in reality, which includes }\DIFaddendFL the renewal model and the crowd forecasts\DIFdelbeginFL \DIFdelFL {included. Values (except for Bias) are computed as differences to }\DIFdelendFL \DIFaddbeginFL \DIFaddFL {, but not }\DIFaddendFL the \DIFdelbeginFL \DIFdelFL {Hub ensemble excluding our contributions}\DIFdelendFL \DIFaddbeginFL \DIFaddFL {convolution model}\DIFaddendFL . \DIFdelbeginFL \DIFdelFL {For Coverage, this is an absolute difference, for other metrics this is a percentage difference. }\DIFdelendFL A\DIFaddbeginFL \DIFaddFL {, B}\DIFaddendFL : mean weighted interval score (WIS) across horizons \DIFdelbeginFL \DIFdelFL {. B: median WIS. C: Absolute error of }\DIFdelendFL \DIFaddbeginFL \DIFaddFL {relative to }\DIFaddendFL the \DIFdelbeginFL \DIFdelFL {median forecast}\DIFdelendFL \DIFaddbeginFL \DIFaddFL {Hub ensemble (lower values indicate better performance)}\DIFaddendFL . \DIFaddbeginFL \DIFaddFL {C, }\DIFaddendFL D: \DIFdelbeginFL \DIFdelFL {Standard deviation }\DIFdelendFL \DIFaddbeginFL \DIFaddFL {Empirical coverage }\DIFaddendFL of the \DIFdelbeginFL \DIFdelFL {WIS}\DIFdelendFL \DIFaddbeginFL \DIFaddFL {50\% and 90\% prediction intervals minus empirical coverage observed for the Hub ensemble}\DIFaddendFL . E: Dispersion \DIFdelbeginFL \DIFdelFL {(higher }\DIFdelendFL \DIFaddbeginFL \DIFaddFL {relative to the dispersion of the Hub ensemble. Higher }\DIFaddendFL values mean greater \DIFdelbeginFL \DIFdelFL {spread }\DIFdelendFL \DIFaddbeginFL \DIFaddFL {dispersion }\DIFaddendFL of the forecast \DIFdelbeginFL \DIFdelFL {)}\DIFdelendFL \DIFaddbeginFL \DIFaddFL {and imply ceteris paribus a worse score}\DIFaddendFL . F: Bias, i.e. general \DIFaddbeginFL \DIFaddFL {(relative) }\DIFaddendFL tendency to over- \DIFdelbeginFL \DIFdelFL {or underpredict}\DIFdelendFL \DIFaddbeginFL \DIFaddFL {orunderpredict}\DIFaddendFL . Values are between -1 (complete under-prediction) and 1 (complete over-prediction) and 0 ideally. G: \DIFdelbeginFL \DIFdelFL {Empirical coverage }\DIFdelendFL \DIFaddbeginFL \DIFaddFL {Absolute error }\DIFaddendFL of the \DIFdelbeginFL \DIFdelFL {50\% prediction intervals}\DIFdelendFL \DIFaddbeginFL \DIFaddFL {median forecast relative to the Hub ensemble}\DIFaddendFL . \DIFdelbeginFL \DIFdelFL {F: Empirical coverage }\DIFdelendFL \DIFaddbeginFL \DIFaddFL {H. Standard deviation }\DIFaddendFL of \DIFaddbeginFL \DIFaddFL {all WIS values for different horizons relative to }\DIFaddendFL the \DIFdelbeginFL \DIFdelFL {90\% prediction intervals}\DIFdelendFL \DIFaddbeginFL \DIFaddFL {Hub ensemble.}\DIFaddendFL }{figure.4}{}}
\BKM@entry{id=13,dest={73756273656374696F6E2E352E34},srcline={343}}{5C3337365C3337375C303030435C3030306F5C3030306E5C303030745C303030725C303030695C303030625C303030755C303030745C303030695C3030306F5C3030306E5C3030305C3034305C303030745C3030306F5C3030305C3034305C303030745C303030685C303030655C3030305C3034305C303030465C3030306F5C303030725C303030655C303030635C303030615C303030735C303030745C3030305C3034305C303030485C303030755C30303062}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4}Contribution to the Forecast Hub}{18}{subsection.5.4}\protected@file@percent }
\newlabel{contributions-hub}{{5.4}{18}{Contribution to the Forecast Hub}{subsection.5.4}{}}
\BKM@entry{id=14,dest={73656374696F6E2E36},srcline={356}}{5C3337365C3337375C303030445C303030695C303030735C303030635C303030755C303030735C303030735C303030695C3030306F5C3030306E}
\@writefile{toc}{\contentsline {section}{\numberline {6}Discussion}{19}{section.6}\protected@file@percent }
\newlabel{discussion}{{6}{19}{Discussion}{section.6}{}}
\BKM@entry{id=15,dest={617070656E6469782E41},srcline={392}}{5C3337365C3337375C303030535C303030755C303030705C303030705C3030306C5C303030655C3030306D5C303030655C3030306E5C303030745C303030615C303030725C303030795C3030305C3034305C303030695C3030306E5C303030665C3030306F5C303030725C3030306D5C303030615C303030745C303030695C3030306F5C3030306E}
\BKM@entry{id=16,dest={73756273656374696F6E2E412E31},srcline={395}}{5C3337365C3337375C303030535C303030635C3030306F5C303030725C303030695C3030306E5C303030675C3030305C3034305C3030306D5C303030655C303030745C303030725C303030695C303030635C303030735C3030305C3034305C303030755C303030735C303030655C30303064}
\gdef \LT@i {\LT@entry 
    {1}{83.13188pt}\LT@entry 
    {1}{381.88582pt}}
\@writefile{toc}{\contentsline {section}{\numberline {A}Supplementary information}{25}{appendix.A}\protected@file@percent }
\newlabel{supplementary-information}{{A}{25}{Supplementary information}{appendix.A}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.1}Scoring metrics used}{25}{subsection.A.1}\protected@file@percent }
\newlabel{scoring-metrics-used}{{A.1}{25}{Scoring metrics used}{subsection.A.1}{}}
\newlabel{tab:scoring-metrics}{{S1}{25}{Scoring metrics used}{table.1}{}}
\@writefile{lot}{\contentsline {table}{\numberline {S1}{Overview of the scoring metrics used.}}{25}{table.1}\protected@file@percent }
\newlabel{tab:scoring-metrics}{{S1}{26}{Scoring metrics used}{table.1}{}}
\BKM@entry{id=17,dest={73756273656374696F6E2E412E32},srcline={434}}{5C3337365C3337375C303030545C303030685C303030655C3030305C3034305C303030635C303030725C3030306F5C303030775C303030645C303030665C3030306F5C303030725C303030655C303030635C303030615C303030735C303030745C303030695C3030306E5C303030675C3030305C3034305C303030615C303030705C30303070}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.2}The crowdforecasting app}{27}{subsection.A.2}\protected@file@percent }
\newlabel{the-crowdforecasting-app}{{A.2}{27}{The crowdforecasting app}{subsection.A.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {S1}{\ignorespaces Screenshot of the crowdforecasting app used to elicit predictions (made in June 2021). }}{27}{figure.1}\protected@file@percent }
\newlabel{fig:screenshot}{{S1}{27}{Screenshot of the crowdforecasting app used to elicit predictions (made in June 2021)}{figure.1}{}}
\BKM@entry{id=18,dest={73756273656374696F6E2E412E33},srcline={443}}{5C3337365C3337375C303030465C303030755C303030725C303030745C303030685C303030655C303030725C3030305C3034305C303030645C303030655C303030745C303030615C303030695C3030306C5C303030735C3030305C3034305C3030306F5C3030306E5C3030305C3034305C303030745C303030685C303030655C3030305C3034305C303030735C303030655C3030306D5C303030695C3030302D5C3030306D5C303030655C303030635C303030685C303030615C3030306E5C303030695C303030735C303030745C303030695C303030635C3030305C3034305C303030665C3030306F5C303030725C303030655C303030635C303030615C303030735C303030745C303030695C3030306E5C303030675C3030305C3034305C3030306D5C3030306F5C303030645C303030655C3030306C5C30303073}
\BKM@entry{id=19,dest={73756273756273656374696F6E2E412E332E31},srcline={446}}{5C3337365C3337375C303030525C303030655C3030306E5C303030655C303030775C303030615C3030306C5C3030305C3034305C303030655C303030715C303030755C303030615C303030745C303030695C3030306F5C3030306E5C3030305C3034305C3030306D5C3030306F5C303030645C303030655C3030306C}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.3}Further details on the semi-mechanistic forecasting models}{28}{subsection.A.3}\protected@file@percent }
\newlabel{further-details-on-the-semi-mechanistic-forecasting-models}{{A.3}{28}{Further details on the semi-mechanistic forecasting models}{subsection.A.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {A.3.1}Renewal equation model}{28}{subsubsection.A.3.1}\protected@file@percent }
\newlabel{renewal-equation-model}{{A.3.1}{28}{Renewal equation model}{subsubsection.A.3.1}{}}
\BKM@entry{id=20,dest={73756273756273656374696F6E2E412E332E32},srcline={533}}{5C3337365C3337375C3030304D5C3030306F5C303030645C303030655C3030306C5C3030305C3034305C303030665C303030695C303030745C303030745C303030695C3030306E5C30303067}
\newlabel{convolution-model}{{A.3.1.1}{31}{Convolution model}{paragraph.A.3.1.1}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {A.3.1.1}Convolution model}{31}{paragraph.A.3.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {A.3.2}Model fitting}{31}{subsubsection.A.3.2}\protected@file@percent }
\newlabel{model-fitting}{{A.3.2}{31}{Model fitting}{subsubsection.A.3.2}{}}
\BKM@entry{id=21,dest={73756273656374696F6E2E412E34},srcline={540}}{5C3337365C3337375C303030545C303030615C303030625C3030306C5C303030655C303030735C3030305C3034305C303030775C303030695C303030745C303030685C3030305C3034305C303030725C303030655C303030735C303030755C3030306C5C303030745C303030735C3030305C3034305C3030306F5C303030665C3030305C3034305C303030745C303030685C303030655C3030305C3034305C303030665C3030306F5C303030725C303030655C303030635C303030615C303030735C303030745C3030305C3034305C303030655C303030765C303030615C3030306C5C303030755C303030615C303030745C303030695C3030306F5C3030306E}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.4}Tables with results of the forecast evaluation}{33}{subsection.A.4}\protected@file@percent }
\newlabel{tables-with-results-of-the-forecast-evaluation}{{A.4}{33}{Tables with results of the forecast evaluation}{subsection.A.4}{}}
\@writefile{lot}{\contentsline {table}{\numberline {S2}{\ignorespaces Scores for one and two week ahead forecasts (cut to three significant digits and rounded). Note that scores for cases (which include the whole period from October 12th 2020 until March 1st 2021) and deaths (which include only forecasts from the 21st of December 2020 on) are computed on different subsets. Numbers in brackets show the metrics relative to the Hub ensemble (i.e. the median ensemble of all other models submitted to the German and Polish Forecast Hub, excluding our contributions). WIS is the mean weighted interval score (lower values are better), WIS - sd is the standard deviation of all scores achieved by a model. Dispersion, over-prediction and under-prediction together sum up to the weighted interval score. Bias (between -1 and 1, 0 is ideal) represents the general average tendency of a model to over- or underpredict. 50\% and 90\%-coverage are the percentage of observed values that fell within the 50\% and 90\% prediction intervals of a model.\\\hspace  {\textwidth }}}{33}{table.2}\protected@file@percent }
\newlabel{tab:score-table-2}{{S2}{33}{Scores for one and two week ahead forecasts (cut to three significant digits and rounded). Note that scores for cases (which include the whole period from October 12th 2020 until March 1st 2021) and deaths (which include only forecasts from the 21st of December 2020 on) are computed on different subsets. Numbers in brackets show the metrics relative to the Hub ensemble (i.e. the median ensemble of all other models submitted to the German and Polish Forecast Hub, excluding our contributions). WIS is the mean weighted interval score (lower values are better), WIS - sd is the standard deviation of all scores achieved by a model. Dispersion, over-prediction and under-prediction together sum up to the weighted interval score. Bias (between -1 and 1, 0 is ideal) represents the general average tendency of a model to over- or underpredict. 50\% and 90\%-coverage are the percentage of observed values that fell within the 50\% and 90\% prediction intervals of a model.\\\hspace {\textwidth }}{table.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {S3}{\ignorespaces Scores for three and four week ahead forecasts (cut to three significant digits and rounded). Note that scores for cases (which include the whole period from October 12th 2020 until March 1st 2021) and deaths (which include only forecasts from the 21st of December 2020 on) are computed on different subsets. Numbers in brackets show the metrics relative to the Hub ensemble (i.e. the median ensemble of all other models submitted to the German and Polish Forecast Hub, excluding our contributions). WIS is the mean weighted interval score (lower values are better), WIS - sd is the standard deviation of all scores achieved by a model. Dispersion, over-prediction and under-prediction together sum up to the weighted interval score. Bias (between -1 and 1, 0 is ideal) represents the general average tendency of a model to over- or underpredict. 50\% and 90\%-coverage are the percentage of observed values that fell within the 50\% and 90\% prediction intervals of a model.\\\hspace  {\textwidth }}}{34}{table.3}\protected@file@percent }
\newlabel{tab:score-table-4}{{S3}{34}{Scores for three and four week ahead forecasts (cut to three significant digits and rounded). Note that scores for cases (which include the whole period from October 12th 2020 until March 1st 2021) and deaths (which include only forecasts from the 21st of December 2020 on) are computed on different subsets. Numbers in brackets show the metrics relative to the Hub ensemble (i.e. the median ensemble of all other models submitted to the German and Polish Forecast Hub, excluding our contributions). WIS is the mean weighted interval score (lower values are better), WIS - sd is the standard deviation of all scores achieved by a model. Dispersion, over-prediction and under-prediction together sum up to the weighted interval score. Bias (between -1 and 1, 0 is ideal) represents the general average tendency of a model to over- or underpredict. 50\% and 90\%-coverage are the percentage of observed values that fell within the 50\% and 90\% prediction intervals of a model.\\\hspace {\textwidth }}{table.3}{}}
\BKM@entry{id=22,dest={73756273656374696F6E2E412E35},srcline={637}}{5C3337365C3337375C303030415C303030675C303030675C303030725C303030655C303030675C303030615C303030745C303030655C3030305C3034305C303030705C303030655C303030725C303030665C3030306F5C303030725C3030306D5C303030615C3030306E5C303030635C303030655C3030305C3034305C303030625C303030795C3030305C3034305C3030306C5C3030306F5C303030635C303030615C303030745C303030695C3030306F5C3030306E}
\BKM@entry{id=23,dest={73756273756273656374696F6E2E412E352E31},srcline={640}}{5C3337365C3337375C303030505C303030655C303030725C303030665C3030306F5C303030725C3030306D5C303030615C3030306E5C303030635C303030655C3030305C3034305C303030695C3030306E5C3030305C3034305C303030475C303030655C303030725C3030306D5C303030615C3030306E5C30303079}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.5}Aggregate performance by location}{36}{subsection.A.5}\protected@file@percent }
\newlabel{aggregate-performance-by-location}{{A.5}{36}{Aggregate performance by location}{subsection.A.5}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {A.5.1}Performance in Germany}{36}{subsubsection.A.5.1}\protected@file@percent }
\newlabel{performance-in-germany}{{A.5.1}{36}{Performance in Germany}{subsubsection.A.5.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {S2}{\ignorespaces {\color {blue}\uwave {Visualisation of aggregate performance metrics for forecasts one to four weeks into the future in Germany. A, B: mean weighted interval score (WIS, lower indicates better performance) across horizons. WIS is decomposed into its components dispersion, over-prediction and under-prediction. C: Empirical coverage of the 50\% prediction intervals (50\% coverage is perfect). D: Empirical coverage of the 90\% prediction intervals. E: Dispersion (same as in panel A, B). Higher values mean greater dispersion of the forecast and imply ceteris paribus a worse score. F: Bias, i.e. general (relative) tendency to over- or underpredict. Values are between -1 (complete under-prediction) and 1 (complete over-prediction) and 0 ideally. G: Absolute error of the median forecast (lower is better). H. Standard deviation of all WIS values for different horizons}}}}{36}{figure.2}\protected@file@percent }
\newlabel{fig:agg-performance-all-Germany}{{S2}{36}{\DIFaddFL {Visualisation of aggregate performance metrics for forecasts one to four weeks into the future in Germany. A, B: mean weighted interval score (WIS, lower indicates better performance) across horizons. WIS is decomposed into its components dispersion, over-prediction and under-prediction. C: Empirical coverage of the 50\% prediction intervals (50\% coverage is perfect). D: Empirical coverage of the 90\% prediction intervals. E: Dispersion (same as in panel A, B). Higher values mean greater dispersion of the forecast and imply ceteris paribus a worse score. F: Bias, i.e. general (relative) tendency to over- or underpredict. Values are between -1 (complete under-prediction) and 1 (complete over-prediction) and 0 ideally. G: Absolute error of the median forecast (lower is better). H. Standard deviation of all WIS values for different horizons}}{figure.2}{}}
\BKM@entry{id=24,dest={73756273756273656374696F6E2E412E352E32},srcline={647}}{5C3337365C3337375C303030505C303030655C303030725C303030665C3030306F5C303030725C3030306D5C303030615C3030306E5C303030635C303030655C3030305C3034305C303030695C3030306E5C3030305C3034305C303030505C3030306F5C3030306C5C303030615C3030306E5C30303064}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {A.5.2}Performance in Poland}{38}{subsubsection.A.5.2}\protected@file@percent }
\newlabel{performance-in-poland}{{A.5.2}{38}{Performance in Poland}{subsubsection.A.5.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {S3}{\ignorespaces {\color {blue}\uwave {Visualisation of aggregate performance metrics for forecasts one to four weeks into the future in Poland. A, B: mean weighted interval score (WIS, lower indicates better performance) across horizons. WIS is decomposed into its components dispersion, over-prediction and under-prediction. C: Empirical coverage of the 50\% prediction intervals (50\% coverage is perfect). D: Empirical coverage of the 90\% prediction intervals. E: Dispersion (same as in panel A, B). Higher values mean greater dispersion of the forecast and imply ceteris paribus a worse score. F: Bias, i.e. general (relative) tendency to over- or underpredict. Values are between -1 (complete under-prediction) and 1 (complete over-prediction) and 0 ideally. G: Absolute error of the median forecast (lower is better). H. Standard deviation of all WIS values for different horizons}}}}{38}{figure.3}\protected@file@percent }
\newlabel{fig:agg-performance-all-Poland}{{S3}{38}{\DIFaddFL {Visualisation of aggregate performance metrics for forecasts one to four weeks into the future in Poland. A, B: mean weighted interval score (WIS, lower indicates better performance) across horizons. WIS is decomposed into its components dispersion, over-prediction and under-prediction. C: Empirical coverage of the 50\% prediction intervals (50\% coverage is perfect). D: Empirical coverage of the 90\% prediction intervals. E: Dispersion (same as in panel A, B). Higher values mean greater dispersion of the forecast and imply ceteris paribus a worse score. F: Bias, i.e. general (relative) tendency to over- or underpredict. Values are between -1 (complete under-prediction) and 1 (complete over-prediction) and 0 ideally. G: Absolute error of the median forecast (lower is better). H. Standard deviation of all WIS values for different horizons}}{figure.3}{}}
\BKM@entry{id=25,dest={73756273756273656374696F6E2E412E352E33},srcline={654}}{5C3337365C3337375C303030505C303030655C303030725C303030665C3030306F5C303030725C3030306D5C303030615C3030306E5C303030635C303030655C3030305C3034305C303030615C303030635C303030725C3030306F5C303030735C303030735C3030305C3034305C3030306C5C3030306F5C303030635C303030615C303030745C303030695C3030306F5C3030306E5C303030735C3030305C3034305C303030695C3030306E5C3030305C3034305C303030615C303030625C303030735C3030306F5C3030306C5C303030755C303030745C303030655C3030305C3034305C303030745C303030655C303030725C3030306D5C30303073}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {A.5.3}Performance across locations in absolute terms}{40}{subsubsection.A.5.3}\protected@file@percent }
\newlabel{performance-across-locations-in-absolute-terms}{{A.5.3}{40}{Performance across locations in absolute terms}{subsubsection.A.5.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {S4}{\ignorespaces Visualisation of aggregate performance metrics across locations. A\DIFaddbeginFL  {\color {blue}\uwave {, B}}\DIFaddendFL  : mean weighted interval score (WIS\DIFaddbeginFL  {\color {blue}\uwave {, lower indicates better performance}}\DIFaddendFL  ) across horizons. \DIFdelbeginFL  {\color {red}\sout {B: median }}\DIFdelendFL  WIS \DIFaddbeginFL  {\color {blue}\uwave {is decomposed into its components dispersion, over-prediction and under-prediction}}\DIFaddendFL  . C: \DIFdelbeginFL  {\color {red}\sout {Absolute error }}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {Empirical coverage }}\DIFaddendFL  of the \DIFdelbeginFL  {\color {red}\sout {median forecast}}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {50\% prediction intervals (50\% coverage is perfect)}}\DIFaddendFL  . D: \DIFdelbeginFL  {\color {red}\sout {Standard deviation }}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {Empirical coverage }}\DIFaddendFL  of the \DIFdelbeginFL  {\color {red}\sout {WIS}}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {90\% prediction intervals}}\DIFaddendFL  . E: Dispersion (\DIFdelbeginFL  {\color {red}\sout {higher }}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {same as in panel A, B). Higher }}\DIFaddendFL  values mean \DIFdelbeginFL  {\color {red}\sout {further spread out }}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {greater dispersion of the }}\DIFaddendFL  forecast \DIFdelbeginFL  {\color {red}\sout {)}}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {and imply ceteris paribus a worse score}}\DIFaddendFL  . F: Bias, i.e. general \DIFaddbeginFL  {\color {blue}\uwave {(relative) }}\DIFaddendFL  tendency to over- or underpredict. Values are between -1 (complete under-prediction) and 1 (complete over-prediction) and 0 ideally. G: \DIFdelbeginFL  {\color {red}\sout {Empirical coverage }}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {Absolute error }}\DIFaddendFL  of the \DIFdelbeginFL  {\color {red}\sout {50\% prediction intervals}}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {median forecast (lower is better)}}\DIFaddendFL  . \DIFdelbeginFL  {\color {red}\sout {F: Empirical coverage }}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {H. Standard deviation }}\DIFaddendFL  of \DIFdelbeginFL  {\color {red}\sout {the 90\% prediction intervals}}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {WIS values}}\DIFaddendFL  .}}{40}{figure.4}\protected@file@percent }
\newlabel{fig:performance-locations}{{S4}{40}{Visualisation of aggregate performance metrics across locations. A\DIFaddbeginFL \DIFaddFL {, B}\DIFaddendFL : mean weighted interval score (WIS\DIFaddbeginFL \DIFaddFL {, lower indicates better performance}\DIFaddendFL ) across horizons. \DIFdelbeginFL \DIFdelFL {B: median }\DIFdelendFL WIS \DIFaddbeginFL \DIFaddFL {is decomposed into its components dispersion, over-prediction and under-prediction}\DIFaddendFL . C: \DIFdelbeginFL \DIFdelFL {Absolute error }\DIFdelendFL \DIFaddbeginFL \DIFaddFL {Empirical coverage }\DIFaddendFL of the \DIFdelbeginFL \DIFdelFL {median forecast}\DIFdelendFL \DIFaddbeginFL \DIFaddFL {50\% prediction intervals (50\% coverage is perfect)}\DIFaddendFL . D: \DIFdelbeginFL \DIFdelFL {Standard deviation }\DIFdelendFL \DIFaddbeginFL \DIFaddFL {Empirical coverage }\DIFaddendFL of the \DIFdelbeginFL \DIFdelFL {WIS}\DIFdelendFL \DIFaddbeginFL \DIFaddFL {90\% prediction intervals}\DIFaddendFL . E: Dispersion (\DIFdelbeginFL \DIFdelFL {higher }\DIFdelendFL \DIFaddbeginFL \DIFaddFL {same as in panel A, B). Higher }\DIFaddendFL values mean \DIFdelbeginFL \DIFdelFL {further spread out }\DIFdelendFL \DIFaddbeginFL \DIFaddFL {greater dispersion of the }\DIFaddendFL forecast \DIFdelbeginFL \DIFdelFL {)}\DIFdelendFL \DIFaddbeginFL \DIFaddFL {and imply ceteris paribus a worse score}\DIFaddendFL . F: Bias, i.e. general \DIFaddbeginFL \DIFaddFL {(relative) }\DIFaddendFL tendency to over- or underpredict. Values are between -1 (complete under-prediction) and 1 (complete over-prediction) and 0 ideally. G: \DIFdelbeginFL \DIFdelFL {Empirical coverage }\DIFdelendFL \DIFaddbeginFL \DIFaddFL {Absolute error }\DIFaddendFL of the \DIFdelbeginFL \DIFdelFL {50\% prediction intervals}\DIFdelendFL \DIFaddbeginFL \DIFaddFL {median forecast (lower is better)}\DIFaddendFL . \DIFdelbeginFL \DIFdelFL {F: Empirical coverage }\DIFdelendFL \DIFaddbeginFL \DIFaddFL {H. Standard deviation }\DIFaddendFL of \DIFdelbeginFL \DIFdelFL {the 90\% prediction intervals}\DIFdelendFL \DIFaddbeginFL \DIFaddFL {WIS values}\DIFaddendFL }{figure.4}{}}
\BKM@entry{id=26,dest={73756273656374696F6E2E412E36},srcline={661}}{5C3337365C3337375C303030505C303030655C303030725C303030665C3030306F5C303030725C3030306D5C303030615C3030306E5C303030635C303030655C3030305C3034305C303030615C303030635C303030725C3030306F5C303030735C303030735C3030305C3034305C3030306C5C3030306F5C303030635C303030615C303030745C303030695C3030306F5C3030306E5C303030735C3030305C3034305C303030695C3030306E5C3030305C3034305C303030725C303030655C3030306C5C303030615C303030745C303030695C303030765C303030655C3030305C3034305C303030745C303030655C303030725C3030306D5C30303073}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.6}Performance across locations in relative terms}{42}{subsection.A.6}\protected@file@percent }
\newlabel{performance-across-locations-in-relative-terms}{{A.6}{42}{Performance across locations in relative terms}{subsection.A.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {S5}{\ignorespaces Visualisation of \DIFaddbeginFL  {\color {blue}\uwave {relative }}\DIFaddendFL  aggregate performance metrics across locations\DIFdelbeginFL  {\color {red}\sout {relative to the Hub ensemble (excluding our contributions)}}\DIFdelendFL  . A\DIFaddbeginFL  {\color {blue}\uwave {, B}}\DIFaddendFL  : mean weighted interval score (WIS) across \DIFdelbeginFL  {\color {red}\sout {horizons}}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {locations (lower values indicate better performance)}}\DIFaddendFL  . \DIFdelbeginFL  {\color {red}\sout {B: median WIS. }}\DIFdelendFL  C\DIFdelbeginFL  {\color {red}\sout {: Absolute error of the median forecast. }}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {, }}\DIFaddendFL  D: \DIFdelbeginFL  {\color {red}\sout {Standard deviation }}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {Empirical coverage }}\DIFaddendFL  of the \DIFdelbeginFL  {\color {red}\sout {WIS}}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {50\% and 90\% prediction intervals}}\DIFaddendFL  . E: Dispersion\DIFdelbeginFL  {\color {red}\sout {(higher }}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {. Higher }}\DIFaddendFL  values mean \DIFdelbeginFL  {\color {red}\sout {further spread out }}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {greater dispersion of the }}\DIFaddendFL  forecast \DIFdelbeginFL  {\color {red}\sout {)}}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {and imply ceteris paribus a worse score}}\DIFaddendFL  . F: Bias, i.e. general \DIFaddbeginFL  {\color {blue}\uwave {(relative) }}\DIFaddendFL  tendency to over- \DIFdelbeginFL  {\color {red}\sout {or underpredict}}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {orunderpredict}}\DIFaddendFL  . Values are between -1 (complete under-prediction) and 1 (complete over-prediction) and 0 ideally. G: \DIFdelbeginFL  {\color {red}\sout {Empirical coverage }}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {Absolute error }}\DIFaddendFL  of the \DIFdelbeginFL  {\color {red}\sout {50\% prediction intervals}}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {median forecast}}\DIFaddendFL  . \DIFdelbeginFL  {\color {red}\sout {F: Empirical coverage }}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {H. Standard deviation }}\DIFaddendFL  of \DIFdelbeginFL  {\color {red}\sout {the 90\% prediction intervals}}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {WIS values}}\DIFaddendFL  .}}{42}{figure.5}\protected@file@percent }
\newlabel{fig:performance-locations-rel}{{S5}{42}{Visualisation of \DIFaddbeginFL \DIFaddFL {relative }\DIFaddendFL aggregate performance metrics across locations\DIFdelbeginFL \DIFdelFL {relative to the Hub ensemble (excluding our contributions)}\DIFdelendFL . A\DIFaddbeginFL \DIFaddFL {, B}\DIFaddendFL : mean weighted interval score (WIS) across \DIFdelbeginFL \DIFdelFL {horizons}\DIFdelendFL \DIFaddbeginFL \DIFaddFL {locations (lower values indicate better performance)}\DIFaddendFL . \DIFdelbeginFL \DIFdelFL {B: median WIS. }\DIFdelendFL C\DIFdelbeginFL \DIFdelFL {: Absolute error of the median forecast. }\DIFdelendFL \DIFaddbeginFL \DIFaddFL {, }\DIFaddendFL D: \DIFdelbeginFL \DIFdelFL {Standard deviation }\DIFdelendFL \DIFaddbeginFL \DIFaddFL {Empirical coverage }\DIFaddendFL of the \DIFdelbeginFL \DIFdelFL {WIS}\DIFdelendFL \DIFaddbeginFL \DIFaddFL {50\% and 90\% prediction intervals}\DIFaddendFL . E: Dispersion\DIFdelbeginFL \DIFdelFL {(higher }\DIFdelendFL \DIFaddbeginFL \DIFaddFL {. Higher }\DIFaddendFL values mean \DIFdelbeginFL \DIFdelFL {further spread out }\DIFdelendFL \DIFaddbeginFL \DIFaddFL {greater dispersion of the }\DIFaddendFL forecast \DIFdelbeginFL \DIFdelFL {)}\DIFdelendFL \DIFaddbeginFL \DIFaddFL {and imply ceteris paribus a worse score}\DIFaddendFL . F: Bias, i.e. general \DIFaddbeginFL \DIFaddFL {(relative) }\DIFaddendFL tendency to over- \DIFdelbeginFL \DIFdelFL {or underpredict}\DIFdelendFL \DIFaddbeginFL \DIFaddFL {orunderpredict}\DIFaddendFL . Values are between -1 (complete under-prediction) and 1 (complete over-prediction) and 0 ideally. G: \DIFdelbeginFL \DIFdelFL {Empirical coverage }\DIFdelendFL \DIFaddbeginFL \DIFaddFL {Absolute error }\DIFaddendFL of the \DIFdelbeginFL \DIFdelFL {50\% prediction intervals}\DIFdelendFL \DIFaddbeginFL \DIFaddFL {median forecast}\DIFaddendFL . \DIFdelbeginFL \DIFdelFL {F: Empirical coverage }\DIFdelendFL \DIFaddbeginFL \DIFaddFL {H. Standard deviation }\DIFaddendFL of \DIFdelbeginFL \DIFdelFL {the 90\% prediction intervals}\DIFdelendFL \DIFaddbeginFL \DIFaddFL {WIS values}\DIFaddendFL }{figure.5}{}}
\BKM@entry{id=27,dest={73756273656374696F6E2E412E37},srcline={670}}{5C3337365C3337375C303030565C303030695C303030735C303030755C303030615C3030306C5C303030695C303030735C303030615C303030745C303030695C3030306F5C3030306E5C3030305C3034305C3030306F5C303030665C3030305C3034305C303030645C303030615C303030695C3030306C5C303030795C3030305C3034305C303030725C303030655C303030705C3030306F5C303030725C303030745C303030655C303030645C3030305C3034305C303030635C303030615C303030735C303030655C303030735C3030305C3034305C303030615C3030306E5C303030645C3030305C3034305C303030645C303030655C303030615C303030745C303030685C30303073}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.7}Visualisation of daily reported cases and deaths}{43}{subsection.A.7}\protected@file@percent }
\newlabel{visualisation-of-daily-reported-cases-and-deaths}{{A.7}{43}{Visualisation of daily reported cases and deaths}{subsection.A.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {S6}{\ignorespaces Visualisation of daily report data. The black line represents weekly data divided by seven. Data were last accessed through the German and Polish Forecast Hub on August 21 2021.}}{43}{figure.6}\protected@file@percent }
\newlabel{fig:daily-truth}{{S6}{43}{Visualisation of daily report data. The black line represents weekly data divided by seven. Data were last accessed through the German and Polish Forecast Hub on August 21 2021}{figure.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {S7}{\ignorespaces {\color {blue}\uwave {Visualisation of the absolute difference between the daily report data at the time and the data now. In Germany, there were zero cases and deaths reported on 2020-10-12, and only later 2467 cases and 6 deaths were added. Data were last accessed through the German and Polish Forecast Hub on May 10 2022.}}}}{44}{figure.7}\protected@file@percent }
\newlabel{fig:daily-truth-update}{{S7}{44}{\DIFaddFL {Visualisation of the absolute difference between the daily report data at the time and the data now. In Germany, there were zero cases and deaths reported on 2020-10-12, and only later 2467 cases and 6 deaths were added. Data were last accessed through the German and Polish Forecast Hub on May 10 2022.}}{figure.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {S8}{\ignorespaces {\color {blue}\uwave {Visualisation of the relative difference between the weekly report data at the time and the data now. Apart from the data that was retrospectively added on 2020-10-12, data updates did not have a noticeable effect on weekly data (as shown in the forecasting application). Data were last accessed through the German and Polish Forecast Hub on May 10 2022.}}}}{45}{figure.8}\protected@file@percent }
\newlabel{fig:weekly-truth-update}{{S8}{45}{\DIFaddFL {Visualisation of the relative difference between the weekly report data at the time and the data now. Apart from the data that was retrospectively added on 2020-10-12, data updates did not have a noticeable effect on weekly data (as shown in the forecasting application). Data were last accessed through the German and Polish Forecast Hub on May 10 2022.}}{figure.8}{}}
\BKM@entry{id=28,dest={73756273656374696F6E2E412E38},srcline={687}}{5C3337365C3337375C303030565C303030695C303030735C303030755C303030615C3030306C5C303030695C303030735C303030615C303030745C303030695C3030306F5C3030306E5C3030305C3034305C3030306F5C303030665C3030305C3034305C303030735C303030635C3030306F5C303030725C303030655C303030735C3030305C3034305C303030615C3030306E5C303030645C3030305C3034305C303030665C3030306F5C303030725C303030655C303030635C303030615C303030735C303030745C303030735C3030305C3034305C303030315C3030302C5C3030305C3034305C303030335C3030302C5C3030305C3034305C303030345C3030305C3034305C303030775C303030655C303030655C3030306B5C303030735C3030305C3034305C303030615C303030685C303030655C303030615C30303064}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.8}Visualisation of scores and forecasts 1, 3, 4 weeks ahead}{46}{subsection.A.8}\protected@file@percent }
\newlabel{visualisation-of-scores-and-forecasts-1-3-4-weeks-ahead}{{A.8}{46}{Visualisation of scores and forecasts 1, 3, 4 weeks ahead}{subsection.A.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {S9}{\ignorespaces A, C: Visualisation of 50\% prediction intervals of one week ahead forecasts against the reported values. Forecasts that were not scored (because there was no complete set of death forecasts available) are greyed out. B, D: Visualisation of corresponding WIS.}}{46}{figure.9}\protected@file@percent }
\newlabel{fig:forecasts-and-truth-1}{{S9}{46}{A, C: Visualisation of 50\% prediction intervals of one week ahead forecasts against the reported values. Forecasts that were not scored (because there was no complete set of death forecasts available) are greyed out. B, D: Visualisation of corresponding WIS}{figure.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {S10}{\ignorespaces A, C: Visualisation of 50\% prediction intervals of three week ahead forecasts against the reported values. Forecasts that were not scored (because there was no complete set of death forecasts available) are greyed out. B, D: Visualisation of corresponding WIS.}}{47}{figure.10}\protected@file@percent }
\newlabel{fig:forecasts-and-truth-3}{{S10}{47}{A, C: Visualisation of 50\% prediction intervals of three week ahead forecasts against the reported values. Forecasts that were not scored (because there was no complete set of death forecasts available) are greyed out. B, D: Visualisation of corresponding WIS}{figure.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {S11}{\ignorespaces A, C: Visualisation of 50\% prediction intervals of four week ahead forecasts against the reported values. Forecasts that were not scored (because there was no complete set of death forecasts available) are greyed out. B, D: Visualisation of corresponding WIS.}}{48}{figure.11}\protected@file@percent }
\newlabel{fig:forecasts-and-truth-4}{{S11}{48}{A, C: Visualisation of 50\% prediction intervals of four week ahead forecasts against the reported values. Forecasts that were not scored (because there was no complete set of death forecasts available) are greyed out. B, D: Visualisation of corresponding WIS}{figure.11}{}}
\BKM@entry{id=29,dest={73756273656374696F6E2E412E39},srcline={704}}{5C3337365C3337375C303030445C303030695C303030735C303030745C303030725C303030695C303030625C303030755C303030745C303030695C3030306F5C3030306E5C3030305C3034305C3030306F5C303030665C3030305C3034305C303030735C303030635C3030306F5C303030725C303030655C30303073}
\BKM@entry{id=30,dest={73756273756273656374696F6E2E412E392E31},srcline={707}}{5C3337365C3337375C303030415C303030625C303030735C3030306F5C3030306C5C303030755C303030745C303030655C3030305C3034305C303030735C303030635C3030306F5C303030725C303030655C30303073}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.9}Distribution of scores}{49}{subsection.A.9}\protected@file@percent }
\newlabel{distribution-of-scores}{{A.9}{49}{Distribution of scores}{subsection.A.9}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {A.9.1}Absolute scores}{49}{subsubsection.A.9.1}\protected@file@percent }
\newlabel{absolute-scores}{{A.9.1}{49}{Absolute scores}{subsubsection.A.9.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {S12}{\ignorespaces A: Distribution of weighted interval scores for one week ahead forecasts of the different models and forecast targets. B: Distribution of WIS separate by country.}}{49}{figure.12}\protected@file@percent }
\newlabel{fig:distribution-scores-1}{{S12}{49}{A: Distribution of weighted interval scores for one week ahead forecasts of the different models and forecast targets. B: Distribution of WIS separate by country}{figure.12}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {S13}{\ignorespaces A: Distribution of weighted interval scores for three week ahead forecasts of the different models and forecast targets. B: Distribution of WIS separate by country.}}{50}{figure.13}\protected@file@percent }
\newlabel{fig:distribution-scores-3}{{S13}{50}{A: Distribution of weighted interval scores for three week ahead forecasts of the different models and forecast targets. B: Distribution of WIS separate by country}{figure.13}{}}
\BKM@entry{id=31,dest={73756273756273656374696F6E2E412E392E32},srcline={722}}{5C3337365C3337375C303030525C303030615C3030306E5C3030306B5C303030735C3030305C3034305C303030615C303030635C303030685C303030695C303030655C303030765C303030655C303030645C3030305C3034305C303030625C303030795C3030305C3034305C303030665C3030306F5C303030725C303030655C303030635C303030615C303030735C303030745C30303073}
\@writefile{lof}{\contentsline {figure}{\numberline {S14}{\ignorespaces A: Distribution of weighted interval scores for four week ahead forecasts of the different models and forecast targets. B: Distribution of WIS separate by country.}}{51}{figure.14}\protected@file@percent }
\newlabel{fig:distribution-scores-4}{{S14}{51}{A: Distribution of weighted interval scores for four week ahead forecasts of the different models and forecast targets. B: Distribution of WIS separate by country}{figure.14}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {A.9.2}Ranks achieved by forecasts}{52}{subsubsection.A.9.2}\protected@file@percent }
\newlabel{ranks-achieved-by-forecasts}{{A.9.2}{52}{Ranks achieved by forecasts}{subsubsection.A.9.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {S15}{\ignorespaces A: Distribution of the ranks (determined by the weighted interval score) for one week ahead forecasts of the different models and forecast targets. B: Distribution of ranks separate by country.}}{52}{figure.15}\protected@file@percent }
\newlabel{fig:distribution-scores-ranks-1}{{S15}{52}{A: Distribution of the ranks (determined by the weighted interval score) for one week ahead forecasts of the different models and forecast targets. B: Distribution of ranks separate by country}{figure.15}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {S16}{\ignorespaces A: Distribution of the ranks (determined by the weighted interval score) for two week ahead forecasts of the different models and forecast targets. B: Distribution of ranks separate by country.}}{53}{figure.16}\protected@file@percent }
\newlabel{fig:distribution-scores-ranks-2}{{S16}{53}{A: Distribution of the ranks (determined by the weighted interval score) for two week ahead forecasts of the different models and forecast targets. B: Distribution of ranks separate by country}{figure.16}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {S17}{\ignorespaces A: Distribution of the ranks (determined by the weighted interval score) for three week ahead forecasts of the different models and forecast targets. B: Distribution of ranks separate by country.}}{54}{figure.17}\protected@file@percent }
\newlabel{fig:distribution-scores-ranks-3}{{S17}{54}{A: Distribution of the ranks (determined by the weighted interval score) for three week ahead forecasts of the different models and forecast targets. B: Distribution of ranks separate by country}{figure.17}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {S18}{\ignorespaces A: Distribution of the ranks (determined by the weighted interval score) for four week ahead forecasts of the different models and forecast targets. B: Distribution of ranks separate by country.}}{55}{figure.18}\protected@file@percent }
\newlabel{fig:distribution-scores-ranks-4}{{S18}{55}{A: Distribution of the ranks (determined by the weighted interval score) for four week ahead forecasts of the different models and forecast targets. B: Distribution of ranks separate by country}{figure.18}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {S19}{\ignorespaces {\color {blue}\uwave {Density plot with the difference in WIS between the Crowd forecast and the Hub ensemble (values below zero mean better performance of the Crowd forecasts) for a 2 week ahead forecast horizon.}}}}{56}{figure.19}\protected@file@percent }
\newlabel{fig:distribution-scores-differences}{{S19}{56}{\DIFaddFL {Density plot with the difference in WIS between the Crowd forecast and the Hub ensemble (values below zero mean better performance of the Crowd forecasts) for a 2 week ahead forecast horizon.}}{figure.19}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {S20}{\ignorespaces {\color {blue}\uwave {Density plot with the difference in WIS between the Crowd forecast and the Renewal model (values below zero mean better performance of the Crowd forecasts) for a 2 week ahead forecast horizon.}}}}{56}{figure.20}\protected@file@percent }
\newlabel{fig:distribution-scores-differences-renewal}{{S20}{56}{\DIFaddFL {Density plot with the difference in WIS between the Crowd forecast and the Renewal model (values below zero mean better performance of the Crowd forecasts) for a 2 week ahead forecast horizon.}}{figure.20}{}}
\BKM@entry{id=32,dest={73756273656374696F6E2E412E3130},srcline={754}}{5C3337365C3337375C303030435C3030306F5C3030306D5C303030705C303030615C303030725C303030695C303030735C3030306F5C3030306E5C3030305C3034305C3030306F5C303030665C3030305C3034305C303030655C3030306E5C303030735C303030655C3030306D5C303030625C3030306C5C303030655C30303073}
\BKM@entry{id=33,dest={73756273756273656374696F6E2E412E31302E31},srcline={757}}{5C3337365C3337375C303030505C303030655C303030725C303030665C3030306F5C303030725C3030306D5C303030615C3030306E5C303030635C303030655C3030305C3034305C303030765C303030695C303030735C303030755C303030615C3030306C5C303030695C303030735C303030615C303030745C303030695C3030306F5C3030306E5C3030305C3034305C3030306D5C303030655C303030615C3030306E5C3030305C3034305C303030655C3030306E5C303030735C303030655C3030306D5C303030625C3030306C5C30303065}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.10}Comparison of ensembles}{58}{subsection.A.10}\protected@file@percent }
\newlabel{comparison-of-ensembles}{{A.10}{58}{Comparison of ensembles}{subsection.A.10}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {A.10.1}Performance visualisation mean ensemble}{58}{subsubsection.A.10.1}\protected@file@percent }
\newlabel{performance-visualisation-mean-ensemble}{{A.10.1}{58}{Performance visualisation mean ensemble}{subsubsection.A.10.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {S21}{\ignorespaces Visualisation of aggregate performance metrics across forecast horizons for the different versions of the Hub mean ensemble. “Hub-ensemble” \DIFaddbeginFL  {\color {blue}\uwave {extit}}{\DIFaddendFL  excludes\DIFaddbeginFL  } \DIFaddendFL  all our models, Hub-ensemble-all \DIFaddbeginFL  {\color {blue}\uwave {extit}}{\DIFaddendFL  includes\DIFaddbeginFL  } \DIFaddendFL  all of our models, “\DIFdelbeginFL  {\color {red}\sout {Hub-ensemble-real}}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {Hub-ensemble-realised}}\DIFaddendFL  ” is the \DIFdelbeginFL  {\color {red}\sout {real }}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {actual }}\DIFaddendFL  hub-ensemble \DIFdelbeginFL  {\color {red}\sout {with }}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {observed in reality, which includes }}\DIFaddendFL  the renewal model and the crowd forecasts\DIFdelbeginFL  {\color {red}\sout {included}}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {, but ont the convolution model}}\DIFaddendFL  . Values (except for Bias) are computed as differences to the Hub ensemble \DIFdelbeginFL  {\color {red}\sout {excluding }}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {which excludes }}\DIFaddendFL  our contributions. For Coverage, this is an absolute difference, for other metrics this is a percentage difference. A\DIFaddbeginFL  {\color {blue}\uwave {, B}}\DIFaddendFL  : mean weighted interval score (WIS) across horizons \DIFdelbeginFL  {\color {red}\sout {. B: median WIS. C: Absolute error of }}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {relative to }}\DIFaddendFL  the \DIFdelbeginFL  {\color {red}\sout {median forecast}}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {Hub ensemble (lower values indicate better performance)}}\DIFaddendFL  . \DIFaddbeginFL  {\color {blue}\uwave {C, }}\DIFaddendFL  D: \DIFdelbeginFL  {\color {red}\sout {Standard deviation }}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {Empirical coverage }}\DIFaddendFL  of the \DIFdelbeginFL  {\color {red}\sout {WIS}}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {50\% and 90\% prediction intervals minus empirical coverage observed for the Hub ensemble}}\DIFaddendFL  . E: Dispersion \DIFdelbeginFL  {\color {red}\sout {(higher }}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {relative to the dispersion of the Hub ensemble. Higher }}\DIFaddendFL  values mean greater \DIFdelbeginFL  {\color {red}\sout {spread }}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {dispersion }}\DIFaddendFL  of the forecast \DIFdelbeginFL  {\color {red}\sout {)}}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {and imply ceteris paribus a worse score}}\DIFaddendFL  . F: Bias, i.e. general \DIFaddbeginFL  {\color {blue}\uwave {(relative) }}\DIFaddendFL  tendency to over- \DIFdelbeginFL  {\color {red}\sout {or underpredict}}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {orunderpredict}}\DIFaddendFL  . Values are between -1 (complete under-prediction) and 1 (complete over-prediction) and 0 ideally. G: \DIFdelbeginFL  {\color {red}\sout {Empirical coverage }}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {Absolute error }}\DIFaddendFL  of the \DIFdelbeginFL  {\color {red}\sout {50\% prediction intervals}}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {median forecast relative to the Hub ensemble}}\DIFaddendFL  . \DIFdelbeginFL  {\color {red}\sout {F: Empirical coverage }}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {H. Standard deviation }}\DIFaddendFL  of \DIFaddbeginFL  {\color {blue}\uwave {all WIS values for different horizons relative to }}\DIFaddendFL  the \DIFdelbeginFL  {\color {red}\sout {90\% prediction intervals}}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {Hub ensemble.}}\DIFaddendFL  }}{58}{figure.21}\protected@file@percent }
\newlabel{fig:agg-performance-ensemble-mean}{{S21}{58}{Visualisation of aggregate performance metrics across forecast horizons for the different versions of the Hub mean ensemble. “Hub-ensemble” \DIFaddbeginFL \DIFaddFL {extit}{\DIFaddendFL excludes\DIFaddbeginFL } \DIFaddendFL all our models, Hub-ensemble-all \DIFaddbeginFL \DIFaddFL {extit}{\DIFaddendFL includes\DIFaddbeginFL } \DIFaddendFL all of our models, “\DIFdelbeginFL \DIFdelFL {Hub-ensemble-real}\DIFdelendFL \DIFaddbeginFL \DIFaddFL {Hub-ensemble-realised}\DIFaddendFL ” is the \DIFdelbeginFL \DIFdelFL {real }\DIFdelendFL \DIFaddbeginFL \DIFaddFL {actual }\DIFaddendFL hub-ensemble \DIFdelbeginFL \DIFdelFL {with }\DIFdelendFL \DIFaddbeginFL \DIFaddFL {observed in reality, which includes }\DIFaddendFL the renewal model and the crowd forecasts\DIFdelbeginFL \DIFdelFL {included}\DIFdelendFL \DIFaddbeginFL \DIFaddFL {, but ont the convolution model}\DIFaddendFL . Values (except for Bias) are computed as differences to the Hub ensemble \DIFdelbeginFL \DIFdelFL {excluding }\DIFdelendFL \DIFaddbeginFL \DIFaddFL {which excludes }\DIFaddendFL our contributions. For Coverage, this is an absolute difference, for other metrics this is a percentage difference. A\DIFaddbeginFL \DIFaddFL {, B}\DIFaddendFL : mean weighted interval score (WIS) across horizons \DIFdelbeginFL \DIFdelFL {. B: median WIS. C: Absolute error of }\DIFdelendFL \DIFaddbeginFL \DIFaddFL {relative to }\DIFaddendFL the \DIFdelbeginFL \DIFdelFL {median forecast}\DIFdelendFL \DIFaddbeginFL \DIFaddFL {Hub ensemble (lower values indicate better performance)}\DIFaddendFL . \DIFaddbeginFL \DIFaddFL {C, }\DIFaddendFL D: \DIFdelbeginFL \DIFdelFL {Standard deviation }\DIFdelendFL \DIFaddbeginFL \DIFaddFL {Empirical coverage }\DIFaddendFL of the \DIFdelbeginFL \DIFdelFL {WIS}\DIFdelendFL \DIFaddbeginFL \DIFaddFL {50\% and 90\% prediction intervals minus empirical coverage observed for the Hub ensemble}\DIFaddendFL . E: Dispersion \DIFdelbeginFL \DIFdelFL {(higher }\DIFdelendFL \DIFaddbeginFL \DIFaddFL {relative to the dispersion of the Hub ensemble. Higher }\DIFaddendFL values mean greater \DIFdelbeginFL \DIFdelFL {spread }\DIFdelendFL \DIFaddbeginFL \DIFaddFL {dispersion }\DIFaddendFL of the forecast \DIFdelbeginFL \DIFdelFL {)}\DIFdelendFL \DIFaddbeginFL \DIFaddFL {and imply ceteris paribus a worse score}\DIFaddendFL . F: Bias, i.e. general \DIFaddbeginFL \DIFaddFL {(relative) }\DIFaddendFL tendency to over- \DIFdelbeginFL \DIFdelFL {or underpredict}\DIFdelendFL \DIFaddbeginFL \DIFaddFL {orunderpredict}\DIFaddendFL . Values are between -1 (complete under-prediction) and 1 (complete over-prediction) and 0 ideally. G: \DIFdelbeginFL \DIFdelFL {Empirical coverage }\DIFdelendFL \DIFaddbeginFL \DIFaddFL {Absolute error }\DIFaddendFL of the \DIFdelbeginFL \DIFdelFL {50\% prediction intervals}\DIFdelendFL \DIFaddbeginFL \DIFaddFL {median forecast relative to the Hub ensemble}\DIFaddendFL . \DIFdelbeginFL \DIFdelFL {F: Empirical coverage }\DIFdelendFL \DIFaddbeginFL \DIFaddFL {H. Standard deviation }\DIFaddendFL of \DIFaddbeginFL \DIFaddFL {all WIS values for different horizons relative to }\DIFaddendFL the \DIFdelbeginFL \DIFdelFL {90\% prediction intervals}\DIFdelendFL \DIFaddbeginFL \DIFaddFL {Hub ensemble.}\DIFaddendFL }{figure.21}{}}
\BKM@entry{id=34,dest={73756273756273656374696F6E2E412E31302E32},srcline={764}}{5C3337365C3337375C303030545C303030615C303030625C3030306C5C303030655C303030735C3030305C3034305C3030306D5C303030655C303030645C303030695C303030615C3030306E5C3030305C3034305C303030655C3030306E5C303030735C303030655C3030306D5C303030625C3030306C5C30303065}
\BKM@entry{id=35,dest={73756273756273656374696F6E2E412E31302E33},srcline={883}}{5C3337365C3337375C303030545C303030615C303030625C3030306C5C303030655C303030735C3030305C3034305C3030306D5C303030655C303030615C3030306E5C3030305C3034305C303030655C3030306E5C303030735C303030655C3030306D5C303030625C3030306C5C30303065}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {A.10.2}Tables median ensemble}{59}{subsubsection.A.10.2}\protected@file@percent }
\newlabel{tables-median-ensemble}{{A.10.2}{59}{Tables median ensemble}{subsubsection.A.10.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {S4}{\ignorespaces Scores for one and two week ahead forecasts (cut to three significant digits and rounded) for the different versions of the median ensemble. Note that scores for cases (which include the whole period from October 12th 2020 until March 1st 2021) and deaths (which include only forecasts from the 21st of December 2020 on) are computed on different subsets. Numbers in brackets show the metrics relative to the Hub ensemble (i.e. the median ensemble of all other models submitted to the German and Polish Forecast Hub, excluding our contributions). WIS is the mean weighted interval score (lower values are better), WIS - sd is the standard deviation of all scores achieved by a model. Dispersion, over-prediction and under-prediction together sum up to the weighted interval score. Bias (between -1 and 1, 0 is ideal) represents the general average tendency of a model to over- or underpredict. 50\% and 90\%-coverage are the percentage of observed values that fell within the 50\% and 90\% prediction intervals of a model.\\\hspace  {\textwidth }}}{59}{table.4}\protected@file@percent }
\newlabel{tab:score-table-ensemble-2}{{S4}{59}{Scores for one and two week ahead forecasts (cut to three significant digits and rounded) for the different versions of the median ensemble. Note that scores for cases (which include the whole period from October 12th 2020 until March 1st 2021) and deaths (which include only forecasts from the 21st of December 2020 on) are computed on different subsets. Numbers in brackets show the metrics relative to the Hub ensemble (i.e. the median ensemble of all other models submitted to the German and Polish Forecast Hub, excluding our contributions). WIS is the mean weighted interval score (lower values are better), WIS - sd is the standard deviation of all scores achieved by a model. Dispersion, over-prediction and under-prediction together sum up to the weighted interval score. Bias (between -1 and 1, 0 is ideal) represents the general average tendency of a model to over- or underpredict. 50\% and 90\%-coverage are the percentage of observed values that fell within the 50\% and 90\% prediction intervals of a model.\\\hspace {\textwidth }}{table.4}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {A.10.3}Tables mean ensemble}{59}{subsubsection.A.10.3}\protected@file@percent }
\newlabel{tables-mean-ensemble}{{A.10.3}{59}{Tables mean ensemble}{subsubsection.A.10.3}{}}
\@writefile{lot}{\contentsline {table}{\numberline {S5}{\ignorespaces Scores for three and four week ahead forecasts (cut to three significant digits and rounded) for the different versions of the median ensemble. Note that scores for cases (which include the whole period from October 12th 2020 until March 1st 2021) and deaths (which include only forecasts from the 21st of December 2020 on) are computed on different subsets. Numbers in brackets show the metrics relative to the Hub ensemble (i.e. the median ensemble of all other models submitted to the German and Polish Forecast Hub, excluding our contributions). WIS is the mean weighted interval score (lower values are better), WIS - sd is the standard deviation of all scores achieved by a model. Dispersion, over-prediction and under-prediction together sum up to the weighted interval score. Bias (between -1 and 1, 0 is ideal) represents the general average tendency of a model to over- or underpredict. 50\% and 90\%-coverage are the percentage of observed values that fell within the 50\% and 90\% prediction intervals of a model.\\\hspace  {\textwidth }}}{60}{table.5}\protected@file@percent }
\newlabel{tab:score-table-ensemble-4}{{S5}{60}{Scores for three and four week ahead forecasts (cut to three significant digits and rounded) for the different versions of the median ensemble. Note that scores for cases (which include the whole period from October 12th 2020 until March 1st 2021) and deaths (which include only forecasts from the 21st of December 2020 on) are computed on different subsets. Numbers in brackets show the metrics relative to the Hub ensemble (i.e. the median ensemble of all other models submitted to the German and Polish Forecast Hub, excluding our contributions). WIS is the mean weighted interval score (lower values are better), WIS - sd is the standard deviation of all scores achieved by a model. Dispersion, over-prediction and under-prediction together sum up to the weighted interval score. Bias (between -1 and 1, 0 is ideal) represents the general average tendency of a model to over- or underpredict. 50\% and 90\%-coverage are the percentage of observed values that fell within the 50\% and 90\% prediction intervals of a model.\\\hspace {\textwidth }}{table.5}{}}
\@writefile{lot}{\contentsline {table}{\numberline {S6}{\ignorespaces Scores for one and two week ahead forecasts (cut to three significant digits and rounded) for the different versions of the mean ensemble. Note that scores for cases (which include the whole period from October 12th 2020 until March 1st 2021) and deaths (which include only forecasts from the 21st of December 2020 on) are computed on different subsets. Numbers in brackets show the metrics relative to the Hub mean ensemble (i.e. the mean ensemble of all other models submitted to the German and Polish Forecast Hub, excluding our contributions). WIS is the mean weighted interval score (lower values are better), WIS - sd is the standard deviation of all scores achieved by a model. Dispersion, over-prediction and under-prediction together sum up to the weighted interval score. Bias (between -1 and 1, 0 is ideal) represents the general average tendency of a model to over- or underpredict. 50\% and 90\%-coverage are the percentage of observed values that fell within the 50\% and 90\% prediction intervals of a model.\\\hspace  {\textwidth }}}{61}{table.6}\protected@file@percent }
\newlabel{tab:score-table-ensemble-mean-2}{{S6}{61}{Scores for one and two week ahead forecasts (cut to three significant digits and rounded) for the different versions of the mean ensemble. Note that scores for cases (which include the whole period from October 12th 2020 until March 1st 2021) and deaths (which include only forecasts from the 21st of December 2020 on) are computed on different subsets. Numbers in brackets show the metrics relative to the Hub mean ensemble (i.e. the mean ensemble of all other models submitted to the German and Polish Forecast Hub, excluding our contributions). WIS is the mean weighted interval score (lower values are better), WIS - sd is the standard deviation of all scores achieved by a model. Dispersion, over-prediction and under-prediction together sum up to the weighted interval score. Bias (between -1 and 1, 0 is ideal) represents the general average tendency of a model to over- or underpredict. 50\% and 90\%-coverage are the percentage of observed values that fell within the 50\% and 90\% prediction intervals of a model.\\\hspace {\textwidth }}{table.6}{}}
\@writefile{lot}{\contentsline {table}{\numberline {S7}{\ignorespaces Scores for three and four week ahead forecasts (cut to three significant digits and rounded) for the different versions of the mean ensemble. Note that scores for cases (which include the whole period from October 12th 2020 until March 1st 2021) and deaths (which include only forecasts from the 21st of December 2020 on) are computed on different subsets. Numbers in brackets show the metrics relative to the Hub mean ensemble (i.e. the mean ensemble of all other models submitted to the German and Polish Forecast Hub, excluding our contributions). WIS is the mean weighted interval score (lower values are better), WIS - sd is the standard deviation of all scores achieved by a model. Dispersion, over-prediction and under-prediction together sum up to the weighted interval score. Bias (between -1 and 1, 0 is ideal) represents the general average tendency of a model to over- or underpredict. 50\% and 90\%-coverage are the percentage of observed values that fell within the 50\% and 90\% prediction intervals of a model.\\\hspace  {\textwidth }}}{62}{table.7}\protected@file@percent }
\newlabel{tab:score-table-ensemble-mean-4}{{S7}{62}{Scores for three and four week ahead forecasts (cut to three significant digits and rounded) for the different versions of the mean ensemble. Note that scores for cases (which include the whole period from October 12th 2020 until March 1st 2021) and deaths (which include only forecasts from the 21st of December 2020 on) are computed on different subsets. Numbers in brackets show the metrics relative to the Hub mean ensemble (i.e. the mean ensemble of all other models submitted to the German and Polish Forecast Hub, excluding our contributions). WIS is the mean weighted interval score (lower values are better), WIS - sd is the standard deviation of all scores achieved by a model. Dispersion, over-prediction and under-prediction together sum up to the weighted interval score. Bias (between -1 and 1, 0 is ideal) represents the general average tendency of a model to over- or underpredict. 50\% and 90\%-coverage are the percentage of observed values that fell within the 50\% and 90\% prediction intervals of a model.\\\hspace {\textwidth }}{table.7}{}}
\BKM@entry{id=36,dest={73756273656374696F6E2E412E3131},srcline={1004}}{5C3337365C3337375C303030535C303030655C3030306E5C303030735C303030695C303030745C303030695C303030765C303030695C303030745C303030795C3030305C3034305C303030615C3030306E5C303030615C3030306C5C303030795C303030735C303030695C30303073}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.11}Sensitivity analysis}{63}{subsection.A.11}\protected@file@percent }
\newlabel{sensitivity-analysis}{{A.11}{63}{Sensitivity analysis}{subsection.A.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {S22}{\ignorespaces Visualisation of aggregate performance metrics across forecast horizons only for the period from \DIFdelbeginFL  {\color {red}\sout {October }}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {December }}\DIFaddendFL  14th 2020 on where all models were available. A, B: mean weighted interval score (WIS, lower indicates better performance) across horizons. WIS is decomposed into its components dispersion, over-prediction and under-prediction. C: Empirical coverage of the 50\% prediction intervals (50\% coverage is perfect). D: Empirical coverage of the 90\% prediction intervals. E: Dispersion (same as in panel A, B). Higher values mean greater dispersion of the forecast and imply ceteris paribus a worse score. F: Bias, i.e. general (relative) tendency to over- or underpredict. Values are between -1 (complete under-prediction) and 1 (complete over-prediction) and 0 ideally. G: Absolute error of the median forecast (lower is better). H. Standard deviation of all WIS values for different horizons}}{64}{figure.22}\protected@file@percent }
\newlabel{fig:agg-performance-all-late}{{S22}{64}{Visualisation of aggregate performance metrics across forecast horizons only for the period from \DIFdelbeginFL \DIFdelFL {October }\DIFdelendFL \DIFaddbeginFL \DIFaddFL {December }\DIFaddendFL 14th 2020 on where all models were available. A, B: mean weighted interval score (WIS, lower indicates better performance) across horizons. WIS is decomposed into its components dispersion, over-prediction and under-prediction. C: Empirical coverage of the 50\% prediction intervals (50\% coverage is perfect). D: Empirical coverage of the 90\% prediction intervals. E: Dispersion (same as in panel A, B). Higher values mean greater dispersion of the forecast and imply ceteris paribus a worse score. F: Bias, i.e. general (relative) tendency to over- or underpredict. Values are between -1 (complete under-prediction) and 1 (complete over-prediction) and 0 ideally. G: Absolute error of the median forecast (lower is better). H. Standard deviation of all WIS values for different horizons}{figure.22}{}}
\@writefile{lot}{\contentsline {table}{\numberline {S8}{\ignorespaces Scores for one and two week ahead forecasts (cut to three significant digits and rounded) calculated on forecasts made between December 14th 2020 and March 1st 2021. Numbers in brackets show the metrics relative to the Hub ensemble (i.e. the median ensemble of all other models submitted to the German and Polish Forecast Hub, excluding our contributions). WIS is the mean weighted interval score (lower values are better), WIS - sd is the standard deviation of all scores achieved by a model. Dispersion, over-prediction and under-prediction together sum up to the weighted interval score. Bias (between -1 and 1, 0 is ideal) represents the general average tendency of a model to over- or underpredict. 50\% and 90\%-coverage are the percentage of observed values that fell within the 50\% and 90\% prediction intervals of a model.\\\hspace  {\textwidth }}}{65}{table.8}\protected@file@percent }
\newlabel{tab:score-table-late-2}{{S8}{65}{Scores for one and two week ahead forecasts (cut to three significant digits and rounded) calculated on forecasts made between December 14th 2020 and March 1st 2021. Numbers in brackets show the metrics relative to the Hub ensemble (i.e. the median ensemble of all other models submitted to the German and Polish Forecast Hub, excluding our contributions). WIS is the mean weighted interval score (lower values are better), WIS - sd is the standard deviation of all scores achieved by a model. Dispersion, over-prediction and under-prediction together sum up to the weighted interval score. Bias (between -1 and 1, 0 is ideal) represents the general average tendency of a model to over- or underpredict. 50\% and 90\%-coverage are the percentage of observed values that fell within the 50\% and 90\% prediction intervals of a model.\\\hspace {\textwidth }}{table.8}{}}
\@writefile{lot}{\contentsline {table}{\numberline {S9}{\ignorespaces Scores for three and four week ahead forecasts (cut to three significant digits and rounded) calculated on forecasts made between December 14th 2020 and March 1st 2021. Numbers in brackets show the metrics relative to the Hub ensemble (i.e. the median ensemble of all other models submitted to the German and Polish Forecast Hub, excluding our contributions). WIS is the mean weighted interval score (lower values are better), WIS - sd is the standard deviation of all scores achieved by a model. Dispersion, over-prediction and under-prediction together sum up to the weighted interval score. Bias (between -1 and 1, 0 is ideal) represents the general average tendency of a model to over- or underpredict. 50\% and 90\%-coverage are the percentage of observed values that fell within the 50\% and 90\% prediction intervals of a model.\\\hspace  {\textwidth }}}{66}{table.9}\protected@file@percent }
\newlabel{tab:score-table-late-4}{{S9}{66}{Scores for three and four week ahead forecasts (cut to three significant digits and rounded) calculated on forecasts made between December 14th 2020 and March 1st 2021. Numbers in brackets show the metrics relative to the Hub ensemble (i.e. the median ensemble of all other models submitted to the German and Polish Forecast Hub, excluding our contributions). WIS is the mean weighted interval score (lower values are better), WIS - sd is the standard deviation of all scores achieved by a model. Dispersion, over-prediction and under-prediction together sum up to the weighted interval score. Bias (between -1 and 1, 0 is ideal) represents the general average tendency of a model to over- or underpredict. 50\% and 90\%-coverage are the percentage of observed values that fell within the 50\% and 90\% prediction intervals of a model.\\\hspace {\textwidth }}{table.9}{}}
\BKM@entry{id=37,dest={73756273656374696F6E2E412E3132},srcline={1107}}{5C3337365C3337375C3030304F5C303030765C303030655C303030725C303030765C303030695C303030655C303030775C3030305C3034305C3030306F5C303030665C3030305C3034305C3030306D5C3030306F5C303030645C303030655C3030306C5C303030735C3030305C3034305C303030615C3030306E5C303030645C3030305C3034305C303030665C3030306F5C303030725C303030655C303030635C303030615C303030735C303030745C303030655C303030725C30303073}
\gdef \LT@ii {\LT@entry 
    {1}{140.0374pt}\LT@entry 
    {1}{324.9803pt}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.12}Overview of models and forecasters}{67}{subsection.A.12}\protected@file@percent }
\newlabel{overview-of-models-and-forecasters}{{A.12}{67}{Overview of models and forecasters}{subsection.A.12}{}}
\newlabel{tab:table-ensemble-versions}{{S10}{67}{Overview of models and forecasters}{table.10}{}}
\@writefile{lot}{\contentsline {table}{\numberline {S10}{Overview of the models and ensembles used.}}{67}{table.10}\protected@file@percent }
\newlabel{tab:table-ensemble-versions}{{S10}{68}{Overview of models and forecasters}{table.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {S23}{\ignorespaces Number of participants who submitted a forecast over time.}}{69}{figure.23}\protected@file@percent }
\newlabel{fig:num-forecasters}{{S23}{69}{Number of participants who submitted a forecast over time}{figure.23}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {S24}{\ignorespaces Number of member models (including our crowd forecasts and the renewal model) in the official Hub ensemble. Note that the renewal model was not included in the ensemble on December 28th 2020.}}{70}{figure.24}\protected@file@percent }
\newlabel{fig:num-ensemble-members}{{S24}{70}{Number of member models (including our crowd forecasts and the renewal model) in the official Hub ensemble. Note that the renewal model was not included in the ensemble on December 28th 2020}{figure.24}{}}
\BKM@entry{id=38,dest={73756273656374696F6E2E412E3133},srcline={1166}}{5C3337365C3337375C303030435C3030306F5C3030306D5C303030705C303030615C303030725C303030695C303030735C3030306F5C3030306E5C3030305C3034305C3030306F5C303030665C3030305C3034305C303030635C303030725C3030306F5C303030775C303030645C3030305C3034305C303030665C3030306F5C303030725C303030655C303030635C303030615C303030735C303030745C303030735C3030305C3034305C303030615C3030306E5C303030645C3030305C3034305C303030615C303030705C303030705C3030306C5C303030695C303030635C303030615C303030745C303030695C3030306F5C3030306E5C3030305C3034305C303030625C303030615C303030735C303030655C3030306C5C303030695C3030306E5C30303065}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.13}Comparison of crowd forecasts and application baseline}{71}{subsection.A.13}\protected@file@percent }
\newlabel{comparison-of-crowd-forecasts-and-application-baseline}{{A.13}{71}{Comparison of crowd forecasts and application baseline}{subsection.A.13}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {S25}{\ignorespaces {\color {blue}\uwave {Crowd forecasts and baseline shown in the application for a two week horizon. Shown are the 90\% and 50\% prediction intervals as well as the median (in order of increasing opacity). For any given point in time, the baseline shown in red is what forecasters saw when they opened the app (the baseline shown was constant across all forecast horizons).}}}}{71}{figure.25}\protected@file@percent }
\newlabel{fig:compare-forecasters}{{S25}{71}{\DIFaddFL {Crowd forecasts and baseline shown in the application for a two week horizon. Shown are the 90\% and 50\% prediction intervals as well as the median (in order of increasing opacity). For any given point in time, the baseline shown in red is what forecasters saw when they opened the app (the baseline shown was constant across all forecast horizons).}}{figure.25}{}}
\gdef \@abspage@last{78}
